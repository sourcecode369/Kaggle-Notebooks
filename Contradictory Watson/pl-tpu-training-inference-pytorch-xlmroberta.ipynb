{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  ['10.0.0.2:8470']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "try:\n",
    "   tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  \n",
    "   print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "except ValueError:\n",
    "   tpu = None\n",
    "if tpu:\n",
    "   tf.config.experimental_connect_to_cluster(tpu)\n",
    "   tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "   strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "   strategy = tf.distribute.get_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ssut/py-googletrans.git\r\n",
      "  Cloning https://github.com/ssut/py-googletrans.git to /tmp/pip-req-build-thm_t6y0\r\n",
      "  Running command git clone -q https://github.com/ssut/py-googletrans.git /tmp/pip-req-build-thm_t6y0\r\n",
      "Collecting httpx==0.13.3\r\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 55 kB 1.3 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: chardet==3.* in /opt/conda/lib/python3.7/site-packages (from httpx==0.13.3->googletrans==3.0.0) (3.0.4)\r\n",
      "Collecting hstspreload\r\n",
      "  Downloading hstspreload-2020.7.29-py3-none-any.whl (926 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 926 kB 7.7 MB/s \r\n",
      "\u001b[?25hCollecting sniffio\r\n",
      "  Downloading sniffio-1.1.0-py3-none-any.whl (4.5 kB)\r\n",
      "Collecting httpcore==0.9.*\r\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 42 kB 867 kB/s \r\n",
      "\u001b[?25hCollecting rfc3986<2,>=1.3\r\n",
      "  Downloading rfc3986-1.4.0-py2.py3-none-any.whl (31 kB)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from httpx==0.13.3->googletrans==3.0.0) (2020.6.20)\r\n",
      "Requirement already satisfied: idna==2.* in /opt/conda/lib/python3.7/site-packages (from httpx==0.13.3->googletrans==3.0.0) (2.9)\r\n",
      "Collecting h11<0.10,>=0.8\r\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 53 kB 1.3 MB/s \r\n",
      "\u001b[?25hCollecting h2==3.*\r\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 65 kB 2.2 MB/s \r\n",
      "\u001b[?25hCollecting hpack<4,>=3.0\r\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\r\n",
      "Collecting hyperframe<6,>=5.2.0\r\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\r\n",
      "Building wheels for collected packages: googletrans\r\n",
      "  Building wheel for googletrans (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for googletrans: filename=googletrans-3.0.0-py3-none-any.whl size=16448 sha256=182cd017564283384652383d21d01ee23c380b71bfd5bd7966c921947fe815f0\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ltm0iwpz/wheels/eb/82/a2/f07ad36dbee6290000d9057df7e3c81a973db81913efd3b252\r\n",
      "Successfully built googletrans\r\n",
      "Installing collected packages: hstspreload, sniffio, h11, hpack, hyperframe, h2, httpcore, rfc3986, httpx, googletrans\r\n",
      "Successfully installed googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2020.7.29 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 rfc3986-1.4.0 sniffio-1.1.0\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100  5115  100  5115    0     0  74130      0 --:--:-- --:--:-- --:--:-- 74130\r\n",
      "Updating... This may take around 2 minutes.\r\n",
      "Updating TPU runtime to pytorch-nightly ...\r\n",
      "Found existing installation: torch 1.5.0\r\n",
      "Uninstalling torch-1.5.0:\r\n",
      "  Successfully uninstalled torch-1.5.0\r\n",
      "Found existing installation: torchvision 0.6.0a0+35d732a\r\n",
      "Uninstalling torchvision-0.6.0a0+35d732a:\r\n",
      "Done updating TPU runtime\r\n",
      "  Successfully uninstalled torchvision-0.6.0a0+35d732a\r\n",
      "Copying gs://tpu-pytorch/wheels/torch-nightly-cp37-cp37m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/109.1 MiB.                                    \r\n",
      "Copying gs://tpu-pytorch/wheels/torch_xla-nightly-cp37-cp37m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/124.6 MiB.                                    \r\n",
      "Copying gs://tpu-pytorch/wheels/torchvision-nightly-cp37-cp37m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/2.4 MiB.                                      \r\n",
      "Processing ./torch-nightly-cp37-cp37m-linux_x86_64.whl\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch==nightly) (0.18.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch==nightly) (1.18.5)\r\n",
      "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\r\n",
      "\u001b[31mERROR: kornia 0.3.1 has requirement torch==1.5.0, but you'll have torch 1.7.0a0+206db5c which is incompatible.\u001b[0m\r\n",
      "\u001b[31mERROR: allennlp 1.0.0 has requirement torch<1.6.0,>=1.5.0, but you'll have torch 1.7.0a0+206db5c which is incompatible.\u001b[0m\r\n",
      "Installing collected packages: torch\r\n",
      "Successfully installed torch-1.7.0a0+206db5c\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Processing ./torch_xla-nightly-cp37-cp37m-linux_x86_64.whl\r\n",
      "Installing collected packages: torch-xla\r\n",
      "Successfully installed torch-xla-1.6+63ff8fb\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Processing ./torchvision-nightly-cp37-cp37m-linux_x86_64.whl\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly) (7.2.0)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly) (1.7.0a0+206db5c)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly) (1.18.5)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->torchvision==nightly) (0.18.2)\r\n",
      "Installing collected packages: torchvision\r\n",
      "Successfully installed torchvision-0.8.0a0+6db1569\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "The following additional packages will be installed:\r\n",
      "  libgfortran4 libopenblas-base\r\n",
      "The following NEW packages will be installed:\r\n",
      "  libgfortran4 libomp5 libopenblas-base libopenblas-dev\r\n",
      "0 upgraded, 4 newly installed, 0 to remove and 59 not upgraded.\r\n",
      "Need to get 8550 kB of archives.\r\n",
      "After this operation, 97.6 MB of additional disk space will be used.\r\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgfortran4 amd64 7.5.0-3ubuntu1~18.04 [492 kB]\r\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenblas-base amd64 0.2.20+ds-4 [3964 kB]\r\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenblas-dev amd64 0.2.20+ds-4 [3860 kB]\r\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\r\n",
      "Fetched 8550 kB in 1s (6560 kB/s)\r\n",
      "debconf: delaying package configuration, since apt-utils is not installed\r\n",
      "Selecting previously unselected package libgfortran4:amd64.\r\n",
      "(Reading database ... 107745 files and directories currently installed.)\r\n",
      "Preparing to unpack .../libgfortran4_7.5.0-3ubuntu1~18.04_amd64.deb ...\r\n",
      "Unpacking libgfortran4:amd64 (7.5.0-3ubuntu1~18.04) ...\r\n",
      "Selecting previously unselected package libopenblas-base:amd64.\r\n",
      "Preparing to unpack .../libopenblas-base_0.2.20+ds-4_amd64.deb ...\r\n",
      "Unpacking libopenblas-base:amd64 (0.2.20+ds-4) ...\r\n",
      "Selecting previously unselected package libopenblas-dev:amd64.\r\n",
      "Preparing to unpack .../libopenblas-dev_0.2.20+ds-4_amd64.deb ...\r\n",
      "Unpacking libopenblas-dev:amd64 (0.2.20+ds-4) ...\r\n",
      "Selecting previously unselected package libomp5:amd64.\r\n",
      "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\r\n",
      "Unpacking libomp5:amd64 (5.0.1-1) ...\r\n",
      "Setting up libomp5:amd64 (5.0.1-1) ...\r\n",
      "Setting up libgfortran4:amd64 (7.5.0-3ubuntu1~18.04) ...\r\n",
      "Setting up libopenblas-base:amd64 (0.2.20+ds-4) ...\r\n",
      "update-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3 to provide /usr/lib/x86_64-linux-gnu/libblas.so.3 (libblas.so.3-x86_64-linux-gnu) in auto mode\r\n",
      "update-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/liblapack.so.3 to provide /usr/lib/x86_64-linux-gnu/liblapack.so.3 (liblapack.so.3-x86_64-linux-gnu) in auto mode\r\n",
      "Setting up libopenblas-dev:amd64 (0.2.20+ds-4) ...\r\n",
      "update-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/libblas.so to provide /usr/lib/x86_64-linux-gnu/libblas.so (libblas.so-x86_64-linux-gnu) in auto mode\r\n",
      "update-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/liblapack.so to provide /usr/lib/x86_64-linux-gnu/liblapack.so (liblapack.so-x86_64-linux-gnu) in auto mode\r\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\r\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/ssut/py-googletrans.git\n",
    "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "!python pytorch-xla-env-setup.py --version nightly  --apt-packages libomp5 libopenblas-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTORCH: 206db5c1272a536fc668a1b5822a7de2c4fc5934\n",
      "XLA: 63ff8fb3b18e4ac627aae74864ce936ba9474a87\n",
      "CPU times: user 1.69 s, sys: 249 ms, total: 1.94 s\n",
      "Wall time: 2.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%autosave 60\n",
    "\n",
    "import os\n",
    "os.environ['XLA_USE_BF16'] = \"1\"\n",
    "os.environ['XLA_TENSOR_ALLOCATOR_MAXSIZE'] = '100000000'\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "from googletrans import Translator\n",
    "from dask import bag, diagnostics\n",
    "\n",
    "import transformers\n",
    "from transformers import (AdamW, \n",
    "                          XLMRobertaTokenizer, \n",
    "                          XLMRobertaModel, \n",
    "                          get_cosine_schedule_with_warmup)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.debug.metrics as met\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import torch_xla.utils.serialization as xser\n",
    "import torch_xla.version as xv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print('PYTORCH:', xv.__torch_gitrev__)\n",
    "print('XLA:', xv.__xla_gitrev__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/contradictory-my-dear-watson/train.csv')\n",
    "test = pd.read_csv('../input/contradictory-my-dear-watson/test.csv')\n",
    "sample_submission = pd.read_csv('../input/contradictory-my-dear-watson/sample_submission.csv')\n",
    "pseudo = pd.read_csv('../input/contradictorywatsonpublicxlmroberta/submission.csv')\n",
    "temp = test.copy()\n",
    "temp['label'] = pseudo.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  3min 11.0s\n",
      "[########################################] | 100% Completed |  3min  5.6s\n",
      "[########################################] | 100% Completed |  1min 19.5s\n",
      "[########################################] | 100% Completed |  1min 19.0s\n"
     ]
    }
   ],
   "source": [
    "def translate(words):\n",
    "    translator = Translator()\n",
    "    decoded = translator.translate(words, dest='en').text\n",
    "    return decoded\n",
    "\n",
    "other_langs_train = train.loc[train.lang_abv != \"en\"].copy()\n",
    "other_langs_test = temp.loc[temp.lang_abv != \"en\"].copy()\n",
    "\n",
    "#TODO: use a dask dataframe instead of bags\n",
    "train_premise_bag = bag.from_sequence(other_langs_train.premise.tolist()).map(translate)\n",
    "train_hypo_bag =  bag.from_sequence(other_langs_train.hypothesis.tolist()).map(translate)\n",
    "test_premise_bag = bag.from_sequence(other_langs_test.premise.tolist()).map(translate)\n",
    "test_hypo_bag =  bag.from_sequence(other_langs_test.hypothesis.tolist()).map(translate)\n",
    "with diagnostics.ProgressBar():\n",
    "    premises_train = train_premise_bag.compute()\n",
    "    hypos_train = train_hypo_bag.compute()\n",
    "    premises_test = test_premise_bag.compute()\n",
    "    hypos_test = test_hypo_bag.compute()\n",
    "\n",
    "other_langs_train[['premise', 'hypothesis']] = list(zip(premises_train, hypos_train))\n",
    "other_langs_test[['premise', 'hypothesis']] = list(zip(premises_test, hypos_test))\n",
    "train = train.append(other_langs_train)\n",
    "temp = temp.append(other_langs_test)\n",
    "train = pd.concat([train, temp], axis=0)\n",
    "train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetRetriever(Dataset):\n",
    "    def __init__(self, df, encoded):\n",
    "        self.df = df\n",
    "        self.encoded = encoded\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):   \n",
    "        ids = self.encoded['input_ids'][index]\n",
    "        mask = self.encoded['attention_mask'][index]\n",
    "        targets = self.df.iloc[index].label\n",
    "        return {\n",
    "            'ids':torch.tensor(ids),\n",
    "            'mask':torch.tensor(mask),\n",
    "            'targets':targets\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLMRoberta(nn.Module):\n",
    "    def __init__(self, num_labels, multisample):\n",
    "        super(XLMRoberta, self).__init__()\n",
    "        output_hidden_states = False\n",
    "        self.num_labels = num_labels\n",
    "        self.multisample= multisample\n",
    "        self.roberta = XLMRobertaModel.from_pretrained(\"xlm-roberta-large\", \n",
    "                                                       output_hidden_states=output_hidden_states, \n",
    "                                                       num_labels=1)\n",
    "        self.layer_norm = nn.LayerNorm(1024*2)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.high_dropout = nn.Dropout(p=0.5)        \n",
    "        self.classifier = nn.Linear(1024*2, self.num_labels)\n",
    "    \n",
    "    def forward(self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None):\n",
    "        outputs = self.roberta(input_ids,\n",
    "                               attention_mask=attention_mask,\n",
    "                               token_type_ids=token_type_ids,\n",
    "                               position_ids=position_ids,\n",
    "                               head_mask=head_mask,\n",
    "                               inputs_embeds=inputs_embeds)\n",
    "        average_pool = torch.mean(outputs[0], 1)\n",
    "        max_pool, _ = torch.max(outputs[0], 1)\n",
    "        concatenate_layer = torch.cat((average_pool, max_pool), 1)\n",
    "        normalization = self.layer_norm(concatenate_layer)\n",
    "        if self.multisample:\n",
    "            # Multisample Dropout\n",
    "            logits = torch.mean(\n",
    "                torch.stack(\n",
    "                    [self.classifier(self.dropout(normalization)) for _ in range(5)],\n",
    "                    dim=0,\n",
    "                ),\n",
    "                dim=0,\n",
    "            )\n",
    "        else:\n",
    "            logits = self.dropout(normalization)\n",
    "            logits = self.classifier(logits)       \n",
    "        outputs = F.log_softmax(logits, dim=1)\n",
    "        return outputs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_optimizer(model):\n",
    "    # Differential Learning Rate\n",
    "    def is_backbone(name):\n",
    "        return \"roberta\" in name\n",
    "    \n",
    "    optimizer_grouped_parameters = [\n",
    "       {'params': [param for name, param in model.named_parameters() if is_backbone(name)], 'lr': LR},\n",
    "       {'params': [param for name, param in model.named_parameters() if not is_backbone(name)], 'lr': 1e-4} \n",
    "    ]\n",
    "    \n",
    "    optimizer = AdamW(\n",
    "        optimizer_grouped_parameters, lr=LR, weight_decay=1e-2\n",
    "    )\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return nn.NLLLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_fn(train_loader, model, optimizer, device, scheduler, epoch=None):\n",
    "    # Train\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1],\n",
    "        prefix=\"[xla:{}]Train:  Epoch: [{}]\".format(xm.get_ordinal(), epoch)\n",
    "    )\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        data_time.update(time.time()-end)\n",
    "        ids = data[\"ids\"]\n",
    "        mask = data[\"mask\"]\n",
    "        targets = data[\"targets\"]\n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "        targets = targets.to(device, dtype=torch.float)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(\n",
    "            input_ids = ids,\n",
    "            attention_mask = mask\n",
    "        )\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        xm.optimizer_step(optimizer)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        acc1= accuracy(outputs, targets, topk=(1,))\n",
    "        losses.update(loss.item(), ids.size(0))\n",
    "        top1.update(acc1[0].item(), ids.size(0))\n",
    "        scheduler.step()\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if i % 30 == 0:\n",
    "            progress.display(i)\n",
    "    del loss\n",
    "    del outputs\n",
    "    del ids\n",
    "    del mask\n",
    "    del targets\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loop_fn(validation_loader, model, device):\n",
    "    #Validation\n",
    "    model.eval()\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    learning_rate = AverageMeter('LR',':2.8f')\n",
    "    progress = ProgressMeter(\n",
    "        len(validation_loader),\n",
    "        [batch_time, losses, top1],\n",
    "        prefix='[xla:{}]Validation: '.format(xm.get_ordinal()))\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, data in enumerate(validation_loader):\n",
    "            ids = data[\"ids\"]\n",
    "            mask = data[\"mask\"]\n",
    "            targets = data[\"targets\"]\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            targets = targets.to(device, dtype=torch.float)\n",
    "            outputs = model(\n",
    "                input_ids = ids,\n",
    "                attention_mask = mask\n",
    "            )\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            acc1= accuracy(outputs, targets, topk=(1,))\n",
    "            losses.update(loss.item(), ids.size(0))\n",
    "            top1.update(acc1[0].item(), ids.size(0))\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            if i % 10 == 0:\n",
    "                progress.display(i)\n",
    "    del loss\n",
    "    del outputs\n",
    "    del ids\n",
    "    del mask\n",
    "    del targets\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e6e45e35fd421ab28fe5c6f5a84558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=513.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca4f693fdfd4e74866c634f7a0fa58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2244861551.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89987fa3dc8e43e08324d844462fe07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "MAX_LEN = 96\n",
    "# Scale learning rate to 8 TPU's\n",
    "LR = 2e-5 * xm.xrt_world_size() \n",
    "METRICS_DEBUG = True\n",
    "\n",
    "\n",
    "WRAPPED_MODEL = xmp.MpModelWrapper(XLMRoberta(num_labels=3, multisample=False))\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-large')\n",
    "\n",
    "mask = np.random.rand(len(train)) < 0.95\n",
    "train_df = train[mask]\n",
    "valid_df = train[~mask]\n",
    "\n",
    "train_text = train_df[['premise', 'hypothesis']].values.tolist()\n",
    "train_encoded = tokenizer.batch_encode_plus(\n",
    "    train_text,\n",
    "    pad_to_max_length=True,\n",
    "    max_length=MAX_LEN\n",
    ")\n",
    "\n",
    "valid_text = valid_df[['premise', 'hypothesis']].values.tolist()\n",
    "valid_encoded = tokenizer.batch_encode_plus(\n",
    "    valid_text,\n",
    "    pad_to_max_length=True,\n",
    "    max_length=MAX_LEN\n",
    ")\n",
    "\n",
    "train_dataset = DatasetRetriever(df=train_df, encoded=train_encoded)\n",
    "valid_dataset = DatasetRetriever(df=valid_df, encoded=valid_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run():\n",
    "    xm.master_print('Starting Run ...')\n",
    "    train_sampler = DistributedSampler(\n",
    "        train_dataset,\n",
    "        num_replicas=xm.xrt_world_size(),\n",
    "        rank=xm.get_ordinal(),\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    train_data_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "        sampler=train_sampler,\n",
    "        drop_last=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "    xm.master_print('Train Loader Created.')\n",
    "    \n",
    "    valid_sampler = DistributedSampler(\n",
    "        valid_dataset,\n",
    "        num_replicas=xm.xrt_world_size(),\n",
    "        rank=xm.get_ordinal(),\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    valid_data_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=VALID_BATCH_SIZE,\n",
    "        sampler=valid_sampler,\n",
    "        drop_last=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "    xm.master_print('Valid Loader Created.')\n",
    "    \n",
    "    num_train_steps = int(len(train_df) / TRAIN_BATCH_SIZE / xm.xrt_world_size())\n",
    "    device = xm.xla_device()\n",
    "    model = WRAPPED_MODEL.to(device)\n",
    "    model.load_state_dict(xser.load(\"../input/contradictorywatsonpublicxlmroberta/model.bin\"))\n",
    "    xm.master_print('Done Model Loading.')\n",
    "    optimizer = get_model_optimizer(model)\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps = 0,\n",
    "        num_training_steps = num_train_steps * EPOCHS\n",
    "    )\n",
    "    xm.master_print(f'Num Train Steps= {num_train_steps}, XRT World Size= {xm.xrt_world_size()}.')\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        para_loader = pl.ParallelLoader(train_data_loader, [device])\n",
    "        xm.master_print('Parallel Loader Created. Training ...')\n",
    "        train_loop_fn(para_loader.per_device_loader(device),\n",
    "                      model,  \n",
    "                      optimizer, \n",
    "                      device, \n",
    "                      scheduler, \n",
    "                      epoch\n",
    "                     )\n",
    "        \n",
    "        xm.master_print(\"Finished training epoch {}\".format(epoch))\n",
    "            \n",
    "        para_loader = pl.ParallelLoader(valid_data_loader, [device])\n",
    "        xm.master_print('Parallel Loader Created. Validating ...')\n",
    "        eval_loop_fn(para_loader.per_device_loader(device), \n",
    "                     model,  \n",
    "                     device\n",
    "                    )\n",
    "        \n",
    "        # Serialized and Memory Reduced Model Saving\n",
    "        if epoch == EPOCHS-1:\n",
    "            xm.master_print('Saving Model ..')\n",
    "            xser.save(model.state_dict(), f\"model.bin\", master_only=True)\n",
    "            xm.master_print('Model Saved.')\n",
    "            \n",
    "    if METRICS_DEBUG:\n",
    "      xm.master_print(met.metrics_report(), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Run ...\n",
      "Train Loader Created.\n",
      "Valid Loader Created.\n",
      "Done Model Loading.\n",
      "Num Train Steps= 184, XRT World Size= 8.\n",
      "Parallel Loader Created. Training ...\n",
      "[xla:6]Train:  Epoch: [0][  0/184]\tTime 32.717 (32.717)\tData  0.073 ( 0.073)\tLoss 4.9219e-01 (4.9219e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:4]Train:  Epoch: [0][  0/184]\tTime  5.500 ( 5.500)\tData  0.067 ( 0.067)\tLoss 4.8047e-01 (4.8047e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:3]Train:  Epoch: [0][  0/184]\tTime 18.252 (18.252)\tData  0.078 ( 0.078)\tLoss 6.3281e-01 (6.3281e-01)\tAcc@1  75.00 ( 75.00)\n",
      "[xla:5]Train:  Epoch: [0][  0/184]\tTime 12.161 (12.161)\tData  0.077 ( 0.077)\tLoss 3.1445e-01 (3.1445e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:2]Train:  Epoch: [0][  0/184]\tTime 26.500 (26.500)\tData  0.089 ( 0.089)\tLoss 3.1445e-01 (3.1445e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:1]Train:  Epoch: [0][  0/184]\tTime 39.819 (39.819)\tData  0.085 ( 0.085)\tLoss 4.9219e-01 (4.9219e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:0]Train:  Epoch: [0][  0/184]\tTime 43.801 (43.801)\tData  0.619 ( 0.619)\tLoss 5.1953e-01 (5.1953e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:7]Train:  Epoch: [0][  0/184]\tTime  0.986 ( 0.986)\tData  0.113 ( 0.113)\tLoss 6.9141e-01 (6.9141e-01)\tAcc@1  69.00 ( 69.00)\n",
      "[xla:0]Train:  Epoch: [0][ 30/184]\tTime  0.759 ( 6.964)\tData  0.060 ( 4.770)\tLoss 5.0391e-01 (4.3010e-01)\tAcc@1  81.00 ( 83.44)\n",
      "[xla:4]Train:  Epoch: [0][ 30/184]\tTime  0.809 ( 5.731)\tData  0.063 ( 4.747)\tLoss 4.2578e-01 (4.0483e-01)\tAcc@1  87.50 ( 83.87)\n",
      "[xla:2]Train:  Epoch: [0][ 30/184]\tTime  0.886 ( 6.409)\tData  0.067 ( 4.745)\tLoss 1.0791e-01 (4.5284e-01)\tAcc@1 100.00 ( 83.47)\n",
      "[xla:3]Train:  Epoch: [0][ 30/184]\tTime  0.867 ( 6.143)\tData  0.057 ( 4.749)\tLoss 2.8320e-01 (4.1784e-01)\tAcc@1  87.50 ( 84.47)\n",
      "[xla:7]Train:  Epoch: [0][ 30/184]\tTime  0.837 ( 5.518)\tData  0.060 ( 4.685)\tLoss 1.4258e-01 (3.6141e-01)\tAcc@1 100.00 ( 87.10)\n",
      "[xla:1]Train:  Epoch: [0][ 30/184]\tTime  1.080 ( 6.839)\tData  0.104 ( 4.760)\tLoss 3.2617e-01 (3.6374e-01)\tAcc@1  94.00 ( 86.06)\n",
      "[xla:5]Train:  Epoch: [0][ 30/184]\tTime  0.959 ( 5.949)\tData  0.052 ( 4.755)\tLoss 2.6367e-01 (4.3385e-01)\tAcc@1  87.50 ( 83.66)\n",
      "[xla:6]Train:  Epoch: [0][ 30/184]\tTime  0.966 ( 6.611)\tData  0.051 ( 4.747)\tLoss 2.9102e-01 (4.0949e-01)\tAcc@1  87.50 ( 85.26)\n",
      "[xla:1]Train:  Epoch: [0][ 60/184]\tTime  0.813 ( 3.918)\tData  0.072 ( 2.454)\tLoss 7.5000e-01 (3.6811e-01)\tAcc@1  43.75 ( 86.07)\n",
      "[xla:5]Train:  Epoch: [0][ 60/184]\tTime  0.813 ( 3.465)\tData  0.093 ( 2.454)\tLoss 4.2969e-01 (4.1636e-01)\tAcc@1  87.50 ( 84.53)\n",
      "[xla:3]Train:  Epoch: [0][ 60/184]\tTime  0.814 ( 3.565)\tData  0.058 ( 2.450)\tLoss 4.2578e-01 (3.9865e-01)\tAcc@1  75.00 ( 84.40)\n",
      "[xla:0]Train:  Epoch: [0][ 60/184]\tTime  0.870 ( 3.984)\tData  0.048 ( 2.461)\tLoss 7.4609e-01 (4.3374e-01)\tAcc@1  69.00 ( 83.22)\n",
      "[xla:6]Train:  Epoch: [0][ 60/184]\tTime  0.854 ( 3.803)\tData  0.095 ( 2.449)\tLoss 4.1406e-01 (3.9552e-01)\tAcc@1  81.00 ( 85.53)\n",
      "[xla:7]Train:  Epoch: [0][ 60/184]\tTime  0.917 ( 3.248)\tData  0.048 ( 2.420)\tLoss 2.0117e-01 (3.5314e-01)\tAcc@1  94.00 ( 86.55)\n",
      "[xla:2]Train:  Epoch: [0][ 60/184]\tTime  1.071 ( 3.701)\tData  0.107 ( 2.447)\tLoss 4.7070e-01 (4.2993e-01)\tAcc@1  69.00 ( 83.91)\n",
      "[xla:4]Train:  Epoch: [0][ 60/184]\tTime  0.877 ( 3.357)\tData  0.065 ( 2.448)\tLoss 2.1973e-01 (3.8188e-01)\tAcc@1  94.00 ( 85.16)\n",
      "[xla:7]Train:  Epoch: [0][ 90/184]\tTime  0.823 ( 2.467)\tData  0.055 ( 1.645)\tLoss 3.3008e-01 (3.7175e-01)\tAcc@1  81.00 ( 86.04)\n",
      "[xla:2]Train:  Epoch: [0][ 90/184]\tTime  0.875 ( 2.772)\tData  0.054 ( 1.666)\tLoss 2.6367e-01 (4.1125e-01)\tAcc@1  87.50 ( 84.40)\n",
      "[xla:6]Train:  Epoch: [0][ 90/184]\tTime  0.813 ( 2.840)\tData  0.056 ( 1.666)\tLoss 4.5703e-01 (3.9410e-01)\tAcc@1  81.00 ( 85.17)\n",
      "[xla:5]Train:  Epoch: [0][ 90/184]\tTime  0.923 ( 2.614)\tData  0.055 ( 1.670)\tLoss 3.5742e-01 (3.9969e-01)\tAcc@1  87.50 ( 84.77)\n",
      "[xla:0]Train:  Epoch: [0][ 90/184]\tTime  0.881 ( 2.962)\tData  0.055 ( 1.673)\tLoss 4.6680e-01 (4.1375e-01)\tAcc@1  87.50 ( 84.30)\n",
      "[xla:1]Train:  Epoch: [0][ 90/184]\tTime  0.895 ( 2.919)\tData  0.065 ( 1.669)\tLoss 8.2812e-01 (3.7864e-01)\tAcc@1  62.50 ( 85.37)\n",
      "[xla:4]Train:  Epoch: [0][ 90/184]\tTime  0.853 ( 2.542)\tData  0.065 ( 1.665)\tLoss 1.6797e-01 (3.7811e-01)\tAcc@1  94.00 ( 85.66)\n",
      "[xla:3]Train:  Epoch: [0][ 90/184]\tTime  0.898 ( 2.682)\tData  0.065 ( 1.667)\tLoss 5.4297e-01 (3.9115e-01)\tAcc@1  81.00 ( 84.65)\n",
      "[xla:1]Train:  Epoch: [0][120/184]\tTime  0.693 ( 2.408)\tData  0.082 ( 1.272)\tLoss 2.8125e-01 (3.8349e-01)\tAcc@1  94.00 ( 85.02)\n",
      "[xla:7]Train:  Epoch: [0][120/184]\tTime  0.750 ( 2.070)\tData  0.096 ( 1.254)\tLoss 6.3672e-01 (3.7670e-01)\tAcc@1  56.25 ( 85.85)\n",
      "[xla:6]Train:  Epoch: [0][120/184]\tTime  0.774 ( 2.350)\tData  0.087 ( 1.271)\tLoss 1.4551e-01 (4.0056e-01)\tAcc@1  94.00 ( 84.72)\n",
      "[xla:2]Train:  Epoch: [0][120/184]\tTime  0.823 ( 2.299)\tData  0.077 ( 1.268)\tLoss 1.5723e-01 (4.0750e-01)\tAcc@1 100.00 ( 84.91)\n",
      "[xla:3]Train:  Epoch: [0][120/184]\tTime  0.883 ( 2.231)\tData  0.074 ( 1.271)\tLoss 4.0234e-01 (3.8295e-01)\tAcc@1  87.50 ( 85.10)\n",
      "[xla:5]Train:  Epoch: [0][120/184]\tTime  0.929 ( 2.181)\tData  0.071 ( 1.272)\tLoss 2.0312e-01 (4.0655e-01)\tAcc@1  94.00 ( 84.16)\n",
      "[xla:4]Train:  Epoch: [0][120/184]\tTime  0.891 ( 2.126)\tData  0.094 ( 1.269)\tLoss 6.5625e-01 (3.9667e-01)\tAcc@1  81.00 ( 85.15)\n",
      "[xla:0]Train:  Epoch: [0][120/184]\tTime  0.946 ( 2.442)\tData  0.066 ( 1.277)\tLoss 6.0547e-01 (4.1535e-01)\tAcc@1  81.00 ( 83.94)\n",
      "[xla:6]Train:  Epoch: [0][150/184]\tTime  0.812 ( 2.064)\tData  0.111 ( 1.033)\tLoss 6.0791e-02 (3.8292e-01)\tAcc@1 100.00 ( 85.70)\n",
      "[xla:2]Train:  Epoch: [0][150/184]\tTime  0.845 ( 2.023)\tData  0.060 ( 1.031)\tLoss 8.9355e-02 (3.9381e-01)\tAcc@1  94.00 ( 85.55)\n",
      "[xla:5]Train:  Epoch: [0][150/184]\tTime  0.934 ( 1.928)\tData  0.055 ( 1.033)\tLoss 2.4805e-01 (3.8817e-01)\tAcc@1  87.50 ( 85.05)\n",
      "[xla:4]Train:  Epoch: [0][150/184]\tTime  0.862 ( 1.884)\tData  0.109 ( 1.031)\tLoss 2.9688e-01 (3.8380e-01)\tAcc@1  87.50 ( 85.42)\n",
      "[xla:1]Train:  Epoch: [0][150/184]\tTime  1.004 ( 2.111)\tData  0.057 ( 1.034)\tLoss 1.3965e-01 (3.5972e-01)\tAcc@1  94.00 ( 86.14)\n",
      "[xla:7]Train:  Epoch: [0][150/184]\tTime  0.911 ( 1.840)\tData  0.061 ( 1.020)\tLoss 8.7402e-02 (3.6885e-01)\tAcc@1 100.00 ( 85.77)\n",
      "[xla:3]Train:  Epoch: [0][150/184]\tTime  0.998 ( 1.969)\tData  0.068 ( 1.035)\tLoss 8.7891e-02 (3.7005e-01)\tAcc@1  94.00 ( 85.54)\n",
      "[xla:0]Train:  Epoch: [0][150/184]\tTime  0.986 ( 2.138)\tData  0.105 ( 1.038)\tLoss 8.3984e-02 (3.9415e-01)\tAcc@1 100.00 ( 84.78)\n",
      "[xla:1]Train:  Epoch: [0][180/184]\tTime  0.680 ( 1.904)\tData  0.052 ( 0.874)\tLoss 2.2852e-01 (3.6069e-01)\tAcc@1  94.00 ( 86.44)\n",
      "[xla:2]Train:  Epoch: [0][180/184]\tTime  0.633 ( 1.831)\tData  0.081 ( 0.871)\tLoss 4.4531e-01 (3.8550e-01)\tAcc@1  87.50 ( 85.64)\n",
      "[xla:6]Train:  Epoch: [0][180/184]\tTime  0.713 ( 1.866)\tData  0.064 ( 0.872)\tLoss 8.5938e-01 (3.8154e-01)\tAcc@1  75.00 ( 85.69)\n",
      "[xla:7]Train:  Epoch: [0][180/184]\tTime  0.797 ( 1.679)\tData  0.077 ( 0.862)\tLoss 5.1172e-01 (3.8064e-01)\tAcc@1  87.50 ( 85.68)\n",
      "[xla:0]Train:  Epoch: [0][180/184]\tTime  0.831 ( 1.928)\tData  0.087 ( 0.877)\tLoss 2.8125e-01 (3.8520e-01)\tAcc@1  94.00 ( 85.06)\n",
      "[xla:5]Train:  Epoch: [0][180/184]\tTime  0.880 ( 1.753)\tData  0.058 ( 0.874)\tLoss 2.7539e-01 (3.9872e-01)\tAcc@1  94.00 ( 84.94)\n",
      "[xla:4]Train:  Epoch: [0][180/184]\tTime  0.855 ( 1.716)\tData  0.080 ( 0.871)\tLoss 2.4316e-01 (3.8598e-01)\tAcc@1  94.00 ( 85.52)\n",
      "[xla:3]Train:  Epoch: [0][180/184]\tTime  0.904 ( 1.787)\tData  0.083 ( 0.874)\tLoss 2.9688e-01 (3.7359e-01)\tAcc@1  94.00 ( 85.98)\n",
      "Finished training epoch 0\n",
      "Parallel Loader Created. Validating ...\n",
      "[xla:6]Validation: [0/9]\tTime 17.621 (17.621)\tLoss 1.6797e-01 (1.6797e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:3]Validation: [0/9]\tTime 17.732 (17.732)\tLoss 4.3359e-01 (4.3359e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:7]Validation: [0/9]\tTime 17.611 (17.611)\tLoss 4.6094e-01 (4.6094e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:2]Validation: [0/9]\tTime 17.816 (17.816)\tLoss 4.1797e-01 (4.1797e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:5]Validation: [0/9]\tTime 17.914 (17.914)\tLoss 3.8281e-01 (3.8281e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:4]Validation: [0/9]\tTime 17.940 (17.940)\tLoss 5.1953e-01 (5.1953e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:1]Validation: [0/9]\tTime 17.615 (17.615)\tLoss 5.8594e-01 (5.8594e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:0]Validation: [0/9]\tTime 17.832 (17.832)\tLoss 6.6797e-01 (6.6797e-01)\tAcc@1  75.00 ( 75.00)\n",
      "Parallel Loader Created. Training ...\n",
      "[xla:4]Train:  Epoch: [1][  0/184]\tTime  0.780 ( 0.780)\tData  0.041 ( 0.041)\tLoss 4.3164e-01 (4.3164e-01)\tAcc@1  75.00 ( 75.00)\n",
      "[xla:5]Train:  Epoch: [1][  0/184]\tTime  0.817 ( 0.817)\tData  0.080 ( 0.080)\tLoss 3.8867e-01 (3.8867e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:0]Train:  Epoch: [1][  0/184]\tTime  0.874 ( 0.874)\tData  0.105 ( 0.105)\tLoss 3.8672e-01 (3.8672e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:6]Train:  Epoch: [1][  0/184]\tTime  0.680 ( 0.680)\tData  0.063 ( 0.063)\tLoss 6.0938e-01 (6.0938e-01)\tAcc@1  75.00 ( 75.00)\n",
      "[xla:1]Train:  Epoch: [1][  0/184]\tTime  0.870 ( 0.870)\tData  0.103 ( 0.103)\tLoss 4.2188e-01 (4.2188e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:2]Train:  Epoch: [1][  0/184]\tTime  0.729 ( 0.729)\tData  0.111 ( 0.111)\tLoss 2.2852e-01 (2.2852e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:7]Train:  Epoch: [1][  0/184]\tTime  0.791 ( 0.791)\tData  0.064 ( 0.064)\tLoss 8.2812e-01 (8.2812e-01)\tAcc@1  75.00 ( 75.00)\n",
      "[xla:3]Train:  Epoch: [1][  0/184]\tTime  0.690 ( 0.690)\tData  0.107 ( 0.107)\tLoss 5.5859e-01 (5.5859e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:2]Train:  Epoch: [1][ 30/184]\tTime  0.774 ( 0.867)\tData  0.042 ( 0.062)\tLoss 1.1279e-01 (4.0875e-01)\tAcc@1 100.00 ( 84.50)\n",
      "[xla:6]Train:  Epoch: [1][ 30/184]\tTime  0.792 ( 0.869)\tData  0.056 ( 0.065)\tLoss 3.9258e-01 (3.9070e-01)\tAcc@1  75.00 ( 85.10)\n",
      "[xla:0]Train:  Epoch: [1][ 30/184]\tTime  0.783 ( 0.879)\tData  0.071 ( 0.067)\tLoss 2.6562e-01 (4.4259e-01)\tAcc@1  87.50 ( 81.63)\n",
      "[xla:7]Train:  Epoch: [1][ 30/184]\tTime  0.832 ( 0.872)\tData  0.077 ( 0.064)\tLoss 1.4746e-01 (3.8212e-01)\tAcc@1 100.00 ( 86.49)\n",
      "[xla:1]Train:  Epoch: [1][ 30/184]\tTime  1.088 ( 0.876)\tData  0.094 ( 0.068)\tLoss 5.9766e-01 (3.8480e-01)\tAcc@1  81.00 ( 86.52)\n",
      "[xla:4]Train:  Epoch: [1][ 30/184]\tTime  0.891 ( 0.887)\tData  0.069 ( 0.065)\tLoss 3.1055e-01 (4.0212e-01)\tAcc@1  87.50 ( 83.27)\n",
      "[xla:3]Train:  Epoch: [1][ 30/184]\tTime  0.852 ( 0.870)\tData  0.054 ( 0.067)\tLoss 2.3633e-01 (3.9349e-01)\tAcc@1  94.00 ( 85.31)\n",
      "[xla:5]Train:  Epoch: [1][ 30/184]\tTime  0.899 ( 0.886)\tData  0.051 ( 0.071)\tLoss 2.3438e-01 (3.9157e-01)\tAcc@1 100.00 ( 83.27)\n",
      "[xla:5]Train:  Epoch: [1][ 60/184]\tTime  0.764 ( 0.886)\tData  0.096 ( 0.069)\tLoss 3.6719e-01 (3.7165e-01)\tAcc@1  94.00 ( 83.94)\n",
      "[xla:7]Train:  Epoch: [1][ 60/184]\tTime  0.905 ( 0.881)\tData  0.049 ( 0.065)\tLoss 2.1973e-01 (3.5744e-01)\tAcc@1  94.00 ( 87.02)\n",
      "[xla:0]Train:  Epoch: [1][ 60/184]\tTime  0.865 ( 0.885)\tData  0.089 ( 0.067)\tLoss 8.4766e-01 (4.2045e-01)\tAcc@1  62.50 ( 84.02)\n",
      "[xla:6]Train:  Epoch: [1][ 60/184]\tTime  0.866 ( 0.880)\tData  0.067 ( 0.068)\tLoss 4.4922e-01 (3.8389e-01)\tAcc@1  81.00 ( 85.15)\n",
      "[xla:1]Train:  Epoch: [1][ 60/184]\tTime  0.866 ( 0.883)\tData  0.087 ( 0.068)\tLoss 7.5391e-01 (3.6237e-01)\tAcc@1  62.50 ( 87.21)\n",
      "[xla:2]Train:  Epoch: [1][ 60/184]\tTime  0.889 ( 0.881)\tData  0.074 ( 0.066)\tLoss 2.5000e-01 (4.1410e-01)\tAcc@1  94.00 ( 83.82)\n",
      "[xla:4]Train:  Epoch: [1][ 60/184]\tTime  0.878 ( 0.889)\tData  0.073 ( 0.068)\tLoss 2.1582e-01 (3.7945e-01)\tAcc@1  94.00 ( 84.63)\n",
      "[xla:3]Train:  Epoch: [1][ 60/184]\tTime  0.946 ( 0.881)\tData  0.076 ( 0.068)\tLoss 3.7109e-01 (3.9341e-01)\tAcc@1  81.00 ( 84.52)\n",
      "[xla:6]Train:  Epoch: [1][ 90/184]\tTime  0.729 ( 0.877)\tData  0.070 ( 0.068)\tLoss 3.4961e-01 (3.9029e-01)\tAcc@1  87.50 ( 84.96)\n",
      "[xla:0]Train:  Epoch: [1][ 90/184]\tTime  0.792 ( 0.880)\tData  0.052 ( 0.068)\tLoss 4.3945e-01 (3.9933e-01)\tAcc@1  94.00 ( 84.55)\n",
      "[xla:2]Train:  Epoch: [1][ 90/184]\tTime  0.823 ( 0.878)\tData  0.071 ( 0.066)\tLoss 1.9727e-01 (3.9474e-01)\tAcc@1  87.50 ( 84.71)\n",
      "[xla:5]Train:  Epoch: [1][ 90/184]\tTime  0.956 ( 0.883)\tData  0.055 ( 0.068)\tLoss 2.5781e-01 (3.6243e-01)\tAcc@1  94.00 ( 84.71)\n",
      "[xla:7]Train:  Epoch: [1][ 90/184]\tTime  0.854 ( 0.879)\tData  0.072 ( 0.064)\tLoss 1.9922e-01 (3.7007e-01)\tAcc@1  94.00 ( 86.85)\n",
      "[xla:4]Train:  Epoch: [1][ 90/184]\tTime  0.843 ( 0.883)\tData  0.067 ( 0.070)\tLoss 2.3047e-01 (3.8011e-01)\tAcc@1  94.00 ( 85.25)\n",
      "[xla:3]Train:  Epoch: [1][ 90/184]\tTime  0.880 ( 0.878)\tData  0.076 ( 0.069)\tLoss 4.0039e-01 (3.9092e-01)\tAcc@1  87.50 ( 85.10)\n",
      "[xla:1]Train:  Epoch: [1][ 90/184]\tTime  0.884 ( 0.880)\tData  0.082 ( 0.069)\tLoss 6.1719e-01 (3.5340e-01)\tAcc@1  69.00 ( 87.37)\n",
      "[xla:1]Train:  Epoch: [1][120/184]\tTime  0.775 ( 0.875)\tData  0.064 ( 0.068)\tLoss 2.0508e-01 (3.6914e-01)\tAcc@1 100.00 ( 86.42)\n",
      "[xla:5]Train:  Epoch: [1][120/184]\tTime  0.813 ( 0.878)\tData  0.078 ( 0.067)\tLoss 3.3789e-01 (3.7304e-01)\tAcc@1  94.00 ( 84.83)\n",
      "[xla:7]Train:  Epoch: [1][120/184]\tTime  0.784 ( 0.875)\tData  0.068 ( 0.063)\tLoss 5.7422e-01 (3.6624e-01)\tAcc@1  69.00 ( 86.66)\n",
      "[xla:0]Train:  Epoch: [1][120/184]\tTime  0.940 ( 0.878)\tData  0.106 ( 0.068)\tLoss 5.0391e-01 (3.9912e-01)\tAcc@1  87.50 ( 84.50)\n",
      "[xla:4]Train:  Epoch: [1][120/184]\tTime  0.927 ( 0.879)\tData  0.094 ( 0.067)\tLoss 5.7422e-01 (3.8935e-01)\tAcc@1  81.00 ( 85.04)\n",
      "[xla:2]Train:  Epoch: [1][120/184]\tTime  0.937 ( 0.875)\tData  0.082 ( 0.066)\tLoss 3.1836e-01 (3.8996e-01)\tAcc@1  87.50 ( 85.46)\n",
      "[xla:3]Train:  Epoch: [1][120/184]\tTime  0.974 ( 0.875)\tData  0.072 ( 0.068)\tLoss 5.1172e-01 (3.8272e-01)\tAcc@1  81.00 ( 85.90)\n",
      "[xla:6]Train:  Epoch: [1][120/184]\tTime  1.019 ( 0.875)\tData  0.050 ( 0.066)\tLoss 1.1865e-01 (3.9187e-01)\tAcc@1  94.00 ( 84.82)\n",
      "[xla:5]Train:  Epoch: [1][150/184]\tTime  0.780 ( 0.881)\tData  0.066 ( 0.067)\tLoss 2.6953e-01 (3.5729e-01)\tAcc@1  81.00 ( 85.83)\n",
      "[xla:1]Train:  Epoch: [1][150/184]\tTime  0.822 ( 0.879)\tData  0.081 ( 0.068)\tLoss 2.8516e-01 (3.4819e-01)\tAcc@1  81.00 ( 87.22)\n",
      "[xla:2]Train:  Epoch: [1][150/184]\tTime  0.887 ( 0.879)\tData  0.049 ( 0.067)\tLoss 2.5977e-01 (3.7632e-01)\tAcc@1  94.00 ( 85.79)\n",
      "[xla:6]Train:  Epoch: [1][150/184]\tTime  0.843 ( 0.879)\tData  0.087 ( 0.067)\tLoss 7.7637e-02 (3.7989e-01)\tAcc@1 100.00 ( 85.78)\n",
      "[xla:7]Train:  Epoch: [1][150/184]\tTime  0.851 ( 0.879)\tData  0.059 ( 0.064)\tLoss 1.1670e-01 (3.5015e-01)\tAcc@1 100.00 ( 87.51)\n",
      "[xla:0]Train:  Epoch: [1][150/184]\tTime  0.910 ( 0.881)\tData  0.055 ( 0.069)\tLoss 3.6719e-01 (3.8704e-01)\tAcc@1  75.00 ( 84.94)\n",
      "[xla:3]Train:  Epoch: [1][150/184]\tTime  1.011 ( 0.879)\tData  0.061 ( 0.067)\tLoss 4.4922e-02 (3.6018e-01)\tAcc@1 100.00 ( 86.97)\n",
      "[xla:4]Train:  Epoch: [1][150/184]\tTime  0.913 ( 0.882)\tData  0.058 ( 0.067)\tLoss 2.5391e-01 (3.6983e-01)\tAcc@1  87.50 ( 85.91)\n",
      "[xla:0]Train:  Epoch: [1][180/184]\tTime  0.923 ( 0.878)\tData  0.044 ( 0.068)\tLoss 4.0625e-01 (3.6856e-01)\tAcc@1  81.00 ( 85.51)\n",
      "[xla:3]Train:  Epoch: [1][180/184]\tTime  0.975 ( 0.876)\tData  0.079 ( 0.067)\tLoss 2.9688e-01 (3.4851e-01)\tAcc@1  94.00 ( 87.38)\n",
      "[xla:1]Train:  Epoch: [1][180/184]\tTime  0.940 ( 0.877)\tData  0.058 ( 0.068)\tLoss 1.4648e-01 (3.3197e-01)\tAcc@1  94.00 ( 87.66)\n",
      "[xla:2]Train:  Epoch: [1][180/184]\tTime  1.003 ( 0.877)\tData  0.063 ( 0.066)\tLoss 4.1602e-01 (3.5675e-01)\tAcc@1  87.50 ( 86.74)\n",
      "[xla:4]Train:  Epoch: [1][180/184]\tTime  1.068 ( 0.880)\tData  0.052 ( 0.067)\tLoss 1.6895e-01 (3.6262e-01)\tAcc@1  87.50 ( 86.27)\n",
      "[xla:6]Train:  Epoch: [1][180/184]\tTime  1.108 ( 0.877)\tData  0.095 ( 0.067)\tLoss 5.1953e-01 (3.6432e-01)\tAcc@1  81.00 ( 86.32)\n",
      "[xla:5]Train:  Epoch: [1][180/184]\tTime  1.093 ( 0.880)\tData  0.051 ( 0.067)\tLoss 4.7852e-01 (3.5444e-01)\tAcc@1  87.50 ( 86.14)\n",
      "[xla:7]Train:  Epoch: [1][180/184]\tTime  1.093 ( 0.878)\tData  0.083 ( 0.064)\tLoss 6.5625e-01 (3.4548e-01)\tAcc@1  87.50 ( 87.87)\n",
      "Finished training epoch 1\n",
      "Parallel Loader Created. Validating ...\n",
      "[xla:0]Validation: [0/9]\tTime  0.227 ( 0.227)\tLoss 8.1250e-01 (8.1250e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:1]Validation: [0/9]\tTime  0.262 ( 0.262)\tLoss 7.8516e-01 (7.8516e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:2]Validation: [0/9]\tTime  0.262 ( 0.262)\tLoss 3.5547e-01 (3.5547e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:3]Validation: [0/9]\tTime  0.282 ( 0.282)\tLoss 3.5742e-01 (3.5742e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:4]Validation: [0/9]\tTime  0.246 ( 0.246)\tLoss 3.9062e-01 (3.9062e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:5]Validation: [0/9]\tTime  0.288 ( 0.288)\tLoss 3.0664e-01 (3.0664e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:6]Validation: [0/9]\tTime  0.276 ( 0.276)\tLoss 1.0156e-01 (1.0156e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:7]Validation: [0/9]\tTime  0.337 ( 0.337)\tLoss 7.5000e-01 (7.5000e-01)\tAcc@1  75.00 ( 75.00)\n",
      "Parallel Loader Created. Training ...\n",
      "[xla:5]Train:  Epoch: [2][  0/184]\tTime  0.872 ( 0.872)\tData  0.108 ( 0.108)\tLoss 1.8164e-01 (1.8164e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:0]Train:  Epoch: [2][  0/184]\tTime  1.029 ( 1.029)\tData  0.069 ( 0.069)\tLoss 7.4219e-01 (7.4219e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:1]Train:  Epoch: [2][  0/184]\tTime  0.917 ( 0.917)\tData  0.084 ( 0.084)\tLoss 2.9883e-01 (2.9883e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:3]Train:  Epoch: [2][  0/184]\tTime  0.933 ( 0.933)\tData  0.114 ( 0.114)\tLoss 6.5625e-01 (6.5625e-01)\tAcc@1  69.00 ( 69.00)\n",
      "[xla:7]Train:  Epoch: [2][  0/184]\tTime  0.769 ( 0.769)\tData  0.069 ( 0.069)\tLoss 4.3164e-01 (4.3164e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:4]Train:  Epoch: [2][  0/184]\tTime  0.721 ( 0.721)\tData  0.018 ( 0.018)\tLoss 3.4961e-01 (3.4961e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:2]Train:  Epoch: [2][  0/184]\tTime  0.621 ( 0.621)\tData  0.068 ( 0.068)\tLoss 1.6309e-01 (1.6309e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:6]Train:  Epoch: [2][  0/184]\tTime  0.619 ( 0.619)\tData  0.057 ( 0.057)\tLoss 2.5391e-01 (2.5391e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:1]Train:  Epoch: [2][ 30/184]\tTime  0.643 ( 0.875)\tData  0.037 ( 0.064)\tLoss 2.9297e-01 (3.4318e-01)\tAcc@1  94.00 ( 87.52)\n",
      "[xla:6]Train:  Epoch: [2][ 30/184]\tTime  0.559 ( 0.858)\tData  0.056 ( 0.067)\tLoss 4.6484e-01 (3.7249e-01)\tAcc@1  75.00 ( 85.07)\n",
      "[xla:4]Train:  Epoch: [2][ 30/184]\tTime  0.713 ( 0.867)\tData  0.052 ( 0.062)\tLoss 4.9414e-01 (3.3799e-01)\tAcc@1  87.50 ( 86.90)\n",
      "[xla:5]Train:  Epoch: [2][ 30/184]\tTime  0.746 ( 0.883)\tData  0.074 ( 0.070)\tLoss 3.0469e-01 (3.9995e-01)\tAcc@1  87.50 ( 85.29)\n",
      "[xla:7]Train:  Epoch: [2][ 30/184]\tTime  0.916 ( 0.873)\tData  0.050 ( 0.064)\tLoss 1.4844e-01 (3.2998e-01)\tAcc@1 100.00 ( 88.11)\n",
      "[xla:2]Train:  Epoch: [2][ 30/184]\tTime  1.121 ( 0.868)\tData  0.091 ( 0.068)\tLoss 8.5938e-02 (4.1592e-01)\tAcc@1 100.00 ( 84.63)\n",
      "[xla:3]Train:  Epoch: [2][ 30/184]\tTime  0.852 ( 0.882)\tData  0.048 ( 0.069)\tLoss 1.2988e-01 (4.2397e-01)\tAcc@1  94.00 ( 83.48)\n",
      "[xla:0]Train:  Epoch: [2][ 30/184]\tTime  0.851 ( 0.890)\tData  0.068 ( 0.072)\tLoss 2.2949e-01 (3.9422e-01)\tAcc@1  94.00 ( 85.06)\n",
      "[xla:4]Train:  Epoch: [2][ 60/184]\tTime  0.739 ( 0.849)\tData  0.041 ( 0.067)\tLoss 3.1641e-01 (3.3780e-01)\tAcc@1  94.00 ( 87.03)\n",
      "[xla:6]Train:  Epoch: [2][ 60/184]\tTime  0.753 ( 0.848)\tData  0.093 ( 0.067)\tLoss 3.6914e-01 (3.7969e-01)\tAcc@1  81.00 ( 84.83)\n",
      "[xla:0]Train:  Epoch: [2][ 60/184]\tTime  0.793 ( 0.860)\tData  0.094 ( 0.069)\tLoss 6.3672e-01 (3.8981e-01)\tAcc@1  75.00 ( 85.36)\n",
      "[xla:1]Train:  Epoch: [2][ 60/184]\tTime  0.822 ( 0.857)\tData  0.052 ( 0.065)\tLoss 5.8594e-01 (3.3671e-01)\tAcc@1  75.00 ( 87.44)\n",
      "[xla:2]Train:  Epoch: [2][ 60/184]\tTime  0.805 ( 0.850)\tData  0.079 ( 0.067)\tLoss 3.4961e-01 (4.0633e-01)\tAcc@1  81.00 ( 84.49)\n",
      "[xla:3]Train:  Epoch: [2][ 60/184]\tTime  0.867 ( 0.857)\tData  0.109 ( 0.066)\tLoss 4.5898e-01 (3.9786e-01)\tAcc@1  81.00 ( 84.11)\n",
      "[xla:5]Train:  Epoch: [2][ 60/184]\tTime  0.862 ( 0.860)\tData  0.058 ( 0.065)\tLoss 3.6719e-01 (3.6813e-01)\tAcc@1  94.00 ( 86.08)\n",
      "[xla:7]Train:  Epoch: [2][ 60/184]\tTime  0.875 ( 0.853)\tData  0.071 ( 0.062)\tLoss 1.8359e-01 (3.1733e-01)\tAcc@1  87.50 ( 87.29)\n",
      "[xla:1]Train:  Epoch: [2][ 90/184]\tTime  0.678 ( 0.862)\tData  0.041 ( 0.065)\tLoss 6.2500e-01 (3.4044e-01)\tAcc@1  69.00 ( 87.21)\n",
      "[xla:4]Train:  Epoch: [2][ 90/184]\tTime  0.691 ( 0.859)\tData  0.077 ( 0.067)\tLoss 1.1670e-01 (3.5489e-01)\tAcc@1  94.00 ( 86.10)\n",
      "[xla:2]Train:  Epoch: [2][ 90/184]\tTime  0.773 ( 0.859)\tData  0.087 ( 0.067)\tLoss 1.5234e-01 (3.9187e-01)\tAcc@1 100.00 ( 84.45)\n",
      "[xla:7]Train:  Epoch: [2][ 90/184]\tTime  0.795 ( 0.861)\tData  0.055 ( 0.065)\tLoss 2.5977e-01 (3.4022e-01)\tAcc@1  94.00 ( 86.53)\n",
      "[xla:0]Train:  Epoch: [2][ 90/184]\tTime  1.037 ( 0.866)\tData  0.083 ( 0.069)\tLoss 4.0039e-01 (3.6794e-01)\tAcc@1  81.00 ( 86.22)\n",
      "[xla:5]Train:  Epoch: [2][ 90/184]\tTime  1.032 ( 0.865)\tData  0.097 ( 0.067)\tLoss 3.3398e-01 (3.6163e-01)\tAcc@1  94.00 ( 86.27)\n",
      "[xla:3]Train:  Epoch: [2][ 90/184]\tTime  0.818 ( 0.864)\tData  0.060 ( 0.065)\tLoss 3.1445e-01 (3.8068e-01)\tAcc@1  81.00 ( 84.88)\n",
      "[xla:6]Train:  Epoch: [2][ 90/184]\tTime  0.854 ( 0.859)\tData  0.058 ( 0.066)\tLoss 4.3555e-01 (3.8527e-01)\tAcc@1  75.00 ( 84.75)\n",
      "[xla:3]Train:  Epoch: [2][120/184]\tTime  0.816 ( 0.857)\tData  0.047 ( 0.066)\tLoss 3.3594e-01 (3.6982e-01)\tAcc@1  94.00 ( 85.75)\n",
      "[xla:5]Train:  Epoch: [2][120/184]\tTime  0.792 ( 0.858)\tData  0.049 ( 0.067)\tLoss 3.2227e-01 (3.6416e-01)\tAcc@1  94.00 ( 86.17)\n",
      "[xla:0]Train:  Epoch: [2][120/184]\tTime  0.789 ( 0.859)\tData  0.053 ( 0.068)\tLoss 4.4727e-01 (3.7418e-01)\tAcc@1  87.50 ( 86.08)\n",
      "[xla:2]Train:  Epoch: [2][120/184]\tTime  0.789 ( 0.854)\tData  0.068 ( 0.066)\tLoss 1.6504e-01 (3.8562e-01)\tAcc@1 100.00 ( 85.05)\n",
      "[xla:6]Train:  Epoch: [2][120/184]\tTime  0.830 ( 0.853)\tData  0.060 ( 0.066)\tLoss 8.9355e-02 (3.8207e-01)\tAcc@1 100.00 ( 84.87)\n",
      "[xla:4]Train:  Epoch: [2][120/184]\tTime  0.881 ( 0.855)\tData  0.049 ( 0.066)\tLoss 7.2266e-01 (3.7386e-01)\tAcc@1  69.00 ( 85.78)\n",
      "[xla:7]Train:  Epoch: [2][120/184]\tTime  0.901 ( 0.856)\tData  0.054 ( 0.065)\tLoss 5.8594e-01 (3.4058e-01)\tAcc@1  75.00 ( 86.83)\n",
      "[xla:1]Train:  Epoch: [2][120/184]\tTime  0.875 ( 0.858)\tData  0.072 ( 0.065)\tLoss 1.1182e-01 (3.4758e-01)\tAcc@1 100.00 ( 87.09)\n",
      "[xla:4]Train:  Epoch: [2][150/184]\tTime  0.576 ( 0.856)\tData  0.047 ( 0.066)\tLoss 1.3184e-01 (3.5236e-01)\tAcc@1 100.00 ( 86.83)\n",
      "[xla:2]Train:  Epoch: [2][150/184]\tTime  0.869 ( 0.856)\tData  0.054 ( 0.066)\tLoss 2.3633e-01 (3.5908e-01)\tAcc@1  87.50 ( 86.25)\n",
      "[xla:3]Train:  Epoch: [2][150/184]\tTime  0.782 ( 0.859)\tData  0.050 ( 0.065)\tLoss 1.5137e-01 (3.4245e-01)\tAcc@1  94.00 ( 86.94)\n",
      "[xla:6]Train:  Epoch: [2][150/184]\tTime  0.873 ( 0.856)\tData  0.047 ( 0.067)\tLoss 1.3672e-01 (3.6202e-01)\tAcc@1  94.00 ( 85.89)\n",
      "[xla:1]Train:  Epoch: [2][150/184]\tTime  0.989 ( 0.859)\tData  0.085 ( 0.065)\tLoss 8.2520e-02 (3.1880e-01)\tAcc@1 100.00 ( 88.47)\n",
      "[xla:0]Train:  Epoch: [2][150/184]\tTime  0.835 ( 0.861)\tData  0.048 ( 0.067)\tLoss 1.3672e-01 (3.5063e-01)\tAcc@1  94.00 ( 87.12)\n",
      "[xla:5]Train:  Epoch: [2][150/184]\tTime  0.930 ( 0.860)\tData  0.052 ( 0.065)\tLoss 2.1387e-01 (3.4269e-01)\tAcc@1  94.00 ( 86.94)\n",
      "[xla:7]Train:  Epoch: [2][150/184]\tTime  0.869 ( 0.858)\tData  0.041 ( 0.065)\tLoss 1.1475e-01 (3.2873e-01)\tAcc@1  94.00 ( 87.22)\n",
      "[xla:2]Train:  Epoch: [2][180/184]\tTime  0.803 ( 0.852)\tData  0.049 ( 0.066)\tLoss 2.0508e-01 (3.3354e-01)\tAcc@1  87.50 ( 87.30)\n",
      "[xla:3]Train:  Epoch: [2][180/184]\tTime  0.941 ( 0.854)\tData  0.078 ( 0.065)\tLoss 3.8281e-01 (3.3070e-01)\tAcc@1  94.00 ( 87.94)\n",
      "[xla:6]Train:  Epoch: [2][180/184]\tTime  0.816 ( 0.852)\tData  0.065 ( 0.066)\tLoss 3.6719e-01 (3.4318e-01)\tAcc@1  81.00 ( 86.72)\n",
      "[xla:1]Train:  Epoch: [2][180/184]\tTime  0.805 ( 0.855)\tData  0.067 ( 0.064)\tLoss 1.0156e-01 (3.0338e-01)\tAcc@1 100.00 ( 89.04)\n",
      "[xla:7]Train:  Epoch: [2][180/184]\tTime  0.902 ( 0.853)\tData  0.041 ( 0.065)\tLoss 7.3438e-01 (3.2177e-01)\tAcc@1  87.50 ( 87.97)\n",
      "[xla:5]Train:  Epoch: [2][180/184]\tTime  0.844 ( 0.855)\tData  0.049 ( 0.064)\tLoss 2.9102e-01 (3.3424e-01)\tAcc@1  94.00 ( 87.41)\n",
      "[xla:4]Train:  Epoch: [2][180/184]\tTime  0.847 ( 0.853)\tData  0.064 ( 0.066)\tLoss 2.7734e-01 (3.3805e-01)\tAcc@1  87.50 ( 87.36)\n",
      "[xla:0]Train:  Epoch: [2][180/184]\tTime  0.849 ( 0.856)\tData  0.079 ( 0.066)\tLoss 4.6680e-01 (3.2992e-01)\tAcc@1  87.50 ( 88.02)\n",
      "[xla:3]Validation: [0/9]\tTime  0.434 ( 0.434)\tLoss 4.5703e-01 (4.5703e-01)\tAcc@1  81.00 ( 81.00)\n",
      "Finished training epoch 2\n",
      "[xla:6]Validation: [0/9]\tTime  0.206 ( 0.206)\tLoss 3.8574e-02 (3.8574e-02)\tAcc@1 100.00 (100.00)\n",
      "Parallel Loader Created. Validating ...\n",
      "[xla:1]Validation: [0/9]\tTime  0.298 ( 0.298)\tLoss 7.9297e-01 (7.9297e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:2]Validation: [0/9]\tTime  0.202 ( 0.202)\tLoss 3.6523e-01 (3.6523e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:0]Validation: [0/9]\tTime  0.218 ( 0.218)\tLoss 7.8906e-01 (7.8906e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:4]Validation: [0/9]\tTime  0.250 ( 0.250)\tLoss 2.7930e-01 (2.7930e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:7]Validation: [0/9]\tTime  0.187 ( 0.187)\tLoss 5.7422e-01 (5.7422e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:5]Validation: [0/9]\tTime  0.221 ( 0.221)\tLoss 1.8457e-01 (1.8457e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:3]Train:  Epoch: [3][  0/184]\tTime  0.649 ( 0.649)\tData  0.078 ( 0.078)\tLoss 2.4902e-01 (2.4902e-01)\tAcc@1  87.50 ( 87.50)\n",
      "Parallel Loader Created. Training ...\n",
      "[xla:6]Train:  Epoch: [3][  0/184]\tTime  0.719 ( 0.719)\tData  0.041 ( 0.041)\tLoss 4.1016e-01 (4.1016e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:1]Train:  Epoch: [3][  0/184]\tTime  0.679 ( 0.679)\tData  0.047 ( 0.047)\tLoss 3.3008e-01 (3.3008e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:2]Train:  Epoch: [3][  0/184]\tTime  0.760 ( 0.760)\tData  0.058 ( 0.058)\tLoss 7.1777e-02 (7.1777e-02)\tAcc@1 100.00 (100.00)\n",
      "[xla:4]Train:  Epoch: [3][  0/184]\tTime  0.729 ( 0.729)\tData  0.107 ( 0.107)\tLoss 4.3164e-01 (4.3164e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:7]Train:  Epoch: [3][  0/184]\tTime  0.553 ( 0.553)\tData  0.023 ( 0.023)\tLoss 5.4688e-01 (5.4688e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:5]Train:  Epoch: [3][  0/184]\tTime  0.476 ( 0.476)\tData  0.044 ( 0.044)\tLoss 1.9434e-01 (1.9434e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:0]Train:  Epoch: [3][  0/184]\tTime  0.561 ( 0.561)\tData  0.094 ( 0.094)\tLoss 3.5352e-01 (3.5352e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:4]Train:  Epoch: [3][ 30/184]\tTime  0.820 ( 0.870)\tData  0.082 ( 0.073)\tLoss 2.8516e-01 (3.7684e-01)\tAcc@1  87.50 ( 85.27)\n",
      "[xla:6]Train:  Epoch: [3][ 30/184]\tTime  0.840 ( 0.877)\tData  0.057 ( 0.060)\tLoss 4.9414e-01 (3.1408e-01)\tAcc@1  81.00 ( 88.11)\n",
      "[xla:3]Train:  Epoch: [3][ 30/184]\tTime  1.070 ( 0.890)\tData  0.088 ( 0.071)\tLoss 7.0801e-02 (3.3836e-01)\tAcc@1 100.00 ( 88.53)\n",
      "[xla:5]Train:  Epoch: [3][ 30/184]\tTime  0.931 ( 0.861)\tData  0.055 ( 0.064)\tLoss 1.2598e-01 (3.5304e-01)\tAcc@1 100.00 ( 87.53)\n",
      "[xla:7]Train:  Epoch: [3][ 30/184]\tTime  0.930 ( 0.863)\tData  0.056 ( 0.066)\tLoss 2.3535e-01 (3.1396e-01)\tAcc@1  87.50 ( 88.15)\n",
      "[xla:0]Train:  Epoch: [3][ 30/184]\tTime  0.912 ( 0.864)\tData  0.058 ( 0.064)\tLoss 1.9336e-01 (3.6013e-01)\tAcc@1  94.00 ( 87.55)\n",
      "[xla:1]Train:  Epoch: [3][ 30/184]\tTime  0.885 ( 0.873)\tData  0.074 ( 0.063)\tLoss 3.7305e-01 (3.1587e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:2]Train:  Epoch: [3][ 30/184]\tTime  0.917 ( 0.875)\tData  0.058 ( 0.062)\tLoss 1.1182e-01 (3.8753e-01)\tAcc@1  94.00 ( 86.05)\n",
      "[xla:7]Train:  Epoch: [3][ 60/184]\tTime  0.661 ( 0.861)\tData  0.044 ( 0.066)\tLoss 2.8711e-01 (3.2105e-01)\tAcc@1  87.50 ( 87.52)\n",
      "[xla:3]Train:  Epoch: [3][ 60/184]\tTime  0.748 ( 0.877)\tData  0.083 ( 0.072)\tLoss 2.0117e-01 (3.3940e-01)\tAcc@1  94.00 ( 87.93)\n",
      "[xla:2]Train:  Epoch: [3][ 60/184]\tTime  0.835 ( 0.870)\tData  0.120 ( 0.065)\tLoss 2.4805e-01 (3.8590e-01)\tAcc@1  87.50 ( 85.23)\n",
      "[xla:4]Train:  Epoch: [3][ 60/184]\tTime  0.804 ( 0.869)\tData  0.091 ( 0.070)\tLoss 2.6172e-01 (3.4268e-01)\tAcc@1  81.00 ( 87.23)\n",
      "[xla:6]Train:  Epoch: [3][ 60/184]\tTime  0.872 ( 0.872)\tData  0.047 ( 0.065)\tLoss 2.8906e-01 (3.3325e-01)\tAcc@1  81.00 ( 87.80)\n",
      "[xla:1]Train:  Epoch: [3][ 60/184]\tTime  0.851 ( 0.869)\tData  0.083 ( 0.069)\tLoss 1.0078e+00 (3.3068e-01)\tAcc@1  56.25 ( 85.75)\n",
      "[xla:5]Train:  Epoch: [3][ 60/184]\tTime  0.865 ( 0.864)\tData  0.107 ( 0.068)\tLoss 4.1797e-01 (3.3229e-01)\tAcc@1  87.50 ( 88.15)\n",
      "[xla:0]Train:  Epoch: [3][ 60/184]\tTime  0.868 ( 0.865)\tData  0.105 ( 0.065)\tLoss 5.0391e-01 (3.7170e-01)\tAcc@1  75.00 ( 86.82)\n",
      "[xla:7]Train:  Epoch: [3][ 90/184]\tTime  0.676 ( 0.858)\tData  0.045 ( 0.067)\tLoss 2.7539e-01 (3.3667e-01)\tAcc@1  87.50 ( 87.25)\n",
      "[xla:4]Train:  Epoch: [3][ 90/184]\tTime  0.786 ( 0.863)\tData  0.087 ( 0.069)\tLoss 3.8867e-01 (3.4826e-01)\tAcc@1  75.00 ( 87.25)\n",
      "[xla:5]Train:  Epoch: [3][ 90/184]\tTime  0.827 ( 0.859)\tData  0.101 ( 0.065)\tLoss 1.7871e-01 (3.2450e-01)\tAcc@1  94.00 ( 88.00)\n",
      "[xla:2]Train:  Epoch: [3][ 90/184]\tTime  0.814 ( 0.864)\tData  0.091 ( 0.066)\tLoss 1.6895e-01 (3.6485e-01)\tAcc@1 100.00 ( 85.98)\n",
      "[xla:1]Train:  Epoch: [3][ 90/184]\tTime  0.798 ( 0.864)\tData  0.093 ( 0.068)\tLoss 4.3750e-01 (3.3233e-01)\tAcc@1  94.00 ( 86.55)\n",
      "[xla:3]Train:  Epoch: [3][ 90/184]\tTime  0.843 ( 0.870)\tData  0.072 ( 0.070)\tLoss 3.7891e-01 (3.3712e-01)\tAcc@1  94.00 ( 87.74)\n",
      "[xla:6]Train:  Epoch: [3][ 90/184]\tTime  0.839 ( 0.866)\tData  0.057 ( 0.064)\tLoss 3.6328e-01 (3.4624e-01)\tAcc@1  87.50 ( 87.02)\n",
      "[xla:0]Train:  Epoch: [3][ 90/184]\tTime  1.000 ( 0.861)\tData  0.063 ( 0.063)\tLoss 2.8125e-01 (3.5245e-01)\tAcc@1  94.00 ( 87.27)\n",
      "[xla:2]Train:  Epoch: [3][120/184]\tTime  0.700 ( 0.863)\tData  0.054 ( 0.066)\tLoss 2.0605e-01 (3.5761e-01)\tAcc@1  94.00 ( 86.74)\n",
      "[xla:0]Train:  Epoch: [3][120/184]\tTime  0.702 ( 0.861)\tData  0.054 ( 0.064)\tLoss 3.9062e-01 (3.5431e-01)\tAcc@1  87.50 ( 86.50)\n",
      "[xla:1]Train:  Epoch: [3][120/184]\tTime  0.733 ( 0.864)\tData  0.076 ( 0.068)\tLoss 2.0605e-01 (3.4073e-01)\tAcc@1  94.00 ( 86.23)\n",
      "[xla:6]Train:  Epoch: [3][120/184]\tTime  0.840 ( 0.866)\tData  0.051 ( 0.066)\tLoss 1.0303e-01 (3.6220e-01)\tAcc@1 100.00 ( 86.46)\n",
      "[xla:7]Train:  Epoch: [3][120/184]\tTime  0.945 ( 0.862)\tData  0.052 ( 0.068)\tLoss 4.1992e-01 (3.3481e-01)\tAcc@1  75.00 ( 87.52)\n",
      "[xla:3]Train:  Epoch: [3][120/184]\tTime  0.881 ( 0.869)\tData  0.059 ( 0.069)\tLoss 4.1016e-01 (3.3750e-01)\tAcc@1  94.00 ( 87.72)\n",
      "[xla:4]Train:  Epoch: [3][120/184]\tTime  0.839 ( 0.865)\tData  0.070 ( 0.070)\tLoss 7.6953e-01 (3.5900e-01)\tAcc@1  69.00 ( 86.90)\n",
      "[xla:5]Train:  Epoch: [3][120/184]\tTime  0.849 ( 0.862)\tData  0.054 ( 0.066)\tLoss 2.2559e-01 (3.3667e-01)\tAcc@1  94.00 ( 87.48)\n",
      "[xla:7]Train:  Epoch: [3][150/184]\tTime  0.982 ( 0.858)\tData  0.086 ( 0.067)\tLoss 2.0020e-01 (3.2068e-01)\tAcc@1  87.50 ( 87.82)\n",
      "[xla:3]Train:  Epoch: [3][150/184]\tTime  0.810 ( 0.864)\tData  0.052 ( 0.067)\tLoss 7.1777e-02 (3.1813e-01)\tAcc@1 100.00 ( 88.31)\n",
      "[xla:5]Train:  Epoch: [3][150/184]\tTime  0.767 ( 0.858)\tData  0.054 ( 0.066)\tLoss 2.5781e-01 (3.1804e-01)\tAcc@1  87.50 ( 88.16)\n",
      "[xla:0]Train:  Epoch: [3][150/184]\tTime  0.789 ( 0.859)\tData  0.062 ( 0.063)\tLoss 2.1582e-01 (3.3565e-01)\tAcc@1  94.00 ( 87.25)\n",
      "[xla:1]Train:  Epoch: [3][150/184]\tTime  0.833 ( 0.861)\tData  0.051 ( 0.067)\tLoss 1.5527e-01 (3.1651e-01)\tAcc@1  94.00 ( 87.69)\n",
      "[xla:6]Train:  Epoch: [3][150/184]\tTime  0.843 ( 0.862)\tData  0.069 ( 0.065)\tLoss 1.3379e-01 (3.4482e-01)\tAcc@1  94.00 ( 87.26)\n",
      "[xla:4]Train:  Epoch: [3][150/184]\tTime  0.861 ( 0.861)\tData  0.084 ( 0.069)\tLoss 2.4023e-01 (3.4214e-01)\tAcc@1  94.00 ( 87.86)\n",
      "[xla:2]Train:  Epoch: [3][150/184]\tTime  0.860 ( 0.861)\tData  0.073 ( 0.066)\tLoss 1.7773e-01 (3.3455e-01)\tAcc@1  94.00 ( 87.77)\n",
      "[xla:5]Train:  Epoch: [3][180/184]\tTime  0.804 ( 0.859)\tData  0.096 ( 0.066)\tLoss 4.0234e-01 (3.0315e-01)\tAcc@1  87.50 ( 88.85)\n",
      "[xla:6]Train:  Epoch: [3][180/184]\tTime  0.812 ( 0.862)\tData  0.071 ( 0.065)\tLoss 4.2969e-01 (3.2575e-01)\tAcc@1  87.50 ( 87.89)\n",
      "[xla:1]Train:  Epoch: [3][180/184]\tTime  0.817 ( 0.861)\tData  0.101 ( 0.067)\tLoss 1.2109e-01 (2.9435e-01)\tAcc@1  94.00 ( 88.68)\n",
      "[xla:3]Train:  Epoch: [3][180/184]\tTime  0.817 ( 0.865)\tData  0.064 ( 0.067)\tLoss 2.4512e-01 (3.0901e-01)\tAcc@1  87.50 ( 88.84)\n",
      "[xla:4]Train:  Epoch: [3][180/184]\tTime  0.893 ( 0.862)\tData  0.051 ( 0.068)\tLoss 3.4180e-01 (3.2765e-01)\tAcc@1  87.50 ( 88.44)\n",
      "[xla:2]Train:  Epoch: [3][180/184]\tTime  0.830 ( 0.862)\tData  0.063 ( 0.065)\tLoss 1.7773e-01 (3.0913e-01)\tAcc@1  94.00 ( 88.78)\n",
      "[xla:7]Train:  Epoch: [3][180/184]\tTime  0.806 ( 0.860)\tData  0.053 ( 0.066)\tLoss 4.2383e-01 (3.1282e-01)\tAcc@1  87.50 ( 88.22)\n",
      "[xla:0]Train:  Epoch: [3][180/184]\tTime  0.907 ( 0.860)\tData  0.059 ( 0.063)\tLoss 1.7676e-01 (3.0792e-01)\tAcc@1  94.00 ( 88.52)\n",
      "[xla:6]Validation: [0/9]\tTime  0.243 ( 0.243)\tLoss 4.5898e-02 (4.5898e-02)\tAcc@1 100.00 (100.00)\n",
      "Finished training epoch 3\n",
      "[xla:5]Validation: [0/9]\tTime  0.220 ( 0.220)\tLoss 1.6309e-01 (1.6309e-01)\tAcc@1  94.00 ( 94.00)\n",
      "Parallel Loader Created. Validating ...\n",
      "[xla:3]Validation: [0/9]\tTime  0.261 ( 0.261)\tLoss 5.3906e-01 (5.3906e-01)\tAcc@1  75.00 ( 75.00)\n",
      "[xla:0]Validation: [0/9]\tTime  0.224 ( 0.224)\tLoss 7.6953e-01 (7.6953e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:2]Validation: [0/9]\tTime  0.271 ( 0.271)\tLoss 4.0820e-01 (4.0820e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:7]Validation: [0/9]\tTime  0.203 ( 0.203)\tLoss 5.9375e-01 (5.9375e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:1]Validation: [0/9]\tTime  0.276 ( 0.276)\tLoss 8.0859e-01 (8.0859e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:4]Validation: [0/9]\tTime  0.268 ( 0.268)\tLoss 3.1055e-01 (3.1055e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:6]Train:  Epoch: [4][  0/184]\tTime  0.552 ( 0.552)\tData  0.036 ( 0.036)\tLoss 3.3008e-01 (3.3008e-01)\tAcc@1  94.00 ( 94.00)\n",
      "Parallel Loader Created. Training ...\n",
      "[xla:5]Train:  Epoch: [4][  0/184]\tTime  0.822 ( 0.822)\tData  0.095 ( 0.095)\tLoss 1.0059e-01 (1.0059e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:1]Train:  Epoch: [4][  0/184]\tTime  0.749 ( 0.749)\tData  0.037 ( 0.037)\tLoss 3.1641e-01 (3.1641e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:3]Train:  Epoch: [4][  0/184]\tTime  0.586 ( 0.586)\tData  0.058 ( 0.058)\tLoss 1.5723e-01 (1.5723e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:2]Train:  Epoch: [4][  0/184]\tTime  0.777 ( 0.777)\tData  0.089 ( 0.089)\tLoss 2.4805e-01 (2.4805e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:0]Train:  Epoch: [4][  0/184]\tTime  0.650 ( 0.650)\tData  0.128 ( 0.128)\tLoss 5.8594e-01 (5.8594e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:4]Train:  Epoch: [4][  0/184]\tTime  0.543 ( 0.543)\tData  0.069 ( 0.069)\tLoss 2.8516e-01 (2.8516e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:7]Train:  Epoch: [4][  0/184]\tTime  0.532 ( 0.532)\tData  0.113 ( 0.113)\tLoss 2.1484e-01 (2.1484e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:4]Train:  Epoch: [4][ 30/184]\tTime  0.818 ( 0.846)\tData  0.063 ( 0.076)\tLoss 3.7891e-01 (2.8905e-01)\tAcc@1  81.00 ( 87.71)\n",
      "[xla:0]Train:  Epoch: [4][ 30/184]\tTime  0.950 ( 0.850)\tData  0.060 ( 0.066)\tLoss 2.3047e-01 (3.4668e-01)\tAcc@1  87.50 ( 87.90)\n",
      "[xla:2]Train:  Epoch: [4][ 30/184]\tTime  0.813 ( 0.856)\tData  0.070 ( 0.062)\tLoss 5.3467e-02 (3.6622e-01)\tAcc@1 100.00 ( 87.68)\n",
      "[xla:5]Train:  Epoch: [4][ 30/184]\tTime  0.841 ( 0.873)\tData  0.057 ( 0.074)\tLoss 1.7578e-01 (3.6801e-01)\tAcc@1  94.00 ( 87.15)\n",
      "[xla:1]Train:  Epoch: [4][ 30/184]\tTime  0.883 ( 0.859)\tData  0.046 ( 0.068)\tLoss 4.0039e-01 (3.1751e-01)\tAcc@1  94.00 ( 88.35)\n",
      "[xla:6]Train:  Epoch: [4][ 30/184]\tTime  0.914 ( 0.871)\tData  0.046 ( 0.064)\tLoss 3.0469e-01 (3.2516e-01)\tAcc@1  87.50 ( 87.11)\n",
      "[xla:3]Train:  Epoch: [4][ 30/184]\tTime  0.874 ( 0.854)\tData  0.057 ( 0.070)\tLoss 2.1973e-01 (3.4996e-01)\tAcc@1  87.50 ( 88.95)\n",
      "[xla:7]Train:  Epoch: [4][ 30/184]\tTime  0.874 ( 0.846)\tData  0.077 ( 0.068)\tLoss 8.8379e-02 (2.7404e-01)\tAcc@1 100.00 ( 90.32)\n",
      "[xla:2]Train:  Epoch: [4][ 60/184]\tTime  0.915 ( 0.864)\tData  0.061 ( 0.065)\tLoss 3.3008e-01 (3.6212e-01)\tAcc@1  87.50 ( 86.67)\n",
      "[xla:1]Train:  Epoch: [4][ 60/184]\tTime  0.844 ( 0.865)\tData  0.047 ( 0.068)\tLoss 7.8906e-01 (3.1216e-01)\tAcc@1  69.00 ( 88.77)\n",
      "[xla:7]Train:  Epoch: [4][ 60/184]\tTime  0.875 ( 0.858)\tData  0.044 ( 0.068)\tLoss 1.9141e-01 (2.8492e-01)\tAcc@1  87.50 ( 89.66)\n",
      "[xla:0]Train:  Epoch: [4][ 60/184]\tTime  0.823 ( 0.862)\tData  0.052 ( 0.066)\tLoss 8.3594e-01 (3.6679e-01)\tAcc@1  69.00 ( 86.48)\n",
      "[xla:5]Train:  Epoch: [4][ 60/184]\tTime  0.828 ( 0.873)\tData  0.053 ( 0.069)\tLoss 4.6094e-01 (3.5120e-01)\tAcc@1  87.50 ( 86.84)\n",
      "[xla:6]Train:  Epoch: [4][ 60/184]\tTime  0.829 ( 0.872)\tData  0.070 ( 0.067)\tLoss 4.7461e-01 (3.4745e-01)\tAcc@1  75.00 ( 85.86)\n",
      "[xla:3]Train:  Epoch: [4][ 60/184]\tTime  0.842 ( 0.863)\tData  0.052 ( 0.068)\tLoss 3.6133e-01 (3.4807e-01)\tAcc@1  81.00 ( 87.11)\n",
      "[xla:4]Train:  Epoch: [4][ 60/184]\tTime  0.875 ( 0.860)\tData  0.076 ( 0.071)\tLoss 1.1279e-01 (3.0710e-01)\tAcc@1  94.00 ( 87.41)\n",
      "[xla:5]Train:  Epoch: [4][ 90/184]\tTime  0.785 ( 0.865)\tData  0.064 ( 0.068)\tLoss 1.6797e-01 (3.4130e-01)\tAcc@1 100.00 ( 87.28)\n",
      "[xla:7]Train:  Epoch: [4][ 90/184]\tTime  0.856 ( 0.855)\tData  0.048 ( 0.065)\tLoss 1.1719e-01 (3.0892e-01)\tAcc@1  94.00 ( 88.62)\n",
      "[xla:2]Train:  Epoch: [4][ 90/184]\tTime  0.856 ( 0.859)\tData  0.053 ( 0.064)\tLoss 2.1289e-01 (3.4377e-01)\tAcc@1  94.00 ( 87.58)\n",
      "[xla:0]Train:  Epoch: [4][ 90/184]\tTime  0.969 ( 0.858)\tData  0.064 ( 0.067)\tLoss 3.0469e-01 (3.4229e-01)\tAcc@1  94.00 ( 87.31)\n",
      "[xla:6]Train:  Epoch: [4][ 90/184]\tTime  0.843 ( 0.864)\tData  0.054 ( 0.066)\tLoss 5.5078e-01 (3.5660e-01)\tAcc@1  81.00 ( 86.13)\n",
      "[xla:4]Train:  Epoch: [4][ 90/184]\tTime  0.899 ( 0.857)\tData  0.054 ( 0.069)\tLoss 8.9844e-02 (3.1786e-01)\tAcc@1 100.00 ( 88.20)\n",
      "[xla:3]Train:  Epoch: [4][ 90/184]\tTime  0.845 ( 0.859)\tData  0.054 ( 0.066)\tLoss 2.9297e-01 (3.3399e-01)\tAcc@1  94.00 ( 87.46)\n",
      "[xla:1]Train:  Epoch: [4][ 90/184]\tTime  0.832 ( 0.861)\tData  0.054 ( 0.067)\tLoss 3.4961e-01 (3.1540e-01)\tAcc@1  94.00 ( 88.49)\n",
      "[xla:5]Train:  Epoch: [4][120/184]\tTime  0.720 ( 0.866)\tData  0.057 ( 0.066)\tLoss 2.7344e-01 (3.5171e-01)\tAcc@1  94.00 ( 86.61)\n",
      "[xla:6]Train:  Epoch: [4][120/184]\tTime  0.744 ( 0.866)\tData  0.053 ( 0.066)\tLoss 8.3008e-02 (3.6141e-01)\tAcc@1 100.00 ( 85.71)\n",
      "[xla:2]Train:  Epoch: [4][120/184]\tTime  0.849 ( 0.862)\tData  0.089 ( 0.066)\tLoss 1.2598e-01 (3.4311e-01)\tAcc@1 100.00 ( 87.83)\n",
      "[xla:1]Train:  Epoch: [4][120/184]\tTime  0.868 ( 0.864)\tData  0.085 ( 0.067)\tLoss 1.6602e-01 (3.2153e-01)\tAcc@1 100.00 ( 88.05)\n",
      "[xla:0]Train:  Epoch: [4][120/184]\tTime  0.927 ( 0.861)\tData  0.082 ( 0.067)\tLoss 4.7070e-01 (3.4352e-01)\tAcc@1  87.50 ( 87.40)\n",
      "[xla:7]Train:  Epoch: [4][120/184]\tTime  0.991 ( 0.860)\tData  0.069 ( 0.065)\tLoss 5.7422e-01 (3.0683e-01)\tAcc@1  81.00 ( 88.86)\n",
      "[xla:4]Train:  Epoch: [4][120/184]\tTime  0.924 ( 0.861)\tData  0.071 ( 0.069)\tLoss 4.9609e-01 (3.2899e-01)\tAcc@1  87.50 ( 87.83)\n",
      "[xla:3]Train:  Epoch: [4][120/184]\tTime  0.950 ( 0.862)\tData  0.070 ( 0.066)\tLoss 4.7266e-01 (3.3357e-01)\tAcc@1  94.00 ( 87.94)\n",
      "[xla:7]Train:  Epoch: [4][150/184]\tTime  0.781 ( 0.858)\tData  0.090 ( 0.065)\tLoss 1.5918e-01 (2.9155e-01)\tAcc@1  94.00 ( 89.34)\n",
      "[xla:0]Train:  Epoch: [4][150/184]\tTime  0.807 ( 0.859)\tData  0.054 ( 0.067)\tLoss 2.3145e-01 (3.2913e-01)\tAcc@1  94.00 ( 87.90)\n",
      "[xla:4]Train:  Epoch: [4][150/184]\tTime  0.879 ( 0.859)\tData  0.056 ( 0.067)\tLoss 1.4746e-01 (3.1752e-01)\tAcc@1 100.00 ( 88.34)\n",
      "[xla:1]Train:  Epoch: [4][150/184]\tTime  0.878 ( 0.861)\tData  0.053 ( 0.067)\tLoss 1.4551e-01 (2.9742e-01)\tAcc@1  94.00 ( 89.12)\n",
      "[xla:2]Train:  Epoch: [4][150/184]\tTime  0.902 ( 0.861)\tData  0.057 ( 0.065)\tLoss 2.9883e-01 (3.3213e-01)\tAcc@1  94.00 ( 88.48)\n",
      "[xla:3]Train:  Epoch: [4][150/184]\tTime  0.831 ( 0.860)\tData  0.055 ( 0.065)\tLoss 1.5918e-01 (3.1672e-01)\tAcc@1  94.00 ( 88.41)\n",
      "[xla:6]Train:  Epoch: [4][150/184]\tTime  0.854 ( 0.864)\tData  0.063 ( 0.066)\tLoss 5.9326e-02 (3.4007e-01)\tAcc@1 100.00 ( 86.87)\n",
      "[xla:5]Train:  Epoch: [4][150/184]\tTime  0.852 ( 0.864)\tData  0.076 ( 0.066)\tLoss 3.4961e-01 (3.3263e-01)\tAcc@1  81.00 ( 87.59)\n",
      "[xla:0]Train:  Epoch: [4][180/184]\tTime  0.821 ( 0.861)\tData  0.064 ( 0.068)\tLoss 2.0703e-01 (3.1097e-01)\tAcc@1  94.00 ( 88.64)\n",
      "[xla:2]Train:  Epoch: [4][180/184]\tTime  0.765 ( 0.862)\tData  0.091 ( 0.065)\tLoss 2.6953e-01 (3.0958e-01)\tAcc@1  94.00 ( 89.12)\n",
      "[xla:7]Train:  Epoch: [4][180/184]\tTime  0.888 ( 0.860)\tData  0.057 ( 0.066)\tLoss 5.0000e-01 (2.8489e-01)\tAcc@1  81.00 ( 89.60)\n",
      "[xla:5]Train:  Epoch: [4][180/184]\tTime  0.884 ( 0.865)\tData  0.098 ( 0.068)\tLoss 4.5312e-01 (3.1839e-01)\tAcc@1  81.00 ( 88.13)\n",
      "[xla:1]Train:  Epoch: [4][180/184]\tTime  1.121 ( 0.863)\tData  0.073 ( 0.067)\tLoss 8.7402e-02 (2.8154e-01)\tAcc@1 100.00 ( 89.69)\n",
      "[xla:4]Train:  Epoch: [4][180/184]\tTime  1.023 ( 0.861)\tData  0.057 ( 0.068)\tLoss 1.1279e-01 (3.0229e-01)\tAcc@1 100.00 ( 89.04)\n",
      "[xla:3]Train:  Epoch: [4][180/184]\tTime  0.921 ( 0.862)\tData  0.097 ( 0.065)\tLoss 1.7188e-01 (3.0750e-01)\tAcc@1  87.50 ( 88.62)\n",
      "[xla:6]Train:  Epoch: [4][180/184]\tTime  0.943 ( 0.865)\tData  0.073 ( 0.067)\tLoss 4.3555e-01 (3.1883e-01)\tAcc@1  81.00 ( 87.71)\n",
      "Finished training epoch 4\n",
      "Parallel Loader Created. Validating ...\n",
      "[xla:2]Validation: [0/9]\tTime  0.219 ( 0.219)\tLoss 3.9062e-01 (3.9062e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:4]Validation: [0/9]\tTime  0.275 ( 0.275)\tLoss 2.6758e-01 (2.6758e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:1]Validation: [0/9]\tTime  0.308 ( 0.308)\tLoss 6.9141e-01 (6.9141e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:0]Validation: [0/9]\tTime  0.434 ( 0.434)\tLoss 8.9453e-01 (8.9453e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:3]Validation: [0/9]\tTime  0.258 ( 0.258)\tLoss 5.0781e-01 (5.0781e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:5]Validation: [0/9]\tTime  0.329 ( 0.329)\tLoss 2.1973e-01 (2.1973e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:7]Validation: [0/9]\tTime  0.243 ( 0.243)\tLoss 5.1953e-01 (5.1953e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:6]Validation: [0/9]\tTime  0.253 ( 0.253)\tLoss 4.7607e-02 (4.7607e-02)\tAcc@1 100.00 (100.00)\n",
      "Parallel Loader Created. Training ...\n",
      "[xla:2]Train:  Epoch: [5][  0/184]\tTime  0.870 ( 0.870)\tData  0.065 ( 0.065)\tLoss 5.3467e-02 (5.3467e-02)\tAcc@1 100.00 (100.00)\n",
      "[xla:4]Train:  Epoch: [5][  0/184]\tTime  0.708 ( 0.708)\tData  0.106 ( 0.106)\tLoss 3.0469e-01 (3.0469e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:7]Train:  Epoch: [5][  0/184]\tTime  0.688 ( 0.688)\tData  0.046 ( 0.046)\tLoss 5.3516e-01 (5.3516e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:0]Train:  Epoch: [5][  0/184]\tTime  0.770 ( 0.770)\tData  0.050 ( 0.050)\tLoss 3.6523e-01 (3.6523e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:5]Train:  Epoch: [5][  0/184]\tTime  0.820 ( 0.820)\tData  0.055 ( 0.055)\tLoss 1.1914e-01 (1.1914e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:1]Train:  Epoch: [5][  0/184]\tTime  0.750 ( 0.750)\tData  0.055 ( 0.055)\tLoss 3.2812e-01 (3.2812e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:6]Train:  Epoch: [5][  0/184]\tTime  0.538 ( 0.538)\tData  0.039 ( 0.039)\tLoss 4.9414e-01 (4.9414e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:3]Train:  Epoch: [5][  0/184]\tTime  0.602 ( 0.602)\tData  0.091 ( 0.091)\tLoss 1.7188e-01 (1.7188e-01)\tAcc@1 100.00 (100.00)\n",
      "[xla:0]Train:  Epoch: [5][ 30/184]\tTime  0.708 ( 0.865)\tData  0.053 ( 0.068)\tLoss 1.9434e-01 (3.5248e-01)\tAcc@1  94.00 ( 87.95)\n",
      "[xla:2]Train:  Epoch: [5][ 30/184]\tTime  0.949 ( 0.880)\tData  0.104 ( 0.068)\tLoss 9.6191e-02 (3.3461e-01)\tAcc@1 100.00 ( 89.15)\n",
      "[xla:5]Train:  Epoch: [5][ 30/184]\tTime  0.815 ( 0.867)\tData  0.044 ( 0.072)\tLoss 1.7285e-01 (3.3203e-01)\tAcc@1  94.00 ( 88.95)\n",
      "[xla:4]Train:  Epoch: [5][ 30/184]\tTime  0.940 ( 0.868)\tData  0.065 ( 0.068)\tLoss 4.9805e-01 (3.1727e-01)\tAcc@1  81.00 ( 87.71)\n",
      "[xla:6]Train:  Epoch: [5][ 30/184]\tTime  0.824 ( 0.855)\tData  0.055 ( 0.067)\tLoss 3.2031e-01 (3.0543e-01)\tAcc@1  75.00 ( 87.40)\n",
      "[xla:3]Train:  Epoch: [5][ 30/184]\tTime  0.846 ( 0.858)\tData  0.049 ( 0.065)\tLoss 2.1777e-01 (3.2227e-01)\tAcc@1  94.00 ( 88.34)\n",
      "[xla:1]Train:  Epoch: [5][ 30/184]\tTime  0.821 ( 0.865)\tData  0.054 ( 0.064)\tLoss 5.2734e-01 (3.2727e-01)\tAcc@1  87.50 ( 87.95)\n",
      "[xla:7]Train:  Epoch: [5][ 30/184]\tTime  0.927 ( 0.868)\tData  0.044 ( 0.064)\tLoss 3.8818e-02 (2.7025e-01)\tAcc@1 100.00 ( 89.71)\n",
      "[xla:5]Train:  Epoch: [5][ 60/184]\tTime  0.799 ( 0.866)\tData  0.060 ( 0.069)\tLoss 3.8867e-01 (2.9901e-01)\tAcc@1  87.50 ( 89.87)\n",
      "[xla:7]Train:  Epoch: [5][ 60/184]\tTime  0.793 ( 0.866)\tData  0.069 ( 0.066)\tLoss 5.3711e-02 (2.7935e-01)\tAcc@1 100.00 ( 89.47)\n",
      "[xla:2]Train:  Epoch: [5][ 60/184]\tTime  0.808 ( 0.875)\tData  0.056 ( 0.068)\tLoss 2.7539e-01 (3.4719e-01)\tAcc@1  81.00 ( 88.15)\n",
      "[xla:1]Train:  Epoch: [5][ 60/184]\tTime  0.889 ( 0.866)\tData  0.060 ( 0.067)\tLoss 5.9766e-01 (3.1627e-01)\tAcc@1  69.00 ( 88.06)\n",
      "[xla:4]Train:  Epoch: [5][ 60/184]\tTime  0.885 ( 0.868)\tData  0.078 ( 0.068)\tLoss 1.7480e-01 (3.0273e-01)\tAcc@1  87.50 ( 88.12)\n",
      "[xla:3]Train:  Epoch: [5][ 60/184]\tTime  0.954 ( 0.863)\tData  0.069 ( 0.067)\tLoss 3.1250e-01 (3.1519e-01)\tAcc@1  81.00 ( 87.92)\n",
      "[xla:6]Train:  Epoch: [5][ 60/184]\tTime  0.888 ( 0.862)\tData  0.072 ( 0.072)\tLoss 3.6719e-01 (3.0165e-01)\tAcc@1  87.50 ( 87.46)\n",
      "[xla:0]Train:  Epoch: [5][ 60/184]\tTime  0.972 ( 0.869)\tData  0.084 ( 0.065)\tLoss 7.6953e-01 (3.5483e-01)\tAcc@1  69.00 ( 87.73)\n",
      "[xla:7]Train:  Epoch: [5][ 90/184]\tTime  0.502 ( 0.868)\tData  0.048 ( 0.065)\tLoss 1.9434e-01 (3.0610e-01)\tAcc@1  94.00 ( 88.27)\n",
      "[xla:4]Train:  Epoch: [5][ 90/184]\tTime  0.874 ( 0.872)\tData  0.047 ( 0.067)\tLoss 2.1582e-01 (3.0527e-01)\tAcc@1  94.00 ( 88.14)\n",
      "[xla:3]Train:  Epoch: [5][ 90/184]\tTime  0.838 ( 0.869)\tData  0.047 ( 0.066)\tLoss 3.5156e-01 (3.1440e-01)\tAcc@1  81.00 ( 87.79)\n",
      "[xla:2]Train:  Epoch: [5][ 90/184]\tTime  0.985 ( 0.877)\tData  0.061 ( 0.068)\tLoss 2.4902e-01 (3.3391e-01)\tAcc@1  87.50 ( 88.35)\n",
      "[xla:6]Train:  Epoch: [5][ 90/184]\tTime  0.844 ( 0.868)\tData  0.053 ( 0.073)\tLoss 3.4766e-01 (3.3060e-01)\tAcc@1  87.50 ( 86.80)\n",
      "[xla:0]Train:  Epoch: [5][ 90/184]\tTime  0.849 ( 0.872)\tData  0.055 ( 0.064)\tLoss 4.5117e-01 (3.3837e-01)\tAcc@1  87.50 ( 87.94)\n",
      "[xla:1]Train:  Epoch: [5][ 90/184]\tTime  0.901 ( 0.871)\tData  0.045 ( 0.066)\tLoss 4.4727e-01 (3.1709e-01)\tAcc@1  87.50 ( 87.81)\n",
      "[xla:5]Train:  Epoch: [5][ 90/184]\tTime  0.957 ( 0.873)\tData  0.051 ( 0.070)\tLoss 2.0312e-01 (3.0195e-01)\tAcc@1  94.00 ( 89.23)\n",
      "[xla:2]Train:  Epoch: [5][120/184]\tTime  0.742 ( 0.874)\tData  0.070 ( 0.069)\tLoss 2.5391e-01 (3.3378e-01)\tAcc@1  94.00 ( 88.31)\n",
      "[xla:7]Train:  Epoch: [5][120/184]\tTime  0.771 ( 0.870)\tData  0.048 ( 0.067)\tLoss 4.6875e-01 (3.1266e-01)\tAcc@1  75.00 ( 88.13)\n",
      "[xla:3]Train:  Epoch: [5][120/184]\tTime  0.854 ( 0.867)\tData  0.055 ( 0.067)\tLoss 2.4512e-01 (3.1491e-01)\tAcc@1  94.00 ( 88.36)\n",
      "[xla:4]Train:  Epoch: [5][120/184]\tTime  0.785 ( 0.871)\tData  0.052 ( 0.066)\tLoss 5.5859e-01 (3.2172e-01)\tAcc@1  81.00 ( 87.58)\n",
      "[xla:6]Train:  Epoch: [5][120/184]\tTime  0.892 ( 0.867)\tData  0.050 ( 0.071)\tLoss 6.2988e-02 (3.3197e-01)\tAcc@1 100.00 ( 86.61)\n",
      "[xla:0]Train:  Epoch: [5][120/184]\tTime  0.902 ( 0.871)\tData  0.051 ( 0.065)\tLoss 4.9414e-01 (3.3289e-01)\tAcc@1  75.00 ( 87.85)\n",
      "[xla:1]Train:  Epoch: [5][120/184]\tTime  0.856 ( 0.870)\tData  0.048 ( 0.067)\tLoss 1.8848e-01 (3.2712e-01)\tAcc@1  94.00 ( 87.01)\n",
      "[xla:5]Train:  Epoch: [5][120/184]\tTime  0.833 ( 0.871)\tData  0.064 ( 0.070)\tLoss 2.9688e-01 (3.1258e-01)\tAcc@1  94.00 ( 88.65)\n",
      "[xla:2]Train:  Epoch: [5][150/184]\tTime  0.790 ( 0.876)\tData  0.099 ( 0.070)\tLoss 1.5723e-01 (3.1416e-01)\tAcc@1  94.00 ( 88.87)\n",
      "[xla:5]Train:  Epoch: [5][150/184]\tTime  0.831 ( 0.874)\tData  0.055 ( 0.069)\tLoss 1.6211e-01 (2.9823e-01)\tAcc@1  94.00 ( 89.31)\n",
      "[xla:0]Train:  Epoch: [5][150/184]\tTime  0.828 ( 0.874)\tData  0.093 ( 0.065)\tLoss 6.2109e-01 (3.1697e-01)\tAcc@1  81.00 ( 88.73)\n",
      "[xla:1]Train:  Epoch: [5][150/184]\tTime  0.891 ( 0.873)\tData  0.087 ( 0.067)\tLoss 1.2012e-01 (3.0656e-01)\tAcc@1 100.00 ( 87.99)\n",
      "[xla:6]Train:  Epoch: [5][150/184]\tTime  0.872 ( 0.871)\tData  0.097 ( 0.072)\tLoss 5.6396e-02 (3.1952e-01)\tAcc@1 100.00 ( 87.40)\n",
      "[xla:3]Train:  Epoch: [5][150/184]\tTime  0.879 ( 0.872)\tData  0.102 ( 0.068)\tLoss 1.1230e-01 (3.0283e-01)\tAcc@1 100.00 ( 88.74)\n",
      "[xla:4]Train:  Epoch: [5][150/184]\tTime  0.918 ( 0.874)\tData  0.080 ( 0.066)\tLoss 1.9141e-01 (3.1083e-01)\tAcc@1  94.00 ( 88.31)\n",
      "[xla:7]Train:  Epoch: [5][150/184]\tTime  0.869 ( 0.874)\tData  0.086 ( 0.068)\tLoss 1.6406e-01 (3.0027e-01)\tAcc@1  94.00 ( 88.85)\n",
      "[xla:6]Train:  Epoch: [5][180/184]\tTime  0.937 ( 0.871)\tData  0.061 ( 0.070)\tLoss 3.4375e-01 (2.9973e-01)\tAcc@1  87.50 ( 88.50)\n",
      "[xla:1]Train:  Epoch: [5][180/184]\tTime  0.875 ( 0.873)\tData  0.051 ( 0.067)\tLoss 1.2061e-01 (2.8798e-01)\tAcc@1 100.00 ( 88.85)\n",
      "[xla:4]Train:  Epoch: [5][180/184]\tTime  0.839 ( 0.873)\tData  0.063 ( 0.066)\tLoss 1.0791e-01 (3.0101e-01)\tAcc@1  94.00 ( 88.56)\n",
      "[xla:5]Train:  Epoch: [5][180/184]\tTime  0.829 ( 0.873)\tData  0.053 ( 0.069)\tLoss 2.6172e-01 (2.8810e-01)\tAcc@1  87.50 ( 89.85)\n",
      "[xla:0]Train:  Epoch: [5][180/184]\tTime  0.893 ( 0.873)\tData  0.055 ( 0.065)\tLoss 2.1094e-01 (2.9765e-01)\tAcc@1  94.00 ( 89.45)\n",
      "[xla:2]Train:  Epoch: [5][180/184]\tTime  0.833 ( 0.876)\tData  0.054 ( 0.069)\tLoss 8.5938e-02 (2.8976e-01)\tAcc@1 100.00 ( 89.86)\n",
      "[xla:3]Train:  Epoch: [5][180/184]\tTime  0.995 ( 0.871)\tData  0.063 ( 0.068)\tLoss 9.9121e-02 (2.9851e-01)\tAcc@1  94.00 ( 88.82)\n",
      "[xla:7]Train:  Epoch: [5][180/184]\tTime  0.901 ( 0.873)\tData  0.053 ( 0.067)\tLoss 4.5117e-01 (2.9157e-01)\tAcc@1  87.50 ( 89.36)\n",
      "Finished training epoch 5\n",
      "Parallel Loader Created. Validating ...\n",
      "[xla:6]Validation: [0/9]\tTime  0.282 ( 0.282)\tLoss 5.9570e-02 (5.9570e-02)\tAcc@1 100.00 (100.00)\n",
      "[xla:5]Validation: [0/9]\tTime  0.254 ( 0.254)\tLoss 2.2461e-01 (2.2461e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:0]Validation: [0/9]\tTime  0.251 ( 0.251)\tLoss 9.5312e-01 (9.5312e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:7]Validation: [0/9]\tTime  0.217 ( 0.217)\tLoss 4.4141e-01 (4.4141e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:1]Validation: [0/9]\tTime  0.242 ( 0.242)\tLoss 6.9141e-01 (6.9141e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:3]Validation: [0/9]\tTime  0.310 ( 0.310)\tLoss 4.5312e-01 (4.5312e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:2]Validation: [0/9]\tTime  0.215 ( 0.215)\tLoss 3.7109e-01 (3.7109e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:4]Validation: [0/9]\tTime  0.220 ( 0.220)\tLoss 3.0078e-01 (3.0078e-01)\tAcc@1  81.00 ( 81.00)\n",
      "Parallel Loader Created. Training ...\n",
      "[xla:6]Train:  Epoch: [6][  0/184]\tTime  0.741 ( 0.741)\tData  0.070 ( 0.070)\tLoss 3.9648e-01 (3.9648e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:0]Train:  Epoch: [6][  0/184]\tTime  0.744 ( 0.744)\tData  0.073 ( 0.073)\tLoss 3.5742e-01 (3.5742e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:5]Train:  Epoch: [6][  0/184]\tTime  0.785 ( 0.785)\tData  0.078 ( 0.078)\tLoss 1.2988e-01 (1.2988e-01)\tAcc@1 100.00 (100.00)\n",
      "[xla:3]Train:  Epoch: [6][  0/184]\tTime  0.615 ( 0.615)\tData  0.043 ( 0.043)\tLoss 5.0391e-01 (5.0391e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:7]Train:  Epoch: [6][  0/184]\tTime  0.704 ( 0.704)\tData  0.080 ( 0.080)\tLoss 2.5586e-01 (2.5586e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:1]Train:  Epoch: [6][  0/184]\tTime  0.659 ( 0.659)\tData  0.075 ( 0.075)\tLoss 2.9883e-01 (2.9883e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:2]Train:  Epoch: [6][  0/184]\tTime  0.539 ( 0.539)\tData  0.049 ( 0.049)\tLoss 1.4160e-01 (1.4160e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:4]Train:  Epoch: [6][  0/184]\tTime  0.513 ( 0.513)\tData  0.087 ( 0.087)\tLoss 4.8047e-01 (4.8047e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:6]Train:  Epoch: [6][ 30/184]\tTime  0.825 ( 0.899)\tData  0.059 ( 0.080)\tLoss 3.3984e-01 (2.9690e-01)\tAcc@1  87.50 ( 88.16)\n",
      "[xla:5]Train:  Epoch: [6][ 30/184]\tTime  1.020 ( 0.899)\tData  0.084 ( 0.082)\tLoss 4.0039e-01 (3.3387e-01)\tAcc@1  75.00 ( 87.73)\n",
      "[xla:2]Train:  Epoch: [6][ 30/184]\tTime  0.826 ( 0.878)\tData  0.055 ( 0.076)\tLoss 9.8145e-02 (3.4353e-01)\tAcc@1 100.00 ( 87.55)\n",
      "[xla:4]Train:  Epoch: [6][ 30/184]\tTime  0.851 ( 0.874)\tData  0.089 ( 0.072)\tLoss 2.0215e-01 (3.1415e-01)\tAcc@1  94.00 ( 89.18)\n",
      "[xla:1]Train:  Epoch: [6][ 30/184]\tTime  0.891 ( 0.883)\tData  0.046 ( 0.067)\tLoss 3.7109e-01 (2.7719e-01)\tAcc@1  87.50 ( 90.81)\n",
      "[xla:3]Train:  Epoch: [6][ 30/184]\tTime  0.880 ( 0.884)\tData  0.057 ( 0.069)\tLoss 1.5625e-01 (3.1075e-01)\tAcc@1  94.00 ( 89.77)\n",
      "[xla:7]Train:  Epoch: [6][ 30/184]\tTime  0.870 ( 0.886)\tData  0.072 ( 0.069)\tLoss 6.6406e-02 (2.5291e-01)\tAcc@1 100.00 ( 90.37)\n",
      "[xla:0]Train:  Epoch: [6][ 30/184]\tTime  0.866 ( 0.900)\tData  0.086 ( 0.075)\tLoss 1.3184e-01 (3.2738e-01)\tAcc@1  94.00 ( 87.31)\n",
      "[xla:1]Train:  Epoch: [6][ 60/184]\tTime  0.666 ( 0.864)\tData  0.057 ( 0.066)\tLoss 5.8984e-01 (2.8822e-01)\tAcc@1  69.00 ( 90.03)\n",
      "[xla:2]Train:  Epoch: [6][ 60/184]\tTime  0.727 ( 0.864)\tData  0.092 ( 0.071)\tLoss 3.1250e-01 (3.4563e-01)\tAcc@1  87.50 ( 87.20)\n",
      "[xla:3]Train:  Epoch: [6][ 60/184]\tTime  0.789 ( 0.867)\tData  0.124 ( 0.067)\tLoss 2.7148e-01 (2.9343e-01)\tAcc@1  94.00 ( 89.30)\n",
      "[xla:7]Train:  Epoch: [6][ 60/184]\tTime  0.755 ( 0.868)\tData  0.064 ( 0.067)\tLoss 5.3467e-02 (2.5018e-01)\tAcc@1 100.00 ( 89.89)\n",
      "[xla:5]Train:  Epoch: [6][ 60/184]\tTime  0.875 ( 0.877)\tData  0.059 ( 0.073)\tLoss 3.4766e-01 (3.1424e-01)\tAcc@1  87.50 ( 87.73)\n",
      "[xla:6]Train:  Epoch: [6][ 60/184]\tTime  0.807 ( 0.877)\tData  0.066 ( 0.070)\tLoss 2.7734e-01 (3.1472e-01)\tAcc@1  94.00 ( 87.11)\n",
      "[xla:4]Train:  Epoch: [6][ 60/184]\tTime  0.828 ( 0.864)\tData  0.092 ( 0.070)\tLoss 1.6602e-01 (3.0484e-01)\tAcc@1  94.00 ( 89.21)\n",
      "[xla:0]Train:  Epoch: [6][ 60/184]\tTime  0.904 ( 0.877)\tData  0.055 ( 0.072)\tLoss 9.1797e-01 (3.3009e-01)\tAcc@1  69.00 ( 87.72)\n",
      "[xla:2]Train:  Epoch: [6][ 90/184]\tTime  0.711 ( 0.864)\tData  0.064 ( 0.069)\tLoss 2.1191e-01 (3.2900e-01)\tAcc@1  94.00 ( 87.95)\n",
      "[xla:4]Train:  Epoch: [6][ 90/184]\tTime  0.762 ( 0.863)\tData  0.076 ( 0.068)\tLoss 1.3867e-01 (3.0277e-01)\tAcc@1  94.00 ( 89.01)\n",
      "[xla:3]Train:  Epoch: [6][ 90/184]\tTime  0.871 ( 0.866)\tData  0.042 ( 0.068)\tLoss 4.0039e-01 (3.0566e-01)\tAcc@1  81.00 ( 88.52)\n",
      "[xla:6]Train:  Epoch: [6][ 90/184]\tTime  0.882 ( 0.873)\tData  0.046 ( 0.069)\tLoss 2.3242e-01 (3.2924e-01)\tAcc@1  94.00 ( 86.98)\n",
      "[xla:1]Train:  Epoch: [6][ 90/184]\tTime  0.815 ( 0.867)\tData  0.090 ( 0.066)\tLoss 4.9219e-01 (2.9435e-01)\tAcc@1  87.50 ( 89.14)\n",
      "[xla:5]Train:  Epoch: [6][ 90/184]\tTime  0.832 ( 0.873)\tData  0.055 ( 0.070)\tLoss 2.1484e-01 (3.1375e-01)\tAcc@1  87.50 ( 87.51)\n",
      "[xla:7]Train:  Epoch: [6][ 90/184]\tTime  0.871 ( 0.868)\tData  0.080 ( 0.067)\tLoss 7.3242e-02 (2.7833e-01)\tAcc@1 100.00 ( 89.32)\n",
      "[xla:0]Train:  Epoch: [6][ 90/184]\tTime  0.907 ( 0.873)\tData  0.056 ( 0.070)\tLoss 4.0820e-01 (3.1561e-01)\tAcc@1  94.00 ( 88.07)\n",
      "[xla:1]Train:  Epoch: [6][120/184]\tTime  0.867 ( 0.866)\tData  0.046 ( 0.067)\tLoss 1.6797e-01 (3.0540e-01)\tAcc@1  94.00 ( 88.90)\n",
      "[xla:0]Train:  Epoch: [6][120/184]\tTime  0.869 ( 0.870)\tData  0.075 ( 0.069)\tLoss 4.1211e-01 (3.2637e-01)\tAcc@1  94.00 ( 87.47)\n",
      "[xla:5]Train:  Epoch: [6][120/184]\tTime  0.848 ( 0.870)\tData  0.099 ( 0.068)\tLoss 2.2559e-01 (3.2745e-01)\tAcc@1  94.00 ( 86.78)\n",
      "[xla:4]Train:  Epoch: [6][120/184]\tTime  0.882 ( 0.864)\tData  0.086 ( 0.068)\tLoss 5.4297e-01 (3.1655e-01)\tAcc@1  81.00 ( 88.63)\n",
      "[xla:3]Train:  Epoch: [6][120/184]\tTime  0.875 ( 0.866)\tData  0.076 ( 0.068)\tLoss 4.2188e-01 (3.1270e-01)\tAcc@1  94.00 ( 88.74)\n",
      "[xla:7]Train:  Epoch: [6][120/184]\tTime  0.888 ( 0.867)\tData  0.076 ( 0.067)\tLoss 4.0625e-01 (2.9067e-01)\tAcc@1  75.00 ( 89.25)\n",
      "[xla:2]Train:  Epoch: [6][120/184]\tTime  0.870 ( 0.865)\tData  0.084 ( 0.069)\tLoss 3.9844e-01 (3.3178e-01)\tAcc@1  87.50 ( 87.79)\n",
      "[xla:6]Train:  Epoch: [6][120/184]\tTime  0.947 ( 0.871)\tData  0.057 ( 0.068)\tLoss 6.6895e-02 (3.3996e-01)\tAcc@1 100.00 ( 86.34)\n",
      "[xla:4]Train:  Epoch: [6][150/184]\tTime  0.611 ( 0.865)\tData  0.070 ( 0.070)\tLoss 1.3379e-01 (2.9797e-01)\tAcc@1  94.00 ( 89.54)\n",
      "[xla:1]Train:  Epoch: [6][150/184]\tTime  0.717 ( 0.867)\tData  0.075 ( 0.068)\tLoss 1.0547e-01 (2.8745e-01)\tAcc@1 100.00 ( 89.71)\n",
      "[xla:0]Train:  Epoch: [6][150/184]\tTime  0.829 ( 0.871)\tData  0.077 ( 0.071)\tLoss 2.3340e-01 (3.1431e-01)\tAcc@1  87.50 ( 87.91)\n",
      "[xla:2]Train:  Epoch: [6][150/184]\tTime  0.819 ( 0.867)\tData  0.076 ( 0.069)\tLoss 1.4453e-01 (3.0730e-01)\tAcc@1  94.00 ( 88.86)\n",
      "[xla:6]Train:  Epoch: [6][150/184]\tTime  0.953 ( 0.872)\tData  0.058 ( 0.068)\tLoss 7.1289e-02 (3.2412e-01)\tAcc@1 100.00 ( 87.33)\n",
      "[xla:7]Train:  Epoch: [6][150/184]\tTime  0.951 ( 0.869)\tData  0.055 ( 0.068)\tLoss 2.1484e-01 (2.7940e-01)\tAcc@1  94.00 ( 89.91)\n",
      "[xla:3]Train:  Epoch: [6][150/184]\tTime  1.015 ( 0.869)\tData  0.045 ( 0.069)\tLoss 1.3672e-01 (2.9147e-01)\tAcc@1  94.00 ( 89.50)\n",
      "[xla:5]Train:  Epoch: [6][150/184]\tTime  0.970 ( 0.872)\tData  0.078 ( 0.068)\tLoss 1.7285e-01 (3.0509e-01)\tAcc@1  94.00 ( 87.97)\n",
      "[xla:7]Train:  Epoch: [6][180/184]\tTime  0.807 ( 0.869)\tData  0.055 ( 0.068)\tLoss 3.5742e-01 (2.7369e-01)\tAcc@1  87.50 ( 90.27)\n",
      "[xla:6]Train:  Epoch: [6][180/184]\tTime  1.058 ( 0.872)\tData  0.102 ( 0.068)\tLoss 3.7500e-01 (3.0387e-01)\tAcc@1  81.00 ( 88.30)\n",
      "[xla:4]Train:  Epoch: [6][180/184]\tTime  0.872 ( 0.868)\tData  0.064 ( 0.070)\tLoss 3.5352e-01 (2.8817e-01)\tAcc@1  81.00 ( 90.01)\n",
      "[xla:5]Train:  Epoch: [6][180/184]\tTime  0.885 ( 0.872)\tData  0.076 ( 0.068)\tLoss 3.2812e-01 (2.9103e-01)\tAcc@1  94.00 ( 88.83)\n",
      "[xla:0]Train:  Epoch: [6][180/184]\tTime  0.870 ( 0.872)\tData  0.070 ( 0.070)\tLoss 2.3145e-01 (2.9243e-01)\tAcc@1  87.50 ( 88.83)\n",
      "[xla:2]Train:  Epoch: [6][180/184]\tTime  0.915 ( 0.869)\tData  0.054 ( 0.068)\tLoss 1.1279e-01 (2.8674e-01)\tAcc@1 100.00 ( 89.68)\n",
      "[xla:3]Train:  Epoch: [6][180/184]\tTime  0.862 ( 0.870)\tData  0.073 ( 0.069)\tLoss 2.2168e-01 (2.8376e-01)\tAcc@1  87.50 ( 89.66)\n",
      "[xla:1]Train:  Epoch: [6][180/184]\tTime  0.870 ( 0.870)\tData  0.057 ( 0.068)\tLoss 2.3730e-01 (2.7143e-01)\tAcc@1  87.50 ( 90.35)\n",
      "Finished training epoch 6\n",
      "[xla:1]Validation: [0/9]\tTime  0.358 ( 0.358)\tLoss 6.7969e-01 (6.7969e-01)\tAcc@1  81.00 ( 81.00)\n",
      "Parallel Loader Created. Validating ...\n",
      "[xla:5]Validation: [0/9]\tTime  0.319 ( 0.319)\tLoss 1.9238e-01 (1.9238e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:3]Validation: [0/9]\tTime  0.249 ( 0.249)\tLoss 4.4531e-01 (4.4531e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:7]Validation: [0/9]\tTime  0.223 ( 0.223)\tLoss 3.8086e-01 (3.8086e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:0]Validation: [0/9]\tTime  0.273 ( 0.273)\tLoss 9.1016e-01 (9.1016e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:6]Validation: [0/9]\tTime  0.334 ( 0.334)\tLoss 6.5918e-02 (6.5918e-02)\tAcc@1 100.00 (100.00)\n",
      "[xla:2]Validation: [0/9]\tTime  0.258 ( 0.258)\tLoss 3.5938e-01 (3.5938e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:4]Validation: [0/9]\tTime  0.243 ( 0.243)\tLoss 2.7344e-01 (2.7344e-01)\tAcc@1  81.00 ( 81.00)\n",
      "Parallel Loader Created. Training ...\n",
      "[xla:3]Train:  Epoch: [7][  0/184]\tTime  0.747 ( 0.747)\tData  0.031 ( 0.031)\tLoss 2.4219e-01 (2.4219e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:5]Train:  Epoch: [7][  0/184]\tTime  0.894 ( 0.894)\tData  0.096 ( 0.096)\tLoss 1.1035e-01 (1.1035e-01)\tAcc@1 100.00 (100.00)\n",
      "[xla:1]Train:  Epoch: [7][  0/184]\tTime  0.829 ( 0.829)\tData  0.154 ( 0.154)\tLoss 3.3008e-01 (3.3008e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:6]Train:  Epoch: [7][  0/184]\tTime  0.767 ( 0.767)\tData  0.041 ( 0.041)\tLoss 1.4746e-01 (1.4746e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:7]Train:  Epoch: [7][  0/184]\tTime  0.788 ( 0.788)\tData  0.094 ( 0.094)\tLoss 1.8164e-01 (1.8164e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:0]Train:  Epoch: [7][  0/184]\tTime  0.640 ( 0.640)\tData  0.041 ( 0.041)\tLoss 3.5938e-01 (3.5938e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:2]Train:  Epoch: [7][  0/184]\tTime  0.765 ( 0.765)\tData  0.126 ( 0.126)\tLoss 7.0801e-02 (7.0801e-02)\tAcc@1 100.00 (100.00)\n",
      "[xla:4]Train:  Epoch: [7][  0/184]\tTime  0.510 ( 0.510)\tData  0.077 ( 0.077)\tLoss 2.7539e-01 (2.7539e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:7]Train:  Epoch: [7][ 30/184]\tTime  0.782 ( 0.905)\tData  0.045 ( 0.075)\tLoss 8.8379e-02 (2.6815e-01)\tAcc@1 100.00 ( 89.32)\n",
      "[xla:3]Train:  Epoch: [7][ 30/184]\tTime  1.036 ( 0.918)\tData  0.125 ( 0.080)\tLoss 7.5195e-02 (3.0193e-01)\tAcc@1 100.00 ( 89.13)\n",
      "[xla:0]Train:  Epoch: [7][ 30/184]\tTime  1.014 ( 0.899)\tData  0.080 ( 0.076)\tLoss 8.3008e-02 (2.9666e-01)\tAcc@1 100.00 ( 88.31)\n",
      "[xla:1]Train:  Epoch: [7][ 30/184]\tTime  0.894 ( 0.911)\tData  0.051 ( 0.077)\tLoss 3.2422e-01 (3.3263e-01)\tAcc@1  87.50 ( 86.92)\n",
      "[xla:5]Train:  Epoch: [7][ 30/184]\tTime  0.898 ( 0.916)\tData  0.046 ( 0.072)\tLoss 1.3770e-01 (3.0085e-01)\tAcc@1 100.00 ( 88.53)\n",
      "[xla:2]Train:  Epoch: [7][ 30/184]\tTime  0.895 ( 0.903)\tData  0.055 ( 0.071)\tLoss 2.7466e-02 (3.4373e-01)\tAcc@1 100.00 ( 88.94)\n",
      "[xla:6]Train:  Epoch: [7][ 30/184]\tTime  1.032 ( 0.909)\tData  0.072 ( 0.071)\tLoss 3.8867e-01 (2.9086e-01)\tAcc@1  87.50 ( 88.55)\n",
      "[xla:4]Train:  Epoch: [7][ 30/184]\tTime  0.970 ( 0.892)\tData  0.050 ( 0.071)\tLoss 2.7539e-01 (3.1592e-01)\tAcc@1  94.00 ( 87.73)\n",
      "[xla:5]Train:  Epoch: [7][ 60/184]\tTime  0.741 ( 0.905)\tData  0.060 ( 0.074)\tLoss 4.3945e-01 (3.0131e-01)\tAcc@1  87.50 ( 88.25)\n",
      "[xla:4]Train:  Epoch: [7][ 60/184]\tTime  0.779 ( 0.894)\tData  0.055 ( 0.073)\tLoss 2.0312e-01 (2.9393e-01)\tAcc@1  87.50 ( 89.36)\n",
      "[xla:1]Train:  Epoch: [7][ 60/184]\tTime  0.862 ( 0.904)\tData  0.060 ( 0.073)\tLoss 6.7188e-01 (3.2280e-01)\tAcc@1  75.00 ( 87.20)\n",
      "[xla:6]Train:  Epoch: [7][ 60/184]\tTime  0.888 ( 0.904)\tData  0.069 ( 0.074)\tLoss 4.5898e-01 (3.1276e-01)\tAcc@1  81.00 ( 88.46)\n",
      "[xla:3]Train:  Epoch: [7][ 60/184]\tTime  0.984 ( 0.910)\tData  0.049 ( 0.076)\tLoss 1.9629e-01 (3.0277e-01)\tAcc@1  94.00 ( 88.43)\n",
      "[xla:7]Train:  Epoch: [7][ 60/184]\tTime  0.947 ( 0.903)\tData  0.075 ( 0.073)\tLoss 7.8613e-02 (2.8014e-01)\tAcc@1 100.00 ( 88.74)\n",
      "[xla:0]Train:  Epoch: [7][ 60/184]\tTime  0.985 ( 0.900)\tData  0.049 ( 0.076)\tLoss 1.0391e+00 (3.2287e-01)\tAcc@1  62.50 ( 88.11)\n",
      "[xla:2]Train:  Epoch: [7][ 60/184]\tTime  0.872 ( 0.901)\tData  0.050 ( 0.073)\tLoss 2.0898e-01 (3.4863e-01)\tAcc@1  87.50 ( 87.52)\n",
      "[xla:6]Train:  Epoch: [7][ 90/184]\tTime  0.746 ( 0.901)\tData  0.055 ( 0.074)\tLoss 4.3359e-01 (3.2764e-01)\tAcc@1  81.00 ( 88.29)\n",
      "[xla:3]Train:  Epoch: [7][ 90/184]\tTime  0.805 ( 0.905)\tData  0.086 ( 0.075)\tLoss 4.5117e-01 (2.9646e-01)\tAcc@1  75.00 ( 88.57)\n",
      "[xla:0]Train:  Epoch: [7][ 90/184]\tTime  0.814 ( 0.899)\tData  0.084 ( 0.076)\tLoss 3.4570e-01 (3.1695e-01)\tAcc@1  94.00 ( 88.20)\n",
      "[xla:7]Train:  Epoch: [7][ 90/184]\tTime  0.834 ( 0.901)\tData  0.056 ( 0.075)\tLoss 1.5723e-01 (3.0589e-01)\tAcc@1  94.00 ( 87.72)\n",
      "[xla:1]Train:  Epoch: [7][ 90/184]\tTime  0.916 ( 0.903)\tData  0.044 ( 0.072)\tLoss 4.6289e-01 (3.2633e-01)\tAcc@1  94.00 ( 87.39)\n",
      "[xla:5]Train:  Epoch: [7][ 90/184]\tTime  0.908 ( 0.905)\tData  0.091 ( 0.075)\tLoss 1.7969e-01 (2.9978e-01)\tAcc@1  94.00 ( 88.36)\n",
      "[xla:4]Train:  Epoch: [7][ 90/184]\tTime  0.985 ( 0.896)\tData  0.046 ( 0.073)\tLoss 1.2061e-01 (3.0731e-01)\tAcc@1  94.00 ( 89.03)\n",
      "[xla:2]Train:  Epoch: [7][ 90/184]\tTime  0.959 ( 0.901)\tData  0.092 ( 0.072)\tLoss 1.1133e-01 (3.2872e-01)\tAcc@1 100.00 ( 88.10)\n",
      "[xla:2]Train:  Epoch: [7][120/184]\tTime  0.799 ( 0.900)\tData  0.096 ( 0.072)\tLoss 1.7480e-01 (3.2802e-01)\tAcc@1  94.00 ( 88.27)\n",
      "[xla:6]Train:  Epoch: [7][120/184]\tTime  0.888 ( 0.903)\tData  0.103 ( 0.072)\tLoss 4.7119e-02 (3.3769e-01)\tAcc@1 100.00 ( 87.64)\n",
      "[xla:5]Train:  Epoch: [7][120/184]\tTime  0.959 ( 0.905)\tData  0.052 ( 0.075)\tLoss 2.9102e-01 (3.2205e-01)\tAcc@1  87.50 ( 87.42)\n",
      "[xla:4]Train:  Epoch: [7][120/184]\tTime  0.889 ( 0.898)\tData  0.073 ( 0.072)\tLoss 5.1953e-01 (3.2022e-01)\tAcc@1  81.00 ( 88.46)\n",
      "[xla:7]Train:  Epoch: [7][120/184]\tTime  0.947 ( 0.902)\tData  0.065 ( 0.074)\tLoss 5.5078e-01 (3.1322e-01)\tAcc@1  75.00 ( 87.58)\n",
      "[xla:1]Train:  Epoch: [7][120/184]\tTime  0.928 ( 0.904)\tData  0.065 ( 0.071)\tLoss 1.6309e-01 (3.3474e-01)\tAcc@1 100.00 ( 87.16)\n",
      "[xla:3]Train:  Epoch: [7][120/184]\tTime  0.956 ( 0.906)\tData  0.119 ( 0.073)\tLoss 3.8086e-01 (2.9949e-01)\tAcc@1  87.50 ( 88.88)\n",
      "[xla:0]Train:  Epoch: [7][120/184]\tTime  0.927 ( 0.901)\tData  0.108 ( 0.076)\tLoss 6.5234e-01 (3.2986e-01)\tAcc@1  69.00 ( 87.41)\n",
      "[xla:3]Train:  Epoch: [7][150/184]\tTime  0.866 ( 0.906)\tData  0.121 ( 0.073)\tLoss 1.0938e-01 (2.8500e-01)\tAcc@1  94.00 ( 89.41)\n",
      "[xla:6]Train:  Epoch: [7][150/184]\tTime  0.869 ( 0.904)\tData  0.107 ( 0.073)\tLoss 4.6143e-02 (3.1760e-01)\tAcc@1 100.00 ( 88.54)\n",
      "[xla:0]Train:  Epoch: [7][150/184]\tTime  0.835 ( 0.902)\tData  0.077 ( 0.076)\tLoss 1.9922e-01 (3.1307e-01)\tAcc@1  94.00 ( 87.94)\n",
      "[xla:5]Train:  Epoch: [7][150/184]\tTime  0.960 ( 0.906)\tData  0.097 ( 0.075)\tLoss 2.2363e-01 (3.0348e-01)\tAcc@1  87.50 ( 88.32)\n",
      "[xla:2]Train:  Epoch: [7][150/184]\tTime  0.901 ( 0.903)\tData  0.108 ( 0.073)\tLoss 1.1523e-01 (3.0171e-01)\tAcc@1 100.00 ( 89.46)\n",
      "[xla:1]Train:  Epoch: [7][150/184]\tTime  0.952 ( 0.905)\tData  0.072 ( 0.071)\tLoss 1.8066e-01 (3.0686e-01)\tAcc@1  87.50 ( 88.24)\n",
      "[xla:7]Train:  Epoch: [7][150/184]\tTime  0.960 ( 0.904)\tData  0.095 ( 0.075)\tLoss 5.9082e-02 (3.0093e-01)\tAcc@1 100.00 ( 88.23)\n",
      "[xla:4]Train:  Epoch: [7][150/184]\tTime  0.934 ( 0.901)\tData  0.094 ( 0.074)\tLoss 1.5820e-01 (3.0564e-01)\tAcc@1  94.00 ( 88.86)\n",
      "[xla:7]Train:  Epoch: [7][180/184]\tTime  0.816 ( 0.911)\tData  0.060 ( 0.077)\tLoss 3.2031e-01 (2.9195e-01)\tAcc@1  87.50 ( 88.88)\n",
      "[xla:1]Train:  Epoch: [7][180/184]\tTime  0.866 ( 0.912)\tData  0.060 ( 0.073)\tLoss 2.0215e-01 (2.9119e-01)\tAcc@1  94.00 ( 89.09)\n",
      "[xla:6]Train:  Epoch: [7][180/184]\tTime  0.909 ( 0.912)\tData  0.082 ( 0.075)\tLoss 4.0430e-01 (3.0147e-01)\tAcc@1  81.00 ( 88.96)\n",
      "[xla:2]Train:  Epoch: [7][180/184]\tTime  0.984 ( 0.911)\tData  0.054 ( 0.074)\tLoss 2.5781e-01 (2.8250e-01)\tAcc@1  87.50 ( 90.12)\n",
      "[xla:4]Train:  Epoch: [7][180/184]\tTime  0.968 ( 0.909)\tData  0.119 ( 0.075)\tLoss 1.0156e-01 (2.9432e-01)\tAcc@1 100.00 ( 89.43)\n",
      "[xla:3]Train:  Epoch: [7][180/184]\tTime  0.936 ( 0.914)\tData  0.082 ( 0.074)\tLoss 2.9297e-01 (2.7689e-01)\tAcc@1  87.50 ( 89.80)\n",
      "[xla:5]Train:  Epoch: [7][180/184]\tTime  0.903 ( 0.913)\tData  0.078 ( 0.076)\tLoss 4.6094e-01 (2.9286e-01)\tAcc@1  87.50 ( 88.91)\n",
      "[xla:0]Train:  Epoch: [7][180/184]\tTime  0.990 ( 0.910)\tData  0.072 ( 0.076)\tLoss 1.0742e-01 (2.9202e-01)\tAcc@1  94.00 ( 88.84)\n",
      "Finished training epoch 7\n",
      "Parallel Loader Created. Validating ...\n",
      "[xla:3]Validation: [0/9]\tTime  0.311 ( 0.311)\tLoss 4.1797e-01 (4.1797e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:6]Validation: [0/9]\tTime  0.277 ( 0.277)\tLoss 7.0312e-02 (7.0312e-02)\tAcc@1 100.00 (100.00)\n",
      "[xla:0]Validation: [0/9]\tTime  0.286 ( 0.286)\tLoss 8.4766e-01 (8.4766e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:2]Validation: [0/9]\tTime  0.266 ( 0.266)\tLoss 3.6328e-01 (3.6328e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:4]Validation: [0/9]\tTime  0.305 ( 0.305)\tLoss 2.7344e-01 (2.7344e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:5]Validation: [0/9]\tTime  0.263 ( 0.263)\tLoss 1.9629e-01 (1.9629e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:1]Validation: [0/9]\tTime  0.293 ( 0.293)\tLoss 7.2266e-01 (7.2266e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:7]Validation: [0/9]\tTime  0.274 ( 0.274)\tLoss 3.7500e-01 (3.7500e-01)\tAcc@1  81.00 ( 81.00)\n",
      "Parallel Loader Created. Training ...\n",
      "[xla:3]Train:  Epoch: [8][  0/184]\tTime  0.698 ( 0.698)\tData  0.049 ( 0.049)\tLoss 3.1055e-01 (3.1055e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:6]Train:  Epoch: [8][  0/184]\tTime  0.919 ( 0.919)\tData  0.040 ( 0.040)\tLoss 3.8477e-01 (3.8477e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:2]Train:  Epoch: [8][  0/184]\tTime  0.847 ( 0.847)\tData  0.080 ( 0.080)\tLoss 2.2559e-01 (2.2559e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:1]Train:  Epoch: [8][  0/184]\tTime  0.662 ( 0.662)\tData  0.057 ( 0.057)\tLoss 2.4023e-01 (2.4023e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:5]Train:  Epoch: [8][  0/184]\tTime  0.745 ( 0.745)\tData  0.055 ( 0.055)\tLoss 1.8750e-01 (1.8750e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:0]Train:  Epoch: [8][  0/184]\tTime  0.809 ( 0.809)\tData  0.071 ( 0.071)\tLoss 3.5742e-01 (3.5742e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:7]Train:  Epoch: [8][  0/184]\tTime  0.699 ( 0.699)\tData  0.100 ( 0.100)\tLoss 2.9492e-01 (2.9492e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:4]Train:  Epoch: [8][  0/184]\tTime  0.688 ( 0.688)\tData  0.125 ( 0.125)\tLoss 1.4160e-01 (1.4160e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:3]Train:  Epoch: [8][ 30/184]\tTime  0.873 ( 0.925)\tData  0.060 ( 0.078)\tLoss 2.4023e-01 (3.3331e-01)\tAcc@1  94.00 ( 87.76)\n",
      "[xla:4]Train:  Epoch: [8][ 30/184]\tTime  0.999 ( 0.905)\tData  0.074 ( 0.074)\tLoss 1.1572e-01 (2.8037e-01)\tAcc@1  94.00 ( 88.97)\n",
      "[xla:7]Train:  Epoch: [8][ 30/184]\tTime  0.900 ( 0.907)\tData  0.073 ( 0.080)\tLoss 5.7861e-02 (2.3645e-01)\tAcc@1 100.00 ( 91.73)\n",
      "[xla:6]Train:  Epoch: [8][ 30/184]\tTime  0.918 ( 0.922)\tData  0.058 ( 0.078)\tLoss 3.3398e-01 (2.9412e-01)\tAcc@1  94.00 ( 89.99)\n",
      "[xla:2]Train:  Epoch: [8][ 30/184]\tTime  0.840 ( 0.916)\tData  0.055 ( 0.080)\tLoss 7.6172e-02 (3.6199e-01)\tAcc@1 100.00 ( 86.95)\n",
      "[xla:1]Train:  Epoch: [8][ 30/184]\tTime  0.845 ( 0.908)\tData  0.055 ( 0.078)\tLoss 4.7656e-01 (2.9133e-01)\tAcc@1  87.50 ( 90.34)\n",
      "[xla:0]Train:  Epoch: [8][ 30/184]\tTime  0.876 ( 0.912)\tData  0.055 ( 0.075)\tLoss 2.8125e-01 (2.9503e-01)\tAcc@1  87.50 ( 89.32)\n",
      "[xla:5]Train:  Epoch: [8][ 30/184]\tTime  0.987 ( 0.910)\tData  0.075 ( 0.079)\tLoss 1.2207e-01 (3.2751e-01)\tAcc@1  94.00 ( 87.95)\n",
      "[xla:4]Train:  Epoch: [8][ 60/184]\tTime  0.745 ( 0.917)\tData  0.103 ( 0.076)\tLoss 1.4844e-01 (2.8374e-01)\tAcc@1  87.50 ( 88.86)\n",
      "[xla:7]Train:  Epoch: [8][ 60/184]\tTime  0.925 ( 0.919)\tData  0.053 ( 0.079)\tLoss 1.3477e-01 (2.7278e-01)\tAcc@1  94.00 ( 90.06)\n",
      "[xla:2]Train:  Epoch: [8][ 60/184]\tTime  0.916 ( 0.925)\tData  0.101 ( 0.080)\tLoss 3.3984e-01 (3.4644e-01)\tAcc@1  75.00 ( 86.70)\n",
      "[xla:5]Train:  Epoch: [8][ 60/184]\tTime  0.903 ( 0.922)\tData  0.101 ( 0.078)\tLoss 4.1211e-01 (3.0215e-01)\tAcc@1  87.50 ( 88.66)\n",
      "[xla:1]Train:  Epoch: [8][ 60/184]\tTime  0.957 ( 0.921)\tData  0.105 ( 0.079)\tLoss 7.1875e-01 (2.7987e-01)\tAcc@1  69.00 ( 89.59)\n",
      "[xla:6]Train:  Epoch: [8][ 60/184]\tTime  0.970 ( 0.928)\tData  0.070 ( 0.077)\tLoss 4.5703e-01 (3.3002e-01)\tAcc@1  75.00 ( 87.95)\n",
      "[xla:0]Train:  Epoch: [8][ 60/184]\tTime  0.929 ( 0.923)\tData  0.085 ( 0.077)\tLoss 5.8594e-01 (3.2578e-01)\tAcc@1  75.00 ( 88.52)\n",
      "[xla:3]Train:  Epoch: [8][ 60/184]\tTime  0.949 ( 0.931)\tData  0.087 ( 0.079)\tLoss 2.0508e-01 (3.2041e-01)\tAcc@1  94.00 ( 88.36)\n",
      "[xla:7]Train:  Epoch: [8][ 90/184]\tTime  0.946 ( 0.934)\tData  0.100 ( 0.080)\tLoss 2.0117e-01 (2.9828e-01)\tAcc@1  94.00 ( 88.95)\n",
      "[xla:0]Train:  Epoch: [8][ 90/184]\tTime  0.924 ( 0.935)\tData  0.096 ( 0.080)\tLoss 3.2812e-01 (3.1814e-01)\tAcc@1  94.00 ( 88.48)\n",
      "[xla:2]Train:  Epoch: [8][ 90/184]\tTime  1.006 ( 0.937)\tData  0.092 ( 0.083)\tLoss 1.1914e-01 (3.2666e-01)\tAcc@1 100.00 ( 87.32)\n",
      "[xla:1]Train:  Epoch: [8][ 90/184]\tTime  1.104 ( 0.935)\tData  0.080 ( 0.081)\tLoss 4.1016e-01 (2.7806e-01)\tAcc@1  87.50 ( 89.53)\n",
      "[xla:5]Train:  Epoch: [8][ 90/184]\tTime  0.961 ( 0.935)\tData  0.088 ( 0.081)\tLoss 1.0498e-01 (2.9617e-01)\tAcc@1 100.00 ( 88.97)\n",
      "[xla:6]Train:  Epoch: [8][ 90/184]\tTime  1.089 ( 0.939)\tData  0.096 ( 0.080)\tLoss 3.1055e-01 (3.3673e-01)\tAcc@1  87.50 ( 87.82)\n",
      "[xla:3]Train:  Epoch: [8][ 90/184]\tTime  0.963 ( 0.941)\tData  0.095 ( 0.081)\tLoss 3.1641e-01 (3.1013e-01)\tAcc@1  87.50 ( 88.22)\n",
      "[xla:4]Train:  Epoch: [8][ 90/184]\tTime  1.034 ( 0.934)\tData  0.084 ( 0.078)\tLoss 1.0596e-01 (2.8964e-01)\tAcc@1  94.00 ( 88.77)\n",
      "[xla:2]Train:  Epoch: [8][120/184]\tTime  0.820 ( 0.943)\tData  0.086 ( 0.085)\tLoss 4.7852e-01 (3.2696e-01)\tAcc@1  81.00 ( 87.48)\n",
      "[xla:4]Train:  Epoch: [8][120/184]\tTime  0.885 ( 0.940)\tData  0.112 ( 0.079)\tLoss 5.1562e-01 (3.1092e-01)\tAcc@1  87.50 ( 87.79)\n",
      "[xla:7]Train:  Epoch: [8][120/184]\tTime  0.910 ( 0.941)\tData  0.085 ( 0.081)\tLoss 3.3594e-01 (2.9911e-01)\tAcc@1  75.00 ( 89.13)\n",
      "[xla:6]Train:  Epoch: [8][120/184]\tTime  0.970 ( 0.945)\tData  0.063 ( 0.082)\tLoss 1.1865e-01 (3.4133e-01)\tAcc@1  94.00 ( 87.27)\n",
      "[xla:3]Train:  Epoch: [8][120/184]\tTime  0.893 ( 0.947)\tData  0.074 ( 0.083)\tLoss 5.8984e-01 (3.1097e-01)\tAcc@1  87.50 ( 88.57)\n",
      "[xla:0]Train:  Epoch: [8][120/184]\tTime  0.963 ( 0.943)\tData  0.065 ( 0.079)\tLoss 5.9375e-01 (3.3261e-01)\tAcc@1  87.50 ( 87.74)\n",
      "[xla:5]Train:  Epoch: [8][120/184]\tTime  0.957 ( 0.943)\tData  0.095 ( 0.083)\tLoss 3.2422e-01 (3.1795e-01)\tAcc@1  94.00 ( 88.14)\n",
      "[xla:1]Train:  Epoch: [8][120/184]\tTime  1.031 ( 0.942)\tData  0.065 ( 0.083)\tLoss 9.5215e-02 (2.8816e-01)\tAcc@1 100.00 ( 89.15)\n",
      "[xla:2]Train:  Epoch: [8][150/184]\tTime  0.829 ( 0.949)\tData  0.066 ( 0.085)\tLoss 1.1230e-01 (3.0430e-01)\tAcc@1 100.00 ( 88.37)\n",
      "[xla:6]Train:  Epoch: [8][150/184]\tTime  0.892 ( 0.951)\tData  0.070 ( 0.083)\tLoss 1.0254e-01 (3.2532e-01)\tAcc@1 100.00 ( 88.06)\n",
      "[xla:7]Train:  Epoch: [8][150/184]\tTime  0.848 ( 0.948)\tData  0.065 ( 0.084)\tLoss 1.4160e-01 (2.8858e-01)\tAcc@1  94.00 ( 89.69)\n",
      "[xla:1]Train:  Epoch: [8][150/184]\tTime  0.869 ( 0.948)\tData  0.074 ( 0.084)\tLoss 1.2451e-01 (2.7052e-01)\tAcc@1 100.00 ( 90.17)\n",
      "[xla:4]Train:  Epoch: [8][150/184]\tTime  0.941 ( 0.948)\tData  0.073 ( 0.081)\tLoss 1.0010e-01 (2.9399e-01)\tAcc@1 100.00 ( 88.57)\n",
      "[xla:3]Train:  Epoch: [8][150/184]\tTime  1.049 ( 0.952)\tData  0.095 ( 0.084)\tLoss 8.2031e-02 (2.9721e-01)\tAcc@1 100.00 ( 89.28)\n",
      "[xla:5]Train:  Epoch: [8][150/184]\tTime  1.029 ( 0.949)\tData  0.085 ( 0.085)\tLoss 1.9629e-01 (3.0029e-01)\tAcc@1  94.00 ( 88.78)\n",
      "[xla:0]Train:  Epoch: [8][150/184]\tTime  0.990 ( 0.949)\tData  0.076 ( 0.082)\tLoss 1.4062e-01 (3.1739e-01)\tAcc@1 100.00 ( 88.24)\n",
      "[xla:5]Train:  Epoch: [8][180/184]\tTime  0.949 ( 0.943)\tData  0.059 ( 0.084)\tLoss 5.3906e-01 (2.8961e-01)\tAcc@1  81.00 ( 89.33)\n",
      "[xla:0]Train:  Epoch: [8][180/184]\tTime  0.849 ( 0.943)\tData  0.066 ( 0.081)\tLoss 1.9238e-01 (3.0248e-01)\tAcc@1  87.50 ( 88.86)\n",
      "[xla:1]Train:  Epoch: [8][180/184]\tTime  0.851 ( 0.943)\tData  0.054 ( 0.083)\tLoss 1.8164e-01 (2.5549e-01)\tAcc@1  94.00 ( 90.77)\n",
      "[xla:4]Train:  Epoch: [8][180/184]\tTime  0.908 ( 0.942)\tData  0.058 ( 0.080)\tLoss 3.3594e-01 (2.8424e-01)\tAcc@1  75.00 ( 89.30)\n",
      "[xla:3]Train:  Epoch: [8][180/184]\tTime  0.940 ( 0.946)\tData  0.048 ( 0.083)\tLoss 1.1768e-01 (2.8988e-01)\tAcc@1  94.00 ( 89.51)\n",
      "[xla:6]Train:  Epoch: [8][180/184]\tTime  0.884 ( 0.945)\tData  0.060 ( 0.082)\tLoss 4.5312e-01 (3.0964e-01)\tAcc@1  81.00 ( 89.01)\n",
      "[xla:2]Train:  Epoch: [8][180/184]\tTime  1.030 ( 0.944)\tData  0.060 ( 0.083)\tLoss 1.8652e-01 (2.8334e-01)\tAcc@1  94.00 ( 89.31)\n",
      "[xla:7]Train:  Epoch: [8][180/184]\tTime  0.957 ( 0.943)\tData  0.056 ( 0.082)\tLoss 4.0039e-01 (2.7890e-01)\tAcc@1  87.50 ( 90.17)\n",
      "Finished training epoch 8\n",
      "[xla:1]Validation: [0/9]\tTime  0.334 ( 0.334)\tLoss 7.7734e-01 (7.7734e-01)\tAcc@1  81.00 ( 81.00)\n",
      "Parallel Loader Created. Validating ...\n",
      "[xla:3]Validation: [0/9]\tTime  0.197 ( 0.197)\tLoss 4.1211e-01 (4.1211e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:7]Validation: [0/9]\tTime  0.302 ( 0.302)\tLoss 3.5742e-01 (3.5742e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:6]Validation: [0/9]\tTime  0.296 ( 0.296)\tLoss 7.3730e-02 (7.3730e-02)\tAcc@1 100.00 (100.00)\n",
      "[xla:5]Validation: [0/9]\tTime  0.319 ( 0.319)\tLoss 1.7676e-01 (1.7676e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:4]Validation: [0/9]\tTime  0.258 ( 0.258)\tLoss 2.8125e-01 (2.8125e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:0]Validation: [0/9]\tTime  0.226 ( 0.226)\tLoss 7.8125e-01 (7.8125e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:2]Validation: [0/9]\tTime  0.257 ( 0.257)\tLoss 3.7891e-01 (3.7891e-01)\tAcc@1  81.00 ( 81.00)\n",
      "Parallel Loader Created. Training ...\n",
      "[xla:7]Train:  Epoch: [9][  0/184]\tTime  0.836 ( 0.836)\tData  0.061 ( 0.061)\tLoss 1.4160e-01 (1.4160e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:6]Train:  Epoch: [9][  0/184]\tTime  0.818 ( 0.818)\tData  0.072 ( 0.072)\tLoss 3.4961e-01 (3.4961e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:1]Train:  Epoch: [9][  0/184]\tTime  0.823 ( 0.823)\tData  0.028 ( 0.028)\tLoss 3.7500e-01 (3.7500e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:0]Train:  Epoch: [9][  0/184]\tTime  0.778 ( 0.778)\tData  0.093 ( 0.093)\tLoss 4.5117e-01 (4.5117e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:4]Train:  Epoch: [9][  0/184]\tTime  0.802 ( 0.802)\tData  0.066 ( 0.066)\tLoss 2.5977e-01 (2.5977e-01)\tAcc@1  87.50 ( 87.50)\n",
      "[xla:5]Train:  Epoch: [9][  0/184]\tTime  0.671 ( 0.671)\tData  0.062 ( 0.062)\tLoss 1.2402e-01 (1.2402e-01)\tAcc@1 100.00 (100.00)\n",
      "[xla:2]Train:  Epoch: [9][  0/184]\tTime  0.681 ( 0.681)\tData  0.105 ( 0.105)\tLoss 6.1768e-02 (6.1768e-02)\tAcc@1 100.00 (100.00)\n",
      "[xla:3]Train:  Epoch: [9][  0/184]\tTime  0.669 ( 0.669)\tData  0.132 ( 0.132)\tLoss 1.7676e-01 (1.7676e-01)\tAcc@1 100.00 (100.00)\n",
      "[xla:7]Train:  Epoch: [9][ 30/184]\tTime  0.881 ( 0.887)\tData  0.063 ( 0.066)\tLoss 7.1777e-02 (2.4553e-01)\tAcc@1 100.00 ( 89.35)\n",
      "[xla:6]Train:  Epoch: [9][ 30/184]\tTime  0.835 ( 0.886)\tData  0.060 ( 0.067)\tLoss 3.4961e-01 (3.1375e-01)\tAcc@1  81.00 ( 89.55)\n",
      "[xla:0]Train:  Epoch: [9][ 30/184]\tTime  0.939 ( 0.883)\tData  0.053 ( 0.067)\tLoss 1.9727e-01 (3.1239e-01)\tAcc@1  94.00 ( 87.95)\n",
      "[xla:2]Train:  Epoch: [9][ 30/184]\tTime  0.928 ( 0.877)\tData  0.066 ( 0.070)\tLoss 5.6396e-02 (3.0219e-01)\tAcc@1 100.00 ( 89.11)\n",
      "[xla:4]Train:  Epoch: [9][ 30/184]\tTime  0.908 ( 0.885)\tData  0.060 ( 0.072)\tLoss 3.1641e-01 (2.7044e-01)\tAcc@1  81.00 ( 89.94)\n",
      "[xla:3]Train:  Epoch: [9][ 30/184]\tTime  0.852 ( 0.875)\tData  0.070 ( 0.069)\tLoss 1.6113e-01 (2.9604e-01)\tAcc@1  87.50 ( 90.40)\n",
      "[xla:5]Train:  Epoch: [9][ 30/184]\tTime  0.910 ( 0.880)\tData  0.077 ( 0.070)\tLoss 1.4258e-01 (3.0249e-01)\tAcc@1 100.00 ( 88.95)\n",
      "[xla:1]Train:  Epoch: [9][ 30/184]\tTime  0.910 ( 0.888)\tData  0.062 ( 0.072)\tLoss 2.8906e-01 (2.7955e-01)\tAcc@1  94.00 ( 90.58)\n",
      "[xla:1]Train:  Epoch: [9][ 60/184]\tTime  0.566 ( 0.888)\tData  0.059 ( 0.070)\tLoss 6.7969e-01 (2.9041e-01)\tAcc@1  62.50 ( 89.08)\n",
      "[xla:7]Train:  Epoch: [9][ 60/184]\tTime  0.775 ( 0.892)\tData  0.052 ( 0.066)\tLoss 1.5234e-01 (2.7561e-01)\tAcc@1  94.00 ( 88.57)\n",
      "[xla:6]Train:  Epoch: [9][ 60/184]\tTime  0.856 ( 0.891)\tData  0.060 ( 0.069)\tLoss 3.4375e-01 (3.2081e-01)\tAcc@1  81.00 ( 89.58)\n",
      "[xla:2]Train:  Epoch: [9][ 60/184]\tTime  0.792 ( 0.886)\tData  0.056 ( 0.071)\tLoss 1.8066e-01 (3.1749e-01)\tAcc@1  94.00 ( 88.64)\n",
      "[xla:3]Train:  Epoch: [9][ 60/184]\tTime  0.915 ( 0.886)\tData  0.053 ( 0.071)\tLoss 3.8086e-01 (3.0650e-01)\tAcc@1  75.00 ( 88.60)\n",
      "[xla:0]Train:  Epoch: [9][ 60/184]\tTime  0.839 ( 0.890)\tData  0.057 ( 0.068)\tLoss 6.0156e-01 (3.3296e-01)\tAcc@1  75.00 ( 87.77)\n",
      "[xla:5]Train:  Epoch: [9][ 60/184]\tTime  0.840 ( 0.888)\tData  0.073 ( 0.067)\tLoss 4.3750e-01 (2.8615e-01)\tAcc@1  81.00 ( 89.39)\n",
      "[xla:4]Train:  Epoch: [9][ 60/184]\tTime  0.907 ( 0.891)\tData  0.051 ( 0.070)\tLoss 3.3398e-01 (2.7653e-01)\tAcc@1  87.50 ( 89.89)\n",
      "[xla:4]Train:  Epoch: [9][ 90/184]\tTime  0.785 ( 0.883)\tData  0.061 ( 0.069)\tLoss 3.5742e-01 (2.8846e-01)\tAcc@1  81.00 ( 89.45)\n",
      "[xla:6]Train:  Epoch: [9][ 90/184]\tTime  0.767 ( 0.883)\tData  0.077 ( 0.070)\tLoss 3.5547e-01 (3.4356e-01)\tAcc@1  94.00 ( 88.78)\n",
      "[xla:7]Train:  Epoch: [9][ 90/184]\tTime  0.810 ( 0.885)\tData  0.064 ( 0.066)\tLoss 2.1094e-01 (3.1604e-01)\tAcc@1  87.50 ( 87.45)\n",
      "[xla:3]Train:  Epoch: [9][ 90/184]\tTime  0.851 ( 0.880)\tData  0.076 ( 0.070)\tLoss 6.5234e-01 (3.0615e-01)\tAcc@1  87.50 ( 88.80)\n",
      "[xla:1]Train:  Epoch: [9][ 90/184]\tTime  0.956 ( 0.884)\tData  0.056 ( 0.070)\tLoss 5.5469e-01 (2.9760e-01)\tAcc@1  87.50 ( 89.11)\n",
      "[xla:2]Train:  Epoch: [9][ 90/184]\tTime  0.938 ( 0.881)\tData  0.052 ( 0.071)\tLoss 1.1768e-01 (3.1201e-01)\tAcc@1 100.00 ( 87.98)\n",
      "[xla:5]Train:  Epoch: [9][ 90/184]\tTime  0.930 ( 0.882)\tData  0.058 ( 0.066)\tLoss 1.8652e-01 (2.8636e-01)\tAcc@1  87.50 ( 89.18)\n",
      "[xla:0]Train:  Epoch: [9][ 90/184]\tTime  0.888 ( 0.884)\tData  0.059 ( 0.067)\tLoss 2.5391e-01 (3.1293e-01)\tAcc@1  94.00 ( 88.47)\n",
      "[xla:3]Train:  Epoch: [9][120/184]\tTime  0.891 ( 0.891)\tData  0.058 ( 0.073)\tLoss 5.7422e-01 (3.0460e-01)\tAcc@1  87.50 ( 89.21)\n",
      "[xla:2]Train:  Epoch: [9][120/184]\tTime  0.958 ( 0.892)\tData  0.071 ( 0.070)\tLoss 1.8945e-01 (3.0976e-01)\tAcc@1  87.50 ( 88.02)\n",
      "[xla:5]Train:  Epoch: [9][120/184]\tTime  0.913 ( 0.893)\tData  0.081 ( 0.069)\tLoss 2.2754e-01 (3.0004e-01)\tAcc@1  94.00 ( 88.72)\n",
      "[xla:4]Train:  Epoch: [9][120/184]\tTime  0.970 ( 0.895)\tData  0.068 ( 0.070)\tLoss 6.5625e-01 (3.0723e-01)\tAcc@1  87.50 ( 88.92)\n",
      "[xla:0]Train:  Epoch: [9][120/184]\tTime  0.880 ( 0.894)\tData  0.075 ( 0.070)\tLoss 4.6680e-01 (3.2396e-01)\tAcc@1  81.00 ( 88.07)\n",
      "[xla:7]Train:  Epoch: [9][120/184]\tTime  0.932 ( 0.896)\tData  0.098 ( 0.069)\tLoss 4.7852e-01 (3.1624e-01)\tAcc@1  81.00 ( 87.79)\n",
      "[xla:1]Train:  Epoch: [9][120/184]\tTime  0.940 ( 0.895)\tData  0.078 ( 0.073)\tLoss 1.5625e-01 (3.1380e-01)\tAcc@1 100.00 ( 88.56)\n",
      "[xla:6]Train:  Epoch: [9][120/184]\tTime  0.975 ( 0.896)\tData  0.086 ( 0.072)\tLoss 6.2988e-02 (3.4802e-01)\tAcc@1 100.00 ( 87.94)\n",
      "[xla:0]Train:  Epoch: [9][150/184]\tTime  0.822 ( 0.902)\tData  0.110 ( 0.072)\tLoss 1.6992e-01 (3.0687e-01)\tAcc@1  94.00 ( 88.68)\n",
      "[xla:4]Train:  Epoch: [9][150/184]\tTime  0.843 ( 0.903)\tData  0.063 ( 0.073)\tLoss 2.1289e-01 (2.9329e-01)\tAcc@1  94.00 ( 89.73)\n",
      "[xla:2]Train:  Epoch: [9][150/184]\tTime  0.930 ( 0.901)\tData  0.057 ( 0.072)\tLoss 1.8555e-01 (2.9633e-01)\tAcc@1  94.00 ( 88.38)\n",
      "[xla:7]Train:  Epoch: [9][150/184]\tTime  0.940 ( 0.904)\tData  0.088 ( 0.072)\tLoss 1.6797e-01 (3.0013e-01)\tAcc@1  87.50 ( 88.74)\n",
      "[xla:6]Train:  Epoch: [9][150/184]\tTime  1.029 ( 0.904)\tData  0.059 ( 0.075)\tLoss 6.7383e-02 (3.3080e-01)\tAcc@1 100.00 ( 88.65)\n",
      "[xla:5]Train:  Epoch: [9][150/184]\tTime  0.960 ( 0.902)\tData  0.079 ( 0.072)\tLoss 2.5195e-01 (2.8663e-01)\tAcc@1  87.50 ( 89.23)\n",
      "[xla:3]Train:  Epoch: [9][150/184]\tTime  0.924 ( 0.901)\tData  0.095 ( 0.074)\tLoss 2.0508e-01 (2.8868e-01)\tAcc@1  94.00 ( 89.72)\n",
      "[xla:1]Train:  Epoch: [9][150/184]\tTime  0.946 ( 0.904)\tData  0.064 ( 0.075)\tLoss 9.9609e-02 (2.8875e-01)\tAcc@1 100.00 ( 89.61)\n",
      "[xla:1]Train:  Epoch: [9][180/184]\tTime  0.878 ( 0.919)\tData  0.084 ( 0.077)\tLoss 3.1836e-01 (2.7543e-01)\tAcc@1  81.00 ( 90.17)\n",
      "[xla:3]Train:  Epoch: [9][180/184]\tTime  1.141 ( 0.917)\tData  0.121 ( 0.075)\tLoss 1.0254e-01 (2.7934e-01)\tAcc@1  94.00 ( 90.02)\n",
      "[xla:2]Train:  Epoch: [9][180/184]\tTime  0.990 ( 0.918)\tData  0.086 ( 0.074)\tLoss 2.6758e-01 (2.7787e-01)\tAcc@1  94.00 ( 89.41)\n",
      "[xla:6]Train:  Epoch: [9][180/184]\tTime  0.915 ( 0.919)\tData  0.071 ( 0.078)\tLoss 5.5078e-01 (3.1122e-01)\tAcc@1  75.00 ( 89.19)\n",
      "[xla:0]Train:  Epoch: [9][180/184]\tTime  1.221 ( 0.919)\tData  0.146 ( 0.075)\tLoss 2.6172e-01 (2.9270e-01)\tAcc@1  87.50 ( 89.22)\n",
      "[xla:7]Train:  Epoch: [9][180/184]\tTime  1.154 ( 0.920)\tData  0.097 ( 0.076)\tLoss 4.3359e-01 (2.9125e-01)\tAcc@1  87.50 ( 89.10)\n",
      "[xla:5]Train:  Epoch: [9][180/184]\tTime  1.056 ( 0.918)\tData  0.082 ( 0.074)\tLoss 3.3984e-01 (2.7795e-01)\tAcc@1  87.50 ( 89.68)\n",
      "[xla:4]Train:  Epoch: [9][180/184]\tTime  1.099 ( 0.919)\tData  0.118 ( 0.075)\tLoss 1.8359e-01 (2.8530e-01)\tAcc@1  87.50 ( 90.23)\n",
      "[xla:5]Validation: [0/9]\tTime  0.309 ( 0.309)\tLoss 1.7871e-01 (1.7871e-01)\tAcc@1  94.00 ( 94.00)\n",
      "[xla:7]Validation: [0/9]\tTime  0.236 ( 0.236)\tLoss 3.5742e-01 (3.5742e-01)\tAcc@1  81.00 ( 81.00)\n",
      "Finished training epoch 9\n",
      "Parallel Loader Created. Validating ...\n",
      "[xla:3]Validation: [0/9]\tTime  0.308 ( 0.308)\tLoss 4.1211e-01 (4.1211e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:2]Validation: [0/9]\tTime  0.373 ( 0.373)\tLoss 3.6719e-01 (3.6719e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:4]Validation: [0/9]\tTime  0.394 ( 0.394)\tLoss 2.8711e-01 (2.8711e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:6]Validation: [0/9]\tTime  0.351 ( 0.351)\tLoss 7.5195e-02 (7.5195e-02)\tAcc@1 100.00 (100.00)\n",
      "[xla:1]Validation: [0/9]\tTime  0.293 ( 0.293)\tLoss 7.8516e-01 (7.8516e-01)\tAcc@1  81.00 ( 81.00)\n",
      "[xla:0]Validation: [0/9]\tTime  0.331 ( 0.331)\tLoss 7.9297e-01 (7.9297e-01)\tAcc@1  87.50 ( 87.50)\n",
      "Saving Model ..\n",
      "Model Saved.\n",
      "Metric: CompileTime\n",
      "  TotalSamples: 12\n",
      "  Accumulator: 04m31s156ms826.321us\n",
      "  ValueRate: 111ms411.274us / second\n",
      "  Rate: 0.00633151 / second\n",
      "  Percentiles: 1%=010ms542.617us; 5%=010ms542.617us; 10%=026ms805.189us; 20%=027ms977.851us; 50%=08s443ms286.102us; 80%=21s088ms943.427us; 90%=01m11s561ms502.157us; 95%=01m12s312ms044.151us; 99%=01m12s312ms044.151us\n",
      "Metric: DeviceLockWait\n",
      "  TotalSamples: 5957\n",
      "  Accumulator: 035ms024.474us\n",
      "  ValueRate: 020.537us / second\n",
      "  Rate: 3.66414 / second\n",
      "  Percentiles: 1%=003.297us; 5%=003.795us; 10%=004.096us; 20%=004.455us; 50%=005.172us; 80%=006.222us; 90%=006.957us; 95%=008.249us; 99%=014.423us\n",
      "Metric: ExecuteTime\n",
      "  TotalSamples: 5937\n",
      "  Accumulator: 12m10s643ms603.209us\n",
      "  ValueRate: 397ms082.244us / second\n",
      "  Rate: 3.65089 / second\n",
      "  Percentiles: 1%=002ms073.779us; 5%=002ms427.541us; 10%=003ms753.956us; 20%=041ms050.727us; 50%=042ms003.019us; 80%=263ms872.225us; 90%=324ms878.520us; 95%=369ms630.636us; 99%=427ms015.156us\n",
      "Metric: InboundData\n",
      "  TotalSamples: 4255\n",
      "  Accumulator: 1.04GB\n",
      "  ValueRate: 3.54MB / second\n",
      "  Rate: 3.39509 / second\n",
      "  Percentiles: 1%=2.00B; 5%=2.00B; 10%=2.00B; 20%=2.00B; 50%=2.00B; 80%=2.00KB; 90%=2.00MB; 95%=2.00MB; 99%=8.00MB\n",
      "Metric: InputOutputAliasCount\n",
      "  TotalSamples: 8\n",
      "  Accumulator: 3557.00\n",
      "  ValueRate: 9.60 / second\n",
      "  Rate: 0.0215984 / second\n",
      "  Percentiles: 1%=1.00; 5%=1.00; 10%=1.00; 20%=1.00; 50%=4.00; 80%=1577.00; 90%=1577.00; 95%=1577.00; 99%=1577.00\n",
      "Metric: IrValueTensorToXlaData\n",
      "  TotalSamples: 790\n",
      "  Accumulator: 12s969ms958.266us\n",
      "  ValueRate: 818ms554.856us / second\n",
      "  Rate: 53.962 / second\n",
      "  Percentiles: 1%=871.689us; 5%=977.838us; 10%=001ms047.852us; 20%=001ms157.950us; 50%=001ms492.944us; 80%=010ms520.674us; 90%=024ms410.883us; 95%=031ms465.952us; 99%=057ms013.209us\n",
      "Metric: OutboundData\n",
      "  TotalSamples: 10494\n",
      "  Accumulator: 2.13GB\n",
      "  ValueRate: 27.13KB / second\n",
      "  Rate: 5.58575 / second\n",
      "  Percentiles: 1%=2.00B; 5%=2.00B; 10%=2.00B; 20%=2.00B; 50%=2.00B; 80%=8.00B; 90%=8.00B; 95%=24.12KB; 99%=96.50KB\n",
      "Metric: ReleaseDataHandlesTime\n",
      "  TotalSamples: 48953\n",
      "  Accumulator: 53s797ms869.423us\n",
      "  ValueRate: 038ms670.079us / second\n",
      "  Rate: 41.0163 / second\n",
      "  Percentiles: 1%=395.641us; 5%=436.848us; 10%=469.838us; 20%=517.948us; 50%=691.682us; 80%=001ms011.333us; 90%=001ms263.787us; 95%=002ms742.588us; 99%=006ms755.882us\n",
      "Metric: TensorsGraphSize\n",
      "  TotalSamples: 5937\n",
      "  Accumulator: 58154139.00\n",
      "  ValueRate: 31147.39 / second\n",
      "  Rate: 3.65038 / second\n",
      "  Percentiles: 1%=1.00; 5%=1.00; 10%=1.00; 20%=4507.00; 50%=4517.00; 80%=22038.00; 90%=22038.00; 95%=22038.00; 99%=22038.00\n",
      "Metric: TransferFromServerTime\n",
      "  TotalSamples: 4255\n",
      "  Accumulator: 14s101ms114.192us\n",
      "  ValueRate: 030ms288.044us / second\n",
      "  Rate: 3.39509 / second\n",
      "  Percentiles: 1%=001ms027.916us; 5%=001ms161.527us; 10%=001ms234.223us; 20%=001ms321.952us; 50%=002ms592.598us; 80%=002ms473.779us; 90%=008ms880.261us; 95%=027ms230.661us; 99%=048ms423.628us\n",
      "Metric: TransferToServerTime\n",
      "  TotalSamples: 10494\n",
      "  Accumulator: 10m14s883ms129.498us\n",
      "  ValueRate: 351ms362.921us / second\n",
      "  Rate: 5.58476 / second\n",
      "  Percentiles: 1%=969.608us; 5%=001ms107.038us; 10%=001ms222.576us; 20%=001ms387.266us; 50%=003ms101.013us; 80%=208ms414.553us; 90%=261ms249.418us; 95%=309ms619.920us; 99%=369ms699.757us\n",
      "Metric: TransferToServerTransformTime\n",
      "  TotalSamples: 10494\n",
      "  Accumulator: 14s380ms098.010us\n",
      "  ValueRate: 007ms301.357us / second\n",
      "  Rate: 5.58575 / second\n",
      "  Percentiles: 1%=049.722us; 5%=059.556us; 10%=066.193us; 20%=077.146us; 50%=114.547us; 80%=275.151us; 90%=004ms414.855us; 95%=009ms922.479us; 99%=017ms441.603us\n",
      "Counter: CachedCompile\n",
      "  Value: 5925\n",
      "Counter: CreateCompileHandles\n",
      "  Value: 12\n",
      "Counter: CreateDataHandles\n",
      "  Value: 2922235\n",
      "Counter: CreateXlaTensor\n",
      "  Value: 11828186\n",
      "Counter: DestroyDataHandles\n",
      "  Value: 2920387\n",
      "Counter: DestroyXlaTensor\n",
      "  Value: 11826612\n",
      "Counter: DeviceDataCacheMiss\n",
      "  Value: 7374\n",
      "Counter: MarkStep\n",
      "  Value: 1950\n",
      "Counter: ReleaseDataHandles\n",
      "  Value: 2920387\n",
      "Counter: UncachedCompile\n",
      "  Value: 12\n",
      "Counter: XRTAllocateFromTensor_Empty\n",
      "  Value: 39\n",
      "Counter: XrtCompile_Empty\n",
      "  Value: 128\n",
      "Counter: XrtExecuteChained_Empty\n",
      "  Value: 128\n",
      "Counter: XrtExecute_Empty\n",
      "  Value: 128\n",
      "Counter: XrtMemoryInfo_Empty\n",
      "  Value: 128\n",
      "Counter: XrtRead_Empty\n",
      "  Value: 128\n",
      "Counter: XrtReleaseAllocationHandle_Empty\n",
      "  Value: 128\n",
      "Counter: XrtReleaseCompileHandle_Empty\n",
      "  Value: 128\n",
      "Counter: XrtSessionCount\n",
      "  Value: 10\n",
      "Counter: XrtSubTuple_Empty\n",
      "  Value: 128\n",
      "Counter: aten::_local_scalar_dense\n",
      "  Value: 3860\n",
      "Counter: xla::_log_softmax\n",
      "  Value: 1930\n",
      "Counter: xla::_log_softmax_backward_data\n",
      "  Value: 1840\n",
      "Counter: xla::_softmax\n",
      "  Value: 46320\n",
      "Counter: xla::_softmax_backward_data\n",
      "  Value: 44160\n",
      "Counter: xla::_unsafe_view\n",
      "  Value: 370560\n",
      "Counter: xla::add\n",
      "  Value: 323230\n",
      "Counter: xla::add_\n",
      "  Value: 3170007\n",
      "Counter: xla::addcdiv_\n",
      "  Value: 723120\n",
      "Counter: xla::addcmul\n",
      "  Value: 96500\n",
      "Counter: xla::addcmul_\n",
      "  Value: 723120\n",
      "Counter: xla::addmm\n",
      "  Value: 3860\n",
      "Counter: xla::as_strided\n",
      "  Value: 395\n",
      "Counter: xla::bernoulli_\n",
      "  Value: 136160\n",
      "Counter: xla::bmm\n",
      "  Value: 269280\n",
      "Counter: xla::cat\n",
      "  Value: 1930\n",
      "Counter: xla::copy_\n",
      "  Value: 10835\n",
      "Counter: xla::cumsum\n",
      "  Value: 1930\n",
      "Counter: xla::div\n",
      "  Value: 92320\n",
      "Counter: xla::div_\n",
      "  Value: 136160\n",
      "Counter: xla::embedding\n",
      "  Value: 5790\n",
      "Counter: xla::embedding_dense_backward\n",
      "  Value: 5520\n",
      "Counter: xla::empty\n",
      "  Value: 152601\n",
      "Counter: xla::empty_strided\n",
      "  Value: 395\n",
      "Counter: xla::eq\n",
      "  Value: 1930\n",
      "Counter: xla::expand\n",
      "  Value: 189050\n",
      "Counter: xla::fill_\n",
      "  Value: 1840\n",
      "Counter: xla::gelu\n",
      "  Value: 46320\n",
      "Counter: xla::gelu_backward\n",
      "  Value: 44160\n",
      "Counter: xla::index_select\n",
      "  Value: 5790\n",
      "Counter: xla::max\n",
      "  Value: 1930\n",
      "Counter: xla::mean\n",
      "  Value: 1930\n",
      "Counter: xla::mm\n",
      "  Value: 811520\n",
      "Counter: xla::mul\n",
      "  Value: 552180\n",
      "Counter: xla::mul_\n",
      "  Value: 1448170\n",
      "Counter: xla::native_batch_norm\n",
      "  Value: 96500\n",
      "Counter: xla::native_batch_norm_backward\n",
      "  Value: 92000\n",
      "Counter: xla::native_layer_norm\n",
      "  Value: 96500\n",
      "Counter: xla::native_layer_norm_backward\n",
      "  Value: 92000\n",
      "Counter: xla::ne\n",
      "  Value: 1930\n",
      "Counter: xla::nll_loss_backward\n",
      "  Value: 1840\n",
      "Counter: xla::nll_loss_forward\n",
      "  Value: 3770\n",
      "Counter: xla::permute\n",
      "  Value: 361920\n",
      "Counter: xla::rsub\n",
      "  Value: 1930\n",
      "Counter: xla::scatter_\n",
      "  Value: 1840\n",
      "Counter: xla::select\n",
      "  Value: 1930\n",
      "Counter: xla::slice\n",
      "  Value: 11400\n",
      "Counter: xla::sqrt\n",
      "  Value: 723120\n",
      "Counter: xla::sub\n",
      "  Value: 92000\n",
      "Counter: xla::sum\n",
      "  Value: 452730\n",
      "Counter: xla::t\n",
      "  Value: 1084110\n",
      "Counter: xla::tanh\n",
      "  Value: 1930\n",
      "Counter: xla::topk\n",
      "  Value: 1930\n",
      "Counter: xla::transpose\n",
      "  Value: 267120\n",
      "Counter: xla::unsqueeze\n",
      "  Value: 9380\n",
      "Counter: xla::view\n",
      "  Value: 3201800\n",
      "Counter: xla::zero_\n",
      "  Value: 727283\n",
      "Metric: XrtAllocateFromTensor\n",
      "  TotalSamples: 126352\n",
      "  Accumulator: 03m11s861ms681.785us\n",
      "  Mean: 001ms463.199us\n",
      "  StdDev: 001ms053.146us\n",
      "  Rate: 57.3613 / second\n",
      "  Percentiles: 25%=412.414us; 50%=001ms254.191us; 80%=003ms687.817us; 90%=003ms877.416us; 95%=003ms016.698us; 99%=003ms337.836us\n",
      "Metric: XrtCompile\n",
      "  TotalSamples: 68\n",
      "  Accumulator: 25m11s693ms772.036us\n",
      "  Mean: 22s216ms070.177us\n",
      "  StdDev: 28s664ms960.823us\n",
      "  Rate: 0.0358779 / second\n",
      "  Percentiles: 25%=04s348ms270.457us; 50%=08s432ms569.073us; 80%=01m10s094ms325.000us; 90%=01m12s925ms120.586us; 95%=01m12s999ms113.065us; 99%=01m13s694ms572.950us\n",
      "Metric: XrtExecute\n",
      "  TotalSamples: 46474\n",
      "  Accumulator: 02h36m56s698ms397.890us\n",
      "  Mean: 093ms078.575us\n",
      "  StdDev: 121ms298.658us\n",
      "  Rate: 20.4575 / second\n",
      "  Percentiles: 25%=033ms302.591us; 50%=040ms274.626us; 80%=240ms264.320us; 90%=308ms769.181us; 95%=359ms496.731us; 99%=454ms384.315us\n",
      "Metric: XrtExecutorEvict\n",
      "  TotalSamples: 0\n",
      "  Accumulator: nanB\n",
      "  Mean: nanB\n",
      "  StdDev: nanB\n",
      "  Percentiles: \n",
      "Metric: XrtReadLiteral\n",
      "  TotalSamples: 31275\n",
      "  Accumulator: 16s050ms236.590us\n",
      "  Mean: 002ms208.395us\n",
      "  StdDev: 038ms863.287us\n",
      "  Rate: 19.3922 / second\n",
      "  Percentiles: 25%=410.516us; 50%=479.126us; 80%=583.460us; 90%=002ms106.980us; 95%=003ms821.576us; 99%=009ms371.959us\n",
      "Metric: XrtReleaseAllocation\n",
      "  TotalSamples: 371743\n",
      "  Accumulator: 01m19s340ms943.465us\n",
      "  Mean: 027.714us\n",
      "  StdDev: 034.957us\n",
      "  Rate: 301.558 / second\n",
      "  Percentiles: 25%=003.913us; 50%=018.073us; 80%=041.391us; 90%=064.899us; 95%=099.448us; 99%=164.533us\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _mp_fn(rank, flags):\n",
    "    # torch.set_default_tensor_type('torch.FloatTensor')\n",
    "    _run()\n",
    "\n",
    "FLAGS={}\n",
    "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDatasetRetriever(Dataset):\n",
    "    def __init__(self, df, encoded):\n",
    "        self.df = df\n",
    "        self.encoded = encoded\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):   \n",
    "        ids = self.encoded['input_ids'][index]\n",
    "        mask = self.encoded['attention_mask'][index]\n",
    "        return {\n",
    "            'ids':torch.tensor(ids),\n",
    "            'mask':torch.tensor(mask)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_BATCH_SIZE = 32\n",
    "\n",
    "test_text = test[['premise', 'hypothesis']].values.tolist()\n",
    "test_encoded = tokenizer.batch_encode_plus(\n",
    "    test_text,\n",
    "    pad_to_max_length=True,\n",
    "    max_length=MAX_LEN\n",
    ")\n",
    "\n",
    "test_dataset = TestDatasetRetriever(df=test, encoded=test_encoded)\n",
    "\n",
    "test_data_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    drop_last=False,\n",
    "    num_workers=4,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Load Serialized Model\n",
    "device = xm.xla_device()\n",
    "model = WRAPPED_MODEL.to(device).eval()\n",
    "model.load_state_dict(xser.load(\"model.bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:38<00:00,  4.21it/s]\n"
     ]
    }
   ],
   "source": [
    "test_preds = []\n",
    "\n",
    "for i, data in tqdm(enumerate(test_data_loader), total=len(test_data_loader)):\n",
    "    ids = data[\"ids\"]\n",
    "    mask = data[\"mask\"]\n",
    "    ids = ids.to(device, dtype=torch.long)\n",
    "    mask = mask.to(device, dtype=torch.long)\n",
    "    outputs = model(\n",
    "        input_ids = ids,\n",
    "        attention_mask = mask,\n",
    "    )\n",
    "    outputs_np = outputs.cpu().detach().numpy().tolist()\n",
    "    test_preds.extend(outputs_np)  \n",
    "    \n",
    "test_preds = torch.FloatTensor(test_preds)\n",
    "top1_prob, top1_label = torch.topk(test_preds, 1)\n",
    "y = top1_label.cpu().detach().numpy()\n",
    "sample_submission.prediction = y\n",
    "sample_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1518384326ca4e5abd58572db19c97b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fd4b641079a24e159899ef25d6944bf5",
       "placeholder": "​",
       "style": "IPY_MODEL_86dbcaa5ee7b4e8dbaeda6103fd57ad0",
       "value": " 5.07M/5.07M [00:05&lt;00:00, 999kB/s]"
      }
     },
     "1aa47f8b519748bb83d3c3ad5a014ba8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "24ae3629e72b455cb3c84fe29eccd9c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "3361d73970c446ac9f42176b71d310e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3935a3ce3e4144f0ab4477bac4f5808b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4dc26bebfb69467bab7e8ad25d050631": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a4e7682ff19246c4ac2d5be98497aa34",
       "max": 2244861551.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1aa47f8b519748bb83d3c3ad5a014ba8",
       "value": 2244861551.0
      }
     },
     "57e6e45e35fd421ab28fe5c6f5a84558": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_66146c2105a54d41a92dfed58ccdd1b1",
        "IPY_MODEL_5f49af9ac59d42918a696be8a3475751"
       ],
       "layout": "IPY_MODEL_3935a3ce3e4144f0ab4477bac4f5808b"
      }
     },
     "5f49af9ac59d42918a696be8a3475751": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f8990452484f4dec950a930bad6c0b53",
       "placeholder": "​",
       "style": "IPY_MODEL_6ffa0cc142554dbb849f0042c4ba2a54",
       "value": " 513/513 [04:29&lt;00:00, 1.90B/s]"
      }
     },
     "66146c2105a54d41a92dfed58ccdd1b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e8ba24aebaac45af8cc943d1bb0e6a5e",
       "max": 513.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_24ae3629e72b455cb3c84fe29eccd9c1",
       "value": 513.0
      }
     },
     "66543d3828504d5089241efd80428445": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6914d0c6eb7a478a935d5db1aa151b9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_66543d3828504d5089241efd80428445",
       "max": 5069051.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fcc9ecbaf47f44e4a829369c00594a40",
       "value": 5069051.0
      }
     },
     "6ffa0cc142554dbb849f0042c4ba2a54": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7fffb475851b4450878f9b4621af0152": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "86dbcaa5ee7b4e8dbaeda6103fd57ad0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "89987fa3dc8e43e08324d844462fe07e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6914d0c6eb7a478a935d5db1aa151b9d",
        "IPY_MODEL_1518384326ca4e5abd58572db19c97b9"
       ],
       "layout": "IPY_MODEL_7fffb475851b4450878f9b4621af0152"
      }
     },
     "9ac96619bc5842b08043b58084dec1c3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a4e7682ff19246c4ac2d5be98497aa34": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ae4d807abf2b4655850216b172fdab6b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3361d73970c446ac9f42176b71d310e8",
       "placeholder": "​",
       "style": "IPY_MODEL_9ac96619bc5842b08043b58084dec1c3",
       "value": " 2.24G/2.24G [04:11&lt;00:00, 8.92MB/s]"
      }
     },
     "afee6ab94cdd42c599902a1f1328321f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dca4f693fdfd4e74866c634f7a0fa58f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4dc26bebfb69467bab7e8ad25d050631",
        "IPY_MODEL_ae4d807abf2b4655850216b172fdab6b"
       ],
       "layout": "IPY_MODEL_afee6ab94cdd42c599902a1f1328321f"
      }
     },
     "e8ba24aebaac45af8cc943d1bb0e6a5e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8990452484f4dec950a930bad6c0b53": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fcc9ecbaf47f44e4a829369c00594a40": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "fd4b641079a24e159899ef25d6944bf5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
