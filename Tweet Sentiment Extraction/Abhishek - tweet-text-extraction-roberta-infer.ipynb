{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tokenizers\n",
    "import string\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 8\n",
    "EPOCHS = 10\n",
    "BERT_PATH = \"../input/roberta-base/\"\n",
    "MODEL_PATH = \"model.bin\"\n",
    "TRAINING_FILE = \"../input/train.csv\"\n",
    "TOKENIZER = tokenizers.ByteLevelBPETokenizer(\n",
    "    vocab_file=f\"{BERT_PATH}/vocab.json\", \n",
    "    merges_file=f\"{BERT_PATH}/merges.txt\", \n",
    "    lowercase=True,\n",
    "    add_prefix_space=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TweetModel, self).__init__()\n",
    "        self.bert = transformers.RobertaModel.from_pretrained(BERT_PATH)\n",
    "        self.l0 = nn.Linear(768, 2)\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        sequence_output, pooled_output = self.bert(\n",
    "            ids, \n",
    "            attention_mask=mask\n",
    "        )\n",
    "        logits = self.l0(sequence_output)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "\n",
    "        return start_logits, end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): TweetModel(\n",
       "    (bert): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (l0): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = TweetModel()\n",
    "model.to(device)\n",
    "model = nn.DataParallel(model)\n",
    "model.load_state_dict(torch.load(\"../input/roberta-tweet-model/model.bin\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset:\n",
    "    def __init__(self, tweet, sentiment, selected_text):\n",
    "        self.tweet = tweet\n",
    "        self.sentiment = sentiment\n",
    "        self.selected_text = selected_text\n",
    "        self.tokenizer = TOKENIZER\n",
    "        self.max_len = MAX_LEN\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tweet)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        # For Roberta, CLS = <s> and SEP = </s>\n",
    "        # Multiple strings: '<s>hi, my name is abhishek!!!</s></s>whats ur name</s>'\n",
    "        # id for <s>: 0\n",
    "        # id for </s>: 2\n",
    "    \n",
    "        tweet = \" \" + \" \".join(str(self.tweet[item]).split())\n",
    "        selected_text = \" \" + \" \".join(str(self.selected_text[item]).split())\n",
    "    \n",
    "        len_st = len(selected_text)\n",
    "        idx0 = -1\n",
    "        idx1 = -1\n",
    "        for ind in (i for i, e in enumerate(tweet) if e == selected_text[0]):\n",
    "            if tweet[ind: ind+len_st] == selected_text:\n",
    "                idx0 = ind\n",
    "                idx1 = ind + len_st\n",
    "                break\n",
    "        #print(f\"idx0: {idx0}\")\n",
    "        #print(f\"idx1: {idx1}\")\n",
    "        #print(f\"len_st: {len_st}\")\n",
    "        #print(f\"idxed tweet: {tweet[idx0: idx1]}\")\n",
    "\n",
    "        char_targets = [0] * len(tweet)\n",
    "        if idx0 != -1 and idx1 != -1:\n",
    "            for ct in range(idx0, idx1):\n",
    "                # if tweet[ct] != \" \":\n",
    "                char_targets[ct] = 1\n",
    "\n",
    "        #print(f\"char_targets: {char_targets}\")\n",
    "\n",
    "        tok_tweet = self.tokenizer.encode(tweet)\n",
    "        tok_tweet_tokens = tok_tweet.tokens\n",
    "        tok_tweet_ids = tok_tweet.ids\n",
    "        tok_tweet_offsets = tok_tweet.offsets\n",
    "        #print(tweet)\n",
    "        #print(selected_text)\n",
    "        #print(tok_tweet_tokens)\n",
    "        #print(f\"tok_tweet.offsets= {tok_tweet.offsets}\")\n",
    "        \n",
    "        targets = [0] * len(tok_tweet_ids)\n",
    "        target_idx = []\n",
    "        for j, (offset1, offset2) in enumerate(tok_tweet_offsets):\n",
    "            #print(\"**************\")\n",
    "            #print(offset1, offset2)\n",
    "            #print(tweet[offset1: offset2])\n",
    "            #print(char_targets[offset1: offset2])\n",
    "            #print(\"\".join(tok_tweet_tokens)[offset1: offset2])\n",
    "            #print(\"**************\")\n",
    "            if sum(char_targets[offset1: offset2]) > 0:\n",
    "                targets[j] = 1\n",
    "                target_idx.append(j)\n",
    "\n",
    "        #print(f\"targets= {targets}\")\n",
    "        #print(f\"target_idx= {target_idx}\")\n",
    "\n",
    "        #print(tok_tweet_tokens[target_idx[0]])\n",
    "        #print(tok_tweet_tokens[target_idx[-1]])\n",
    "        \n",
    "        targets_start = [0] * len(targets)\n",
    "        targets_end = [0] * len(targets)\n",
    "\n",
    "        non_zero = np.nonzero(targets)[0]\n",
    "        if len(non_zero) > 0:\n",
    "            targets_start[non_zero[0]] = 1\n",
    "            targets_end[non_zero[-1]] = 1\n",
    "        \n",
    "        #print(targets_start)\n",
    "        #print(targets_end)\n",
    "        #print(tok_tweet_tokens)\n",
    "        #print([x for jj, x in enumerate(tok_tweet_tokens) if targets_start[jj] == 1])\n",
    "        #print([x for jj, x in enumerate(tok_tweet_tokens) if targets_end[jj] == 1])\n",
    "        \n",
    "\n",
    "        # check padding:\n",
    "        # <s> pos/neg/neu </s> </s> tweet </s>\n",
    "        if len(tok_tweet_tokens) > self.max_len - 5:\n",
    "            tok_tweet_tokens = tok_tweet_tokens[:self.max_len - 5]\n",
    "            tok_tweet_ids = tok_tweet_ids[:self.max_len - 5]\n",
    "            targets_start = targets_start[:self.max_len - 5]\n",
    "            targets_end = targets_end[:self.max_len - 5]\n",
    "        \n",
    "        # positive: 1313\n",
    "        # negative: 2430\n",
    "        # neutral: 7974\n",
    "\n",
    "        sentiment_id = {\n",
    "            'positive': 1313,\n",
    "            'negative': 2430,\n",
    "            'neutral': 7974\n",
    "        }\n",
    "\n",
    "        tok_tweet_ids = [0] + [sentiment_id[self.sentiment[item]]] + [2] + [2] + tok_tweet_ids + [2]\n",
    "        targets_start = [0] + [0] + [0] + [0] + targets_start + [0]\n",
    "        targets_end = [0] + [0] + [0] + [0] + targets_end + [0]\n",
    "        token_type_ids = [0, 0, 0, 0] + [0] * (len(tok_tweet_ids) - 5) + [0]\n",
    "        mask = [1] * len(token_type_ids)\n",
    "\n",
    "        #print(\"Before padding\")\n",
    "        #print(f\"len(tok_tweet_ids)= {len(tok_tweet_ids)}\")\n",
    "        #print(f\"len(targets_start)= {len(targets_start)}\")\n",
    "        #print(f\"len(targets_end)= {len(targets_end)}\")\n",
    "        #print(f\"len(token_type_ids)= {len(token_type_ids)}\")\n",
    "        #print(f\"len(mask)= {len(mask)}\")\n",
    "\n",
    "        padding_length = self.max_len - len(tok_tweet_ids)\n",
    "        \n",
    "        tok_tweet_ids = tok_tweet_ids + ([1] * padding_length)\n",
    "        mask = mask + ([0] * padding_length)\n",
    "        token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        targets_start = targets_start + ([0] * padding_length)\n",
    "        targets_end = targets_end + ([0] * padding_length)\n",
    "\n",
    "        #print(\"After padding\")\n",
    "        #print(f\"len(tok_tweet_ids)= {len(tok_tweet_ids)}\")\n",
    "        #print(f\"len(targets_start)= {len(targets_start)}\")\n",
    "        #print(f\"len(targets_end)= {len(targets_end)}\")\n",
    "        #print(f\"len(token_type_ids)= {len(token_type_ids)}\")\n",
    "        #print(f\"len(mask)= {len(mask)}\")\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(tok_tweet_ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets_start': torch.tensor(targets_start, dtype=torch.float),\n",
    "            'targets_end': torch.tensor(targets_end, dtype=torch.float),\n",
    "            'padding_len': torch.tensor(padding_length, dtype=torch.long),\n",
    "            'orig_tweet': self.tweet[item],\n",
    "            'orig_selected': self.selected_text[item],\n",
    "            'sentiment': self.sentiment[item]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../input/tweet-sentiment-extraction/test.csv\")\n",
    "df_test.loc[:, \"selected_text\"] = df_test.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TweetDataset(\n",
    "        tweet=df_test.text.values,\n",
    "        sentiment=df_test.sentiment.values,\n",
    "        selected_text=df_test.selected_text.values\n",
    "    )\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=VALID_BATCH_SIZE,\n",
    "    num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:18<00:00, 23.36it/s]\n"
     ]
    }
   ],
   "source": [
    "all_outputs = []\n",
    "fin_outputs_start = []\n",
    "fin_outputs_end = []\n",
    "fin_padding_lens = []\n",
    "fin_orig_selected = []\n",
    "fin_orig_sentiment = []\n",
    "fin_orig_tweet = []\n",
    "fin_tweet_token_ids = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "    for bi, d in enumerate(tk0):\n",
    "        ids = d[\"ids\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        padding_len = d[\"padding_len\"]\n",
    "        sentiment = d[\"sentiment\"]\n",
    "        orig_selected = d[\"orig_selected\"]\n",
    "        orig_tweet = d[\"orig_tweet\"]\n",
    "        targets_start = d[\"targets_start\"]\n",
    "        targets_end = d[\"targets_end\"]\n",
    "\n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "        targets_start = targets_start.to(device, dtype=torch.float)\n",
    "        targets_end = targets_end.to(device, dtype=torch.float)\n",
    "\n",
    "        outputs_start, outputs_end = model(\n",
    "            ids=ids,\n",
    "            mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "\n",
    "        fin_outputs_start.append(torch.sigmoid(outputs_start).cpu().detach().numpy())\n",
    "        fin_outputs_end.append(torch.sigmoid(outputs_end).cpu().detach().numpy())\n",
    "        fin_padding_lens.extend(padding_len.cpu().detach().numpy().tolist())\n",
    "        fin_tweet_token_ids.append(ids.cpu().detach().numpy().tolist())\n",
    "\n",
    "        fin_orig_sentiment.extend(sentiment)\n",
    "        fin_orig_selected.extend(orig_selected)\n",
    "        fin_orig_tweet.extend(orig_tweet)\n",
    "\n",
    "fin_outputs_start = np.vstack(fin_outputs_start)\n",
    "fin_outputs_end = np.vstack(fin_outputs_end)\n",
    "fin_tweet_token_ids = np.vstack(fin_tweet_token_ids)\n",
    "jaccards = []\n",
    "threshold = 0.2\n",
    "for j in range(fin_outputs_start.shape[0]):\n",
    "    target_string = fin_orig_selected[j]\n",
    "    padding_len = fin_padding_lens[j]\n",
    "    sentiment_val = fin_orig_sentiment[j]\n",
    "    original_tweet = fin_orig_tweet[j]\n",
    "\n",
    "    if padding_len > 0:\n",
    "        mask_start = fin_outputs_start[j, 4:-1][:-padding_len] >= threshold\n",
    "        mask_end = fin_outputs_end[j, 4:-1][:-padding_len] >= threshold\n",
    "        tweet_token_ids = fin_tweet_token_ids[j, 4:-1][:-padding_len]\n",
    "    else:\n",
    "        mask_start = fin_outputs_start[j, 4:-1] >= threshold\n",
    "        mask_end = fin_outputs_end[j, 4:-1] >= threshold\n",
    "        tweet_token_ids = fin_tweet_token_ids[j, 4:-1][:-padding_len]\n",
    "\n",
    "    mask = [0] * len(mask_start)\n",
    "    idx_start = np.nonzero(mask_start)[0]\n",
    "    idx_end = np.nonzero(mask_end)[0]\n",
    "    if len(idx_start) > 0:\n",
    "        idx_start = idx_start[0]\n",
    "        if len(idx_end) > 0:\n",
    "            idx_end = idx_end[0]\n",
    "        else:\n",
    "            idx_end = idx_start\n",
    "    else:\n",
    "        idx_start = 0\n",
    "        idx_end = 0\n",
    "\n",
    "    for mj in range(idx_start, idx_end + 1):\n",
    "        mask[mj] = 1\n",
    "\n",
    "    output_tokens = [x for p, x in enumerate(tweet_token_ids) if mask[p] == 1]\n",
    "\n",
    "    filtered_output = TOKENIZER.decode(output_tokens)\n",
    "    filtered_output = filtered_output.strip().lower()\n",
    "\n",
    "    all_outputs.append(filtered_output.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"../input/tweet-sentiment-extraction/sample_submission.csv\")\n",
    "sample.loc[:, 'selected_text'] = all_outputs\n",
    "sample.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11aa4945ff</td>\n",
       "      <td>i wish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fd1db57dc0</td>\n",
       "      <td>i'm done.haha.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2524332d66</td>\n",
       "      <td>i'm concerned for that family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0fb19285b2</td>\n",
       "      <td>hey guys it's working no need to worry.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e6c9e5e3ab</td>\n",
       "      <td>26th february</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                            selected_text\n",
       "0  11aa4945ff                                   i wish\n",
       "1  fd1db57dc0                           i'm done.haha.\n",
       "2  2524332d66            i'm concerned for that family\n",
       "3  0fb19285b2  hey guys it's working no need to worry.\n",
       "4  e6c9e5e3ab                            26th february"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
