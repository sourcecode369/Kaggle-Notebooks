{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100  3569  100  3569    0     0  17325      0 --:--:-- --:--:-- --:--:-- 17325\r\n",
      "Updating TPU and VM. This may take around 2 minutes.\r\n",
      "Updating TPU runtime to nightly ...\r\n",
      "Found existing installation: torch 1.4.0\r\n",
      "Uninstalling torch-1.4.0:\r\n",
      "  Successfully uninstalled torch-1.4.0\r\n",
      "Found existing installation: torchvision 0.5.0\r\n",
      "Uninstalling torchvision-0.5.0:\r\n",
      "  Successfully uninstalled torchvision-0.5.0\r\n",
      "Copying gs://tpu-pytorch/wheels/torch-nightly-cp36-cp36m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/83.3 MiB.                                     \r\n",
      "Copying gs://tpu-pytorch/wheels/torch_xla-nightly-cp36-cp36m-linux_x86_64.whl...\r\n",
      "Done updating TPU runtime: <Response [200]>\r\n",
      "\r\n",
      "Operation completed over 1 objects/113.4 MiB.                                    \r\n",
      "Copying gs://tpu-pytorch/wheels/torchvision-nightly-cp36-cp36m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/2.5 MiB.                                      \r\n",
      "Processing ./torch-nightly-cp36-cp36m-linux_x86_64.whl\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torch==nightly) (1.18.1)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from torch==nightly) (0.18.2)\r\n",
      "\u001b[31mERROR: fastai 1.0.60 requires torchvision, which is not installed.\u001b[0m\r\n",
      "\u001b[31mERROR: catalyst 20.2.4 requires torchvision>=0.2.1, which is not installed.\u001b[0m\r\n",
      "\u001b[31mERROR: allennlp 0.9.0 has requirement spacy<2.2,>=2.1.0, but you'll have spacy 2.2.3 which is incompatible.\u001b[0m\r\n",
      "Installing collected packages: torch\r\n",
      "Successfully installed torch-1.5.0a0+618c621\r\n",
      "Processing ./torch_xla-nightly-cp36-cp36m-linux_x86_64.whl\r\n",
      "Installing collected packages: torch-xla\r\n",
      "Successfully installed torch-xla-1.6+c59c4d1\r\n",
      "Processing ./torchvision-nightly-cp36-cp36m-linux_x86_64.whl\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torchvision==nightly) (1.18.1)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.6/site-packages (from torchvision==nightly) (5.4.1)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from torchvision==nightly) (1.5.0a0+618c621)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from torchvision==nightly) (1.14.0)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from torch->torchvision==nightly) (0.18.2)\r\n",
      "Installing collected packages: torchvision\r\n",
      "Successfully installed torchvision-0.6.0a0+793b647\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "The following additional packages will be installed:\r\n",
      "  libopenblas-base\r\n",
      "The following NEW packages will be installed:\r\n",
      "  libomp5 libopenblas-base libopenblas-dev\r\n",
      "0 upgraded, 3 newly installed, 0 to remove and 34 not upgraded.\r\n",
      "Need to get 7831 kB of archives.\r\n",
      "After this operation, 92.2 MB of additional disk space will be used.\r\n",
      "Get:1 http://deb.debian.org/debian stretch/main amd64 libopenblas-base amd64 0.2.19-3 [3793 kB]\r\n",
      "Get:2 http://deb.debian.org/debian stretch/main amd64 libopenblas-dev amd64 0.2.19-3 [3809 kB]\r\n",
      "Get:3 http://deb.debian.org/debian stretch/main amd64 libomp5 amd64 3.9.1-1 [228 kB]\r\n",
      "Fetched 7831 kB in 0s (10.5 MB/s)\r\n",
      "debconf: delaying package configuration, since apt-utils is not installed\r\n",
      "Selecting previously unselected package libopenblas-base.\r\n",
      "(Reading database ... 74146 files and directories currently installed.)\r\n",
      "Preparing to unpack .../libopenblas-base_0.2.19-3_amd64.deb ...\r\n",
      "Unpacking libopenblas-base (0.2.19-3) ...\r\n",
      "Selecting previously unselected package libopenblas-dev.\r\n",
      "Preparing to unpack .../libopenblas-dev_0.2.19-3_amd64.deb ...\r\n",
      "Unpacking libopenblas-dev (0.2.19-3) ...\r\n",
      "Selecting previously unselected package libomp5:amd64.\r\n",
      "Preparing to unpack .../libomp5_3.9.1-1_amd64.deb ...\r\n",
      "Unpacking libomp5:amd64 (3.9.1-1) ...\r\n",
      "Setting up libomp5:amd64 (3.9.1-1) ...\r\n",
      "Processing triggers for libc-bin (2.24-11+deb9u4) ...\r\n",
      "Setting up libopenblas-base (0.2.19-3) ...\r\n",
      "update-alternatives: using /usr/lib/openblas-base/libblas.so.3 to provide /usr/lib/libblas.so.3 (libblas.so.3) in auto mode\r\n",
      "update-alternatives: using /usr/lib/openblas-base/liblapack.so.3 to provide /usr/lib/liblapack.so.3 (liblapack.so.3) in auto mode\r\n",
      "Setting up libopenblas-dev (0.2.19-3) ...\r\n",
      "update-alternatives: using /usr/lib/openblas-base/libblas.so to provide /usr/lib/libblas.so (libblas.so) in auto mode\r\n",
      "update-alternatives: using /usr/lib/openblas-base/liblapack.so to provide /usr/lib/liblapack.so (liblapack.so) in auto mode\r\n",
      "Processing triggers for libc-bin (2.24-11+deb9u4) ...\r\n"
     ]
    }
   ],
   "source": [
    "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "!python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "16a3df23-8416-46b5-8661-c52345005b6d",
    "_uuid": "993abe0b-2561-4abc-a6a2-b83d8dd4c846"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict, namedtuple\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "import joblib\n",
    "\n",
    "import logging\n",
    "import transformers\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule\n",
    "import sys\n",
    "from sklearn import metrics, model_selection\n",
    "\n",
    "import warnings\n",
    "import torch_xla\n",
    "import torch_xla.debug.metrics as met\n",
    "import torch_xla.distributed.data_parallel as dp\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.utils.utils as xu\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import torch_xla.test.test_utils as test_utils\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class AverageMeter:\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class BERTBaseUncased(nn.Module):\n",
    "    def __init__(self, bert_path):\n",
    "        super(BERTBaseUncased, self).__init__()\n",
    "        self.bert_path = bert_path\n",
    "        self.bert = transformers.BertModel.from_pretrained(self.bert_path)\n",
    "        self.bert_drop = nn.Dropout(0.3)\n",
    "        self.out = nn.Linear(768 * 2, 1)\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            ids,\n",
    "            mask,\n",
    "            token_type_ids\n",
    "    ):\n",
    "        o1, o2 = self.bert(\n",
    "            ids,\n",
    "            attention_mask=mask,\n",
    "            token_type_ids=token_type_ids)\n",
    "        \n",
    "        apool = torch.mean(o1, 1)\n",
    "        mpool, _ = torch.max(o1, 1)\n",
    "        cat = torch.cat((apool, mpool), 1)\n",
    "\n",
    "        bo = self.bert_drop(cat)\n",
    "        p2 = self.out(bo)\n",
    "        return p2\n",
    "\n",
    "\n",
    "class BERTDatasetTraining:\n",
    "    def __init__(self, comment_text, targets, tokenizer, max_length):\n",
    "        self.comment_text = comment_text\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comment_text)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        comment_text = str(self.comment_text[item])\n",
    "        comment_text = \" \".join(comment_text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            comment_text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "        )\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        \n",
    "        padding_length = self.max_length - len(ids)\n",
    "        \n",
    "        ids = ids + ([0] * padding_length)\n",
    "        mask = mask + ([0] * padding_length)\n",
    "        token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[item], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run():\n",
    "    def loss_fn(outputs, targets):\n",
    "        return nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n",
    "\n",
    "    def train_loop_fn(data_loader, model, optimizer, device, scheduler=None):\n",
    "        model.train()\n",
    "        for bi, d in enumerate(data_loader):\n",
    "            ids = d[\"ids\"]\n",
    "            mask = d[\"mask\"]\n",
    "            token_type_ids = d[\"token_type_ids\"]\n",
    "            targets = d[\"targets\"]\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "            targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(\n",
    "                ids=ids,\n",
    "                mask=mask,\n",
    "                token_type_ids=token_type_ids\n",
    "            )\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            if bi % 10 == 0:\n",
    "                xm.master_print(f'bi={bi}, loss={loss}')\n",
    "\n",
    "            loss.backward()\n",
    "            xm.optimizer_step(optimizer)\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "    def eval_loop_fn(data_loader, model, device):\n",
    "        model.eval()\n",
    "        fin_targets = []\n",
    "        fin_outputs = []\n",
    "        for bi, d in enumerate(data_loader):\n",
    "            ids = d[\"ids\"]\n",
    "            mask = d[\"mask\"]\n",
    "            token_type_ids = d[\"token_type_ids\"]\n",
    "            targets = d[\"targets\"]\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "            targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "            outputs = model(\n",
    "                ids=ids,\n",
    "                mask=mask,\n",
    "                token_type_ids=token_type_ids\n",
    "            )\n",
    "\n",
    "            targets_np = targets.cpu().detach().numpy().tolist()\n",
    "            outputs_np = outputs.cpu().detach().numpy().tolist()\n",
    "            fin_targets.extend(targets_np)\n",
    "            fin_outputs.extend(outputs_np)    \n",
    "\n",
    "        return fin_outputs, fin_targets\n",
    "\n",
    "    \n",
    "    MAX_LEN = 192\n",
    "    TRAIN_BATCH_SIZE = 128\n",
    "    EPOCHS = 2\n",
    "\n",
    "    df_train1 = pd.read_csv(\"../input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv\", usecols=[\"comment_text\", \"toxic\"]).fillna(\"none\")\n",
    "    df_train2 = pd.read_csv(\"../input/jigsaw-multilingual-toxic-comment-classification/jigsaw-unintended-bias-train.csv\", usecols=[\"comment_text\", \"toxic\"]).fillna(\"none\")\n",
    "    df_train_full = pd.concat([df_train1, df_train2], axis=0).reset_index(drop=True)\n",
    "    df_train = df_train_full.sample(frac=1).reset_index(drop=True).head(400000)\n",
    "    \n",
    "    df_valid = pd.read_csv('../input/jigsaw-multilingual-toxic-comment-classification/validation.csv')\n",
    "\n",
    "    tokenizer = transformers.BertTokenizer.from_pretrained(\"../input/bert-base-multilingual-uncased/\", do_lower_case=True)\n",
    "\n",
    "    train_targets = df_train.toxic.values\n",
    "    valid_targets = df_valid.toxic.values\n",
    "\n",
    "    train_dataset = BERTDatasetTraining(\n",
    "        comment_text=df_train.comment_text.values,\n",
    "        targets=train_targets,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=MAX_LEN\n",
    "    )\n",
    "\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "          train_dataset,\n",
    "          num_replicas=xm.xrt_world_size(),\n",
    "          rank=xm.get_ordinal(),\n",
    "          shuffle=True)\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "        sampler=train_sampler,\n",
    "        drop_last=True,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    valid_dataset = BERTDatasetTraining(\n",
    "        comment_text=df_valid.comment_text.values,\n",
    "        targets=valid_targets,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=MAX_LEN\n",
    "    )\n",
    "\n",
    "    valid_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "          valid_dataset,\n",
    "          num_replicas=xm.xrt_world_size(),\n",
    "          rank=xm.get_ordinal(),\n",
    "          shuffle=False)\n",
    "\n",
    "    valid_data_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=64,\n",
    "        sampler=valid_sampler,\n",
    "        drop_last=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    device = xm.xla_device()\n",
    "    model = BERTBaseUncased(bert_path=\"../input/bert-base-multilingual-uncased/\").to(device)\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
    "\n",
    "    lr = 3e-5 * xm.xrt_world_size()\n",
    "    num_train_steps = int(len(train_dataset) / TRAIN_BATCH_SIZE / xm.xrt_world_size() * EPOCHS)\n",
    "    xm.master_print(f'num_train_steps = {num_train_steps}, world_size={xm.xrt_world_size()}')\n",
    "\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=num_train_steps\n",
    "    )\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        para_loader = pl.ParallelLoader(train_data_loader, [device])\n",
    "        train_loop_fn(para_loader.per_device_loader(device), model, optimizer, device, scheduler=scheduler)\n",
    "\n",
    "        para_loader = pl.ParallelLoader(valid_data_loader, [device])\n",
    "        o, t = eval_loop_fn(para_loader.per_device_loader(device), model, device)\n",
    "        xm.save(model.state_dict(), \"model.bin\")\n",
    "        auc = metrics.roc_auc_score(np.array(t) >= 0.5, o)\n",
    "        xm.master_print(f'AUC = {auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"XRT_TPU_CONFIG\"] = \"tpu_worker;0;10.0.0.2:8470\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_steps = 6250, world_size=1\n",
      "bi=0, loss=0.8861145377159119\n",
      "bi=10, loss=0.41800597310066223\n",
      "bi=20, loss=0.3906218409538269\n",
      "bi=30, loss=0.34586820006370544\n",
      "bi=40, loss=0.3056565225124359\n",
      "bi=50, loss=0.264599472284317\n",
      "bi=60, loss=0.332931250333786\n",
      "bi=70, loss=0.2663206160068512\n",
      "bi=80, loss=0.2280682772397995\n",
      "bi=90, loss=0.2581605017185211\n",
      "bi=100, loss=0.24878698587417603\n",
      "bi=110, loss=0.25715944170951843\n",
      "bi=120, loss=0.2539026439189911\n",
      "bi=130, loss=0.23967242240905762\n",
      "bi=140, loss=0.2682662308216095\n",
      "bi=150, loss=0.22491095960140228\n",
      "bi=160, loss=0.2609179615974426\n",
      "bi=170, loss=0.3006545603275299\n",
      "bi=180, loss=0.24835970997810364\n",
      "bi=190, loss=0.28647103905677795\n",
      "bi=200, loss=0.25570228695869446\n",
      "bi=210, loss=0.22043831646442413\n",
      "bi=220, loss=0.3044733703136444\n",
      "bi=230, loss=0.29485002160072327\n",
      "bi=240, loss=0.22061733901500702\n",
      "bi=250, loss=0.28341948986053467\n",
      "bi=260, loss=0.2378649115562439\n",
      "bi=270, loss=0.2365652173757553\n",
      "bi=280, loss=0.23381909728050232\n",
      "bi=290, loss=0.20768947899341583\n",
      "bi=300, loss=0.21489407122135162\n",
      "bi=310, loss=0.23612850904464722\n",
      "bi=320, loss=0.3554133474826813\n",
      "bi=330, loss=0.165986567735672\n",
      "bi=340, loss=0.2250504046678543\n",
      "bi=350, loss=0.24654091894626617\n",
      "bi=360, loss=0.2169918268918991\n",
      "bi=370, loss=0.19102807343006134\n",
      "bi=380, loss=0.24948933720588684\n",
      "bi=390, loss=0.26486632227897644\n",
      "bi=400, loss=0.17602775990962982\n",
      "bi=410, loss=0.2010149210691452\n",
      "bi=420, loss=0.24303053319454193\n",
      "bi=430, loss=0.2368144989013672\n",
      "bi=440, loss=0.2700119614601135\n",
      "bi=450, loss=0.24027478694915771\n",
      "bi=460, loss=0.2586267292499542\n",
      "bi=470, loss=0.21466971933841705\n",
      "bi=480, loss=0.2637840509414673\n",
      "bi=490, loss=0.20540645718574524\n",
      "bi=500, loss=0.19896140694618225\n",
      "bi=510, loss=0.2056972086429596\n",
      "bi=520, loss=0.25334635376930237\n",
      "bi=530, loss=0.2585620880126953\n",
      "bi=540, loss=0.22111564874649048\n",
      "bi=550, loss=0.2727857232093811\n",
      "bi=560, loss=0.24968524277210236\n",
      "bi=570, loss=0.18980221450328827\n",
      "bi=580, loss=0.22941374778747559\n",
      "bi=590, loss=0.22663816809654236\n",
      "bi=600, loss=0.20992329716682434\n",
      "bi=610, loss=0.18573161959648132\n",
      "bi=620, loss=0.22903797030448914\n",
      "bi=630, loss=0.18555638194084167\n",
      "bi=640, loss=0.18411926925182343\n",
      "bi=650, loss=0.21875932812690735\n",
      "bi=660, loss=0.22402918338775635\n",
      "bi=670, loss=0.217715784907341\n",
      "bi=680, loss=0.3037432134151459\n",
      "bi=690, loss=0.1988707333803177\n",
      "bi=700, loss=0.2775295674800873\n",
      "bi=710, loss=0.19040146470069885\n",
      "bi=720, loss=0.20699487626552582\n",
      "bi=730, loss=0.21302486956119537\n",
      "bi=740, loss=0.26364290714263916\n",
      "bi=750, loss=0.21965189278125763\n",
      "bi=760, loss=0.2575526237487793\n",
      "bi=770, loss=0.19926346838474274\n",
      "bi=780, loss=0.24356889724731445\n",
      "bi=790, loss=0.23394334316253662\n",
      "bi=800, loss=0.22411516308784485\n",
      "bi=810, loss=0.20537474751472473\n",
      "bi=820, loss=0.21816615760326385\n",
      "bi=830, loss=0.2360089123249054\n",
      "bi=840, loss=0.26123887300491333\n",
      "bi=850, loss=0.26885485649108887\n",
      "bi=860, loss=0.24855422973632812\n",
      "bi=870, loss=0.198087677359581\n",
      "bi=880, loss=0.22091172635555267\n",
      "bi=890, loss=0.25346505641937256\n",
      "bi=900, loss=0.25739485025405884\n",
      "bi=910, loss=0.22817328572273254\n",
      "bi=920, loss=0.23024393618106842\n",
      "bi=930, loss=0.212747260928154\n",
      "bi=940, loss=0.24365787208080292\n",
      "bi=950, loss=0.18014445900917053\n",
      "bi=960, loss=0.23486045002937317\n",
      "bi=970, loss=0.2517540752887726\n",
      "bi=980, loss=0.25280261039733887\n",
      "bi=990, loss=0.2835334539413452\n",
      "bi=1000, loss=0.25178420543670654\n",
      "bi=1010, loss=0.20661617815494537\n",
      "bi=1020, loss=0.20510971546173096\n",
      "bi=1030, loss=0.21390798687934875\n",
      "bi=1040, loss=0.2392093986272812\n",
      "bi=1050, loss=0.20625191926956177\n",
      "bi=1060, loss=0.22944806516170502\n",
      "bi=1070, loss=0.24387262761592865\n",
      "bi=1080, loss=0.23858584463596344\n",
      "bi=1090, loss=0.24382708966732025\n",
      "bi=1100, loss=0.19013583660125732\n",
      "bi=1110, loss=0.24693380296230316\n",
      "bi=1120, loss=0.2301889955997467\n",
      "bi=1130, loss=0.2344682365655899\n",
      "bi=1140, loss=0.20840580761432648\n",
      "bi=1150, loss=0.25059980154037476\n",
      "bi=1160, loss=0.2740437090396881\n",
      "bi=1170, loss=0.23247312009334564\n",
      "bi=1180, loss=0.2212972342967987\n",
      "bi=1190, loss=0.22084328532218933\n",
      "bi=1200, loss=0.2384352833032608\n",
      "bi=1210, loss=0.22856047749519348\n",
      "bi=1220, loss=0.24834388494491577\n",
      "bi=1230, loss=0.2525028586387634\n",
      "bi=1240, loss=0.22107991576194763\n",
      "bi=1250, loss=0.19154956936836243\n",
      "bi=1260, loss=0.21867339313030243\n",
      "bi=1270, loss=0.1795448660850525\n",
      "bi=1280, loss=0.23019450902938843\n",
      "bi=1290, loss=0.1990375518798828\n",
      "bi=1300, loss=0.2613259255886078\n",
      "bi=1310, loss=0.19744651019573212\n",
      "bi=1320, loss=0.19766151905059814\n",
      "bi=1330, loss=0.2535308003425598\n",
      "bi=1340, loss=0.2194245159626007\n",
      "bi=1350, loss=0.23972374200820923\n",
      "bi=1360, loss=0.25705602765083313\n",
      "bi=1370, loss=0.18637412786483765\n",
      "bi=1380, loss=0.19372937083244324\n",
      "bi=1390, loss=0.1908046156167984\n",
      "bi=1400, loss=0.20504972338676453\n",
      "bi=1410, loss=0.25318342447280884\n",
      "bi=1420, loss=0.24831818044185638\n",
      "bi=1430, loss=0.2281506508588791\n",
      "bi=1440, loss=0.2190696895122528\n",
      "bi=1450, loss=0.2532479166984558\n",
      "bi=1460, loss=0.1754433661699295\n",
      "bi=1470, loss=0.2378576099872589\n",
      "bi=1480, loss=0.22449883818626404\n",
      "bi=1490, loss=0.23931893706321716\n",
      "bi=1500, loss=0.2146124541759491\n",
      "bi=1510, loss=0.20988744497299194\n",
      "bi=1520, loss=0.18340729176998138\n",
      "bi=1530, loss=0.2442123144865036\n",
      "bi=1540, loss=0.26949426531791687\n",
      "bi=1550, loss=0.23300103843212128\n",
      "bi=1560, loss=0.24592965841293335\n",
      "bi=1570, loss=0.2146458476781845\n",
      "bi=1580, loss=0.2183670848608017\n",
      "bi=1590, loss=0.2336532324552536\n",
      "bi=1600, loss=0.20929105579853058\n",
      "bi=1610, loss=0.23808258771896362\n",
      "bi=1620, loss=0.2524711489677429\n",
      "bi=1630, loss=0.17449729144573212\n",
      "bi=1640, loss=0.23984870314598083\n",
      "bi=1650, loss=0.20350700616836548\n",
      "bi=1660, loss=0.22966910898685455\n",
      "bi=1670, loss=0.2593304216861725\n",
      "bi=1680, loss=0.16203062236309052\n",
      "bi=1690, loss=0.2166384905576706\n",
      "bi=1700, loss=0.1732969731092453\n",
      "bi=1710, loss=0.2149386703968048\n",
      "bi=1720, loss=0.23144669830799103\n",
      "bi=1730, loss=0.20682458579540253\n",
      "bi=1740, loss=0.1957494467496872\n",
      "bi=1750, loss=0.2163880169391632\n",
      "bi=1760, loss=0.22497883439064026\n",
      "bi=1770, loss=0.20260870456695557\n",
      "bi=1780, loss=0.25864458084106445\n",
      "bi=1790, loss=0.19734880328178406\n",
      "bi=1800, loss=0.23095782101154327\n",
      "bi=1810, loss=0.22373366355895996\n",
      "bi=1820, loss=0.22971175611019135\n",
      "bi=1830, loss=0.2234334945678711\n",
      "bi=1840, loss=0.2140704095363617\n",
      "bi=1850, loss=0.27422356605529785\n",
      "bi=1860, loss=0.2649277150630951\n",
      "bi=1870, loss=0.25030970573425293\n",
      "bi=1880, loss=0.22698858380317688\n",
      "bi=1890, loss=0.28431612253189087\n",
      "bi=1900, loss=0.24375490844249725\n",
      "bi=1910, loss=0.23497451841831207\n",
      "bi=1920, loss=0.20656797289848328\n",
      "bi=1930, loss=0.18105804920196533\n",
      "bi=1940, loss=0.2238236963748932\n",
      "bi=1950, loss=0.21833935379981995\n",
      "bi=1960, loss=0.2617056369781494\n",
      "bi=1970, loss=0.24698901176452637\n",
      "bi=1980, loss=0.24479049444198608\n",
      "bi=1990, loss=0.2723502218723297\n",
      "bi=2000, loss=0.21239495277404785\n",
      "bi=2010, loss=0.25624147057533264\n",
      "bi=2020, loss=0.19258897006511688\n",
      "bi=2030, loss=0.209903746843338\n",
      "bi=2040, loss=0.2361767590045929\n",
      "bi=2050, loss=0.22318488359451294\n",
      "bi=2060, loss=0.21938592195510864\n",
      "bi=2070, loss=0.21161046624183655\n",
      "bi=2080, loss=0.2431352585554123\n",
      "bi=2090, loss=0.17661574482917786\n",
      "bi=2100, loss=0.23536038398742676\n",
      "bi=2110, loss=0.2965337932109833\n",
      "bi=2120, loss=0.25066033005714417\n",
      "bi=2130, loss=0.241603821516037\n",
      "bi=2140, loss=0.21988065540790558\n",
      "bi=2150, loss=0.22507795691490173\n",
      "bi=2160, loss=0.2190389633178711\n",
      "bi=2170, loss=0.19233016669750214\n",
      "bi=2180, loss=0.22824564576148987\n",
      "bi=2190, loss=0.19812287390232086\n",
      "bi=2200, loss=0.216505765914917\n",
      "bi=2210, loss=0.20029835402965546\n",
      "bi=2220, loss=0.21856820583343506\n",
      "bi=2230, loss=0.15497924387454987\n",
      "bi=2240, loss=0.20790034532546997\n",
      "bi=2250, loss=0.1898307353258133\n",
      "bi=2260, loss=0.20279870927333832\n",
      "bi=2270, loss=0.250796914100647\n",
      "bi=2280, loss=0.23329250514507294\n",
      "bi=2290, loss=0.2201656997203827\n",
      "bi=2300, loss=0.2600499987602234\n",
      "bi=2310, loss=0.23772640526294708\n",
      "bi=2320, loss=0.24663400650024414\n",
      "bi=2330, loss=0.24758462607860565\n",
      "bi=2340, loss=0.22414980828762054\n",
      "bi=2350, loss=0.22288011014461517\n",
      "bi=2360, loss=0.21126849949359894\n",
      "bi=2370, loss=0.25440049171447754\n",
      "bi=2380, loss=0.22259177267551422\n",
      "bi=2390, loss=0.2113291621208191\n",
      "bi=2400, loss=0.2105850726366043\n",
      "bi=2410, loss=0.2709639370441437\n",
      "bi=2420, loss=0.20886367559432983\n",
      "bi=2430, loss=0.22084614634513855\n",
      "bi=2440, loss=0.1761830747127533\n",
      "bi=2450, loss=0.21742939949035645\n",
      "bi=2460, loss=0.275691419839859\n",
      "bi=2470, loss=0.18202883005142212\n",
      "bi=2480, loss=0.2797088623046875\n",
      "bi=2490, loss=0.25934433937072754\n",
      "bi=2500, loss=0.18561910092830658\n",
      "bi=2510, loss=0.22512327134609222\n",
      "bi=2520, loss=0.23873677849769592\n",
      "bi=2530, loss=0.22698988020420074\n",
      "bi=2540, loss=0.24258388578891754\n",
      "bi=2550, loss=0.21013006567955017\n",
      "bi=2560, loss=0.22084808349609375\n",
      "bi=2570, loss=0.28930094838142395\n",
      "bi=2580, loss=0.21899063885211945\n",
      "bi=2590, loss=0.23745650053024292\n",
      "bi=2600, loss=0.17435210943222046\n",
      "bi=2610, loss=0.23667041957378387\n",
      "bi=2620, loss=0.28903573751449585\n",
      "bi=2630, loss=0.2628103196620941\n",
      "bi=2640, loss=0.2410789430141449\n",
      "bi=2650, loss=0.2520579993724823\n",
      "bi=2660, loss=0.1956080049276352\n",
      "bi=2670, loss=0.18641655147075653\n",
      "bi=2680, loss=0.2234463393688202\n",
      "bi=2690, loss=0.19026410579681396\n",
      "bi=2700, loss=0.19568800926208496\n",
      "bi=2710, loss=0.22578737139701843\n",
      "bi=2720, loss=0.24644292891025543\n",
      "bi=2730, loss=0.2543259263038635\n",
      "bi=2740, loss=0.16817641258239746\n",
      "bi=2750, loss=0.1941836029291153\n",
      "bi=2760, loss=0.20209680497646332\n",
      "bi=2770, loss=0.18868310749530792\n",
      "bi=2780, loss=0.21017126739025116\n",
      "bi=2790, loss=0.19555158913135529\n",
      "bi=2800, loss=0.21470484137535095\n",
      "bi=2810, loss=0.18956145644187927\n",
      "bi=2820, loss=0.1987144649028778\n",
      "bi=2830, loss=0.21883217990398407\n",
      "bi=2840, loss=0.2347257137298584\n",
      "bi=2850, loss=0.2013809233903885\n",
      "bi=2860, loss=0.25026848912239075\n",
      "bi=2870, loss=0.18999695777893066\n",
      "bi=2880, loss=0.24997788667678833\n",
      "bi=2890, loss=0.18526853621006012\n",
      "bi=2900, loss=0.23053231835365295\n",
      "bi=2910, loss=0.19498908519744873\n",
      "bi=2920, loss=0.21311263740062714\n",
      "bi=2930, loss=0.2750510573387146\n",
      "bi=2940, loss=0.17330332100391388\n",
      "bi=2950, loss=0.2271774709224701\n",
      "bi=2960, loss=0.2034318894147873\n",
      "bi=2970, loss=0.24381017684936523\n",
      "bi=2980, loss=0.24661624431610107\n",
      "bi=2990, loss=0.230485737323761\n",
      "bi=3000, loss=0.2312619388103485\n",
      "bi=3010, loss=0.271650105714798\n",
      "bi=3020, loss=0.17991256713867188\n",
      "bi=3030, loss=0.1920960694551468\n",
      "bi=3040, loss=0.20735396444797516\n",
      "bi=3050, loss=0.20090250670909882\n",
      "bi=3060, loss=0.28692424297332764\n",
      "bi=3070, loss=0.21001562476158142\n",
      "bi=3080, loss=0.2171156257390976\n",
      "bi=3090, loss=0.2695159614086151\n",
      "bi=3100, loss=0.22269456088542938\n",
      "bi=3110, loss=0.2830059826374054\n",
      "bi=3120, loss=0.19009503722190857\n",
      "AUC = 0.8294690228290762\n",
      "bi=0, loss=0.23235251009464264\n",
      "bi=10, loss=0.2777126729488373\n",
      "bi=20, loss=0.27852949500083923\n",
      "bi=30, loss=0.19926641881465912\n",
      "bi=40, loss=0.22089225053787231\n",
      "bi=50, loss=0.1802295744419098\n",
      "bi=60, loss=0.28501057624816895\n",
      "bi=70, loss=0.23654897511005402\n",
      "bi=80, loss=0.19026128947734833\n",
      "bi=90, loss=0.2006496638059616\n",
      "bi=100, loss=0.23033654689788818\n",
      "bi=110, loss=0.24430590867996216\n",
      "bi=120, loss=0.22023224830627441\n",
      "bi=130, loss=0.20614951848983765\n",
      "bi=140, loss=0.24838300049304962\n",
      "bi=150, loss=0.19868546724319458\n",
      "bi=160, loss=0.2382708638906479\n",
      "bi=170, loss=0.26622238755226135\n",
      "bi=180, loss=0.21304798126220703\n",
      "bi=190, loss=0.25627604126930237\n",
      "bi=200, loss=0.22803741693496704\n",
      "bi=210, loss=0.18652497231960297\n",
      "bi=220, loss=0.27558472752571106\n",
      "bi=230, loss=0.2417786866426468\n",
      "bi=240, loss=0.21681542694568634\n",
      "bi=250, loss=0.22886566817760468\n",
      "bi=260, loss=0.21945533156394958\n",
      "bi=270, loss=0.18796886503696442\n",
      "bi=280, loss=0.20573577284812927\n",
      "bi=290, loss=0.2012237161397934\n",
      "bi=300, loss=0.1982225924730301\n",
      "bi=310, loss=0.22033832967281342\n",
      "bi=320, loss=0.31665778160095215\n",
      "bi=330, loss=0.1511336863040924\n",
      "bi=340, loss=0.20956198871135712\n",
      "bi=350, loss=0.23412194848060608\n",
      "bi=360, loss=0.1912834644317627\n",
      "bi=370, loss=0.18214847147464752\n",
      "bi=380, loss=0.23582811653614044\n",
      "bi=390, loss=0.2489141821861267\n",
      "bi=400, loss=0.15536630153656006\n",
      "bi=410, loss=0.19010962545871735\n",
      "bi=420, loss=0.229429692029953\n",
      "bi=430, loss=0.21489299833774567\n",
      "bi=440, loss=0.24624037742614746\n",
      "bi=450, loss=0.22972504794597626\n",
      "bi=460, loss=0.24587135016918182\n",
      "bi=470, loss=0.19825154542922974\n",
      "bi=480, loss=0.24249248206615448\n",
      "bi=490, loss=0.18549951910972595\n",
      "bi=500, loss=0.1863696426153183\n",
      "bi=510, loss=0.20021763443946838\n",
      "bi=520, loss=0.22338929772377014\n",
      "bi=530, loss=0.23253312706947327\n",
      "bi=540, loss=0.2023388296365738\n",
      "bi=550, loss=0.220936581492424\n",
      "bi=560, loss=0.23152568936347961\n",
      "bi=570, loss=0.17517873644828796\n",
      "bi=580, loss=0.2180517464876175\n",
      "bi=590, loss=0.21426157653331757\n",
      "bi=600, loss=0.20020219683647156\n",
      "bi=610, loss=0.1718464195728302\n",
      "bi=620, loss=0.20421746373176575\n",
      "bi=630, loss=0.17406369745731354\n",
      "bi=640, loss=0.17505812644958496\n",
      "bi=650, loss=0.21487171947956085\n",
      "bi=660, loss=0.20928871631622314\n",
      "bi=670, loss=0.20116852223873138\n",
      "bi=680, loss=0.2743961811065674\n",
      "bi=690, loss=0.18571652472019196\n",
      "bi=700, loss=0.25470781326293945\n",
      "bi=710, loss=0.17290019989013672\n",
      "bi=720, loss=0.16608081758022308\n",
      "bi=730, loss=0.20828139781951904\n",
      "bi=740, loss=0.24394531548023224\n",
      "bi=750, loss=0.19317518174648285\n",
      "bi=760, loss=0.24101026356220245\n",
      "bi=770, loss=0.18331986665725708\n",
      "bi=780, loss=0.2252606600522995\n",
      "bi=790, loss=0.21482431888580322\n",
      "bi=800, loss=0.20351456105709076\n",
      "bi=810, loss=0.1918802410364151\n",
      "bi=820, loss=0.20374716818332672\n",
      "bi=830, loss=0.21241766214370728\n",
      "bi=840, loss=0.2495560199022293\n",
      "bi=850, loss=0.26149818301200867\n",
      "bi=860, loss=0.24497906863689423\n",
      "bi=870, loss=0.1859361231327057\n",
      "bi=880, loss=0.1914413869380951\n",
      "bi=890, loss=0.23611988127231598\n",
      "bi=900, loss=0.22915121912956238\n",
      "bi=910, loss=0.21494580805301666\n",
      "bi=920, loss=0.21417899429798126\n",
      "bi=930, loss=0.21062953770160675\n",
      "bi=940, loss=0.22228266298770905\n",
      "bi=950, loss=0.17600587010383606\n",
      "bi=960, loss=0.21920627355575562\n",
      "bi=970, loss=0.24696974456310272\n",
      "bi=980, loss=0.24212764203548431\n",
      "bi=990, loss=0.24356387555599213\n",
      "bi=1000, loss=0.23247002065181732\n",
      "bi=1010, loss=0.1871318817138672\n",
      "bi=1020, loss=0.1876765489578247\n",
      "bi=1030, loss=0.20438554883003235\n",
      "bi=1040, loss=0.23046644032001495\n",
      "bi=1050, loss=0.18837498128414154\n",
      "bi=1060, loss=0.21807032823562622\n",
      "bi=1070, loss=0.21833568811416626\n",
      "bi=1080, loss=0.21815671026706696\n",
      "bi=1090, loss=0.2331601083278656\n",
      "bi=1100, loss=0.17961937189102173\n",
      "bi=1110, loss=0.23962436616420746\n",
      "bi=1120, loss=0.22530487179756165\n",
      "bi=1130, loss=0.21278879046440125\n",
      "bi=1140, loss=0.18997497856616974\n",
      "bi=1150, loss=0.23010703921318054\n",
      "bi=1160, loss=0.25941532850265503\n",
      "bi=1170, loss=0.21590206027030945\n",
      "bi=1180, loss=0.19614428281784058\n",
      "bi=1190, loss=0.2065853774547577\n",
      "bi=1200, loss=0.2354452908039093\n",
      "bi=1210, loss=0.2270064800977707\n",
      "bi=1220, loss=0.24229514598846436\n",
      "bi=1230, loss=0.21940572559833527\n",
      "bi=1240, loss=0.211159348487854\n",
      "bi=1250, loss=0.18554913997650146\n",
      "bi=1260, loss=0.20456309616565704\n",
      "bi=1270, loss=0.17311224341392517\n",
      "bi=1280, loss=0.22023838758468628\n",
      "bi=1290, loss=0.18953761458396912\n",
      "bi=1300, loss=0.2256069779396057\n",
      "bi=1310, loss=0.18776361644268036\n",
      "bi=1320, loss=0.1797177493572235\n",
      "bi=1330, loss=0.23978570103645325\n",
      "bi=1340, loss=0.1972888559103012\n",
      "bi=1350, loss=0.22630544006824493\n",
      "bi=1360, loss=0.2566673457622528\n",
      "bi=1370, loss=0.15839511156082153\n",
      "bi=1380, loss=0.19080746173858643\n",
      "bi=1390, loss=0.1759895384311676\n",
      "bi=1400, loss=0.18786901235580444\n",
      "bi=1410, loss=0.23540224134922028\n",
      "bi=1420, loss=0.24260655045509338\n",
      "bi=1430, loss=0.19812926650047302\n",
      "bi=1440, loss=0.20164798200130463\n",
      "bi=1450, loss=0.24100899696350098\n",
      "bi=1460, loss=0.1673583984375\n",
      "bi=1470, loss=0.2238682210445404\n",
      "bi=1480, loss=0.20719873905181885\n",
      "bi=1490, loss=0.2357463240623474\n",
      "bi=1500, loss=0.20814426243305206\n",
      "bi=1510, loss=0.19242392480373383\n",
      "bi=1520, loss=0.16906265914440155\n",
      "bi=1530, loss=0.2225217968225479\n",
      "bi=1540, loss=0.2559918165206909\n",
      "bi=1550, loss=0.21198639273643494\n",
      "bi=1560, loss=0.24278025329113007\n",
      "bi=1570, loss=0.20865511894226074\n",
      "bi=1580, loss=0.2041175663471222\n",
      "bi=1590, loss=0.217897430062294\n",
      "bi=1600, loss=0.18040277063846588\n",
      "bi=1610, loss=0.21941593289375305\n",
      "bi=1620, loss=0.25503697991371155\n",
      "bi=1630, loss=0.16836506128311157\n",
      "bi=1640, loss=0.2335730940103531\n",
      "bi=1650, loss=0.19920821487903595\n",
      "bi=1660, loss=0.20054784417152405\n",
      "bi=1670, loss=0.2445763647556305\n",
      "bi=1680, loss=0.16102978587150574\n",
      "bi=1690, loss=0.21041440963745117\n",
      "bi=1700, loss=0.16880710422992706\n",
      "bi=1710, loss=0.20688274502754211\n",
      "bi=1720, loss=0.21494349837303162\n",
      "bi=1730, loss=0.1867694854736328\n",
      "bi=1740, loss=0.18854278326034546\n",
      "bi=1750, loss=0.21663711965084076\n",
      "bi=1760, loss=0.2142663300037384\n",
      "bi=1770, loss=0.17718110978603363\n",
      "bi=1780, loss=0.24084757268428802\n",
      "bi=1790, loss=0.17971853911876678\n",
      "bi=1800, loss=0.21820947527885437\n",
      "bi=1810, loss=0.21143580973148346\n",
      "bi=1820, loss=0.22486114501953125\n",
      "bi=1830, loss=0.20916903018951416\n",
      "bi=1840, loss=0.20204609632492065\n",
      "bi=1850, loss=0.2573149502277374\n",
      "bi=1860, loss=0.25023049116134644\n",
      "bi=1870, loss=0.22350157797336578\n",
      "bi=1880, loss=0.21658608317375183\n",
      "bi=1890, loss=0.27906352281570435\n",
      "bi=1900, loss=0.23429062962532043\n",
      "bi=1910, loss=0.20207926630973816\n",
      "bi=1920, loss=0.19350238144397736\n",
      "bi=1930, loss=0.17674720287322998\n",
      "bi=1940, loss=0.21241424977779388\n",
      "bi=1950, loss=0.2082776427268982\n",
      "bi=1960, loss=0.25442877411842346\n",
      "bi=1970, loss=0.226192444562912\n",
      "bi=1980, loss=0.22080913186073303\n",
      "bi=1990, loss=0.26288366317749023\n",
      "bi=2000, loss=0.2011430263519287\n",
      "bi=2010, loss=0.23994922637939453\n",
      "bi=2020, loss=0.172833651304245\n",
      "bi=2030, loss=0.1915859580039978\n",
      "bi=2040, loss=0.2338046431541443\n",
      "bi=2050, loss=0.22249208390712738\n",
      "bi=2060, loss=0.20788002014160156\n",
      "bi=2070, loss=0.20314563810825348\n",
      "bi=2080, loss=0.2349141240119934\n",
      "bi=2090, loss=0.17133529484272003\n",
      "bi=2100, loss=0.22630447149276733\n",
      "bi=2110, loss=0.2794867753982544\n",
      "bi=2120, loss=0.23096416890621185\n",
      "bi=2130, loss=0.22720156610012054\n",
      "bi=2140, loss=0.2176630049943924\n",
      "bi=2150, loss=0.21727043390274048\n",
      "bi=2160, loss=0.20956726372241974\n",
      "bi=2170, loss=0.1782514452934265\n",
      "bi=2180, loss=0.22202211618423462\n",
      "bi=2190, loss=0.1926983892917633\n",
      "bi=2200, loss=0.20480376482009888\n",
      "bi=2210, loss=0.20312240719795227\n",
      "bi=2220, loss=0.21418558061122894\n",
      "bi=2230, loss=0.14866073429584503\n",
      "bi=2240, loss=0.19142577052116394\n",
      "bi=2250, loss=0.17743059992790222\n",
      "bi=2260, loss=0.19404590129852295\n",
      "bi=2270, loss=0.24154247343540192\n",
      "bi=2280, loss=0.21955974400043488\n",
      "bi=2290, loss=0.20862333476543427\n",
      "bi=2300, loss=0.2494007796049118\n",
      "bi=2310, loss=0.22588615119457245\n",
      "bi=2320, loss=0.23018097877502441\n",
      "bi=2330, loss=0.23115801811218262\n",
      "bi=2340, loss=0.21210621297359467\n",
      "bi=2350, loss=0.20800861716270447\n",
      "bi=2360, loss=0.20445162057876587\n",
      "bi=2370, loss=0.23271596431732178\n",
      "bi=2380, loss=0.20957104861736298\n",
      "bi=2390, loss=0.18228761851787567\n",
      "bi=2400, loss=0.19861958920955658\n",
      "bi=2410, loss=0.2785585820674896\n",
      "bi=2420, loss=0.2033376544713974\n",
      "bi=2430, loss=0.21141165494918823\n",
      "bi=2440, loss=0.1698302924633026\n",
      "bi=2450, loss=0.21239247918128967\n",
      "bi=2460, loss=0.2598496973514557\n",
      "bi=2470, loss=0.17431840300559998\n",
      "bi=2480, loss=0.2778138518333435\n",
      "bi=2490, loss=0.2465926855802536\n",
      "bi=2500, loss=0.1724988967180252\n",
      "bi=2510, loss=0.20790520310401917\n",
      "bi=2520, loss=0.237839013338089\n",
      "bi=2530, loss=0.2194393128156662\n",
      "bi=2540, loss=0.22429659962654114\n",
      "bi=2550, loss=0.20669513940811157\n",
      "bi=2560, loss=0.21095839142799377\n",
      "bi=2570, loss=0.28140124678611755\n",
      "bi=2580, loss=0.21726864576339722\n",
      "bi=2590, loss=0.22515714168548584\n",
      "bi=2600, loss=0.16363409161567688\n",
      "bi=2610, loss=0.21955746412277222\n",
      "bi=2620, loss=0.27382761240005493\n",
      "bi=2630, loss=0.2608748972415924\n",
      "bi=2640, loss=0.22646646201610565\n",
      "bi=2650, loss=0.23320218920707703\n",
      "bi=2660, loss=0.1795061081647873\n",
      "bi=2670, loss=0.1734890341758728\n",
      "bi=2680, loss=0.22037889063358307\n",
      "bi=2690, loss=0.1802452951669693\n",
      "bi=2700, loss=0.18721581995487213\n",
      "bi=2710, loss=0.21892227232456207\n",
      "bi=2720, loss=0.2519918978214264\n",
      "bi=2730, loss=0.24675273895263672\n",
      "bi=2740, loss=0.1586170345544815\n",
      "bi=2750, loss=0.18163229525089264\n",
      "bi=2760, loss=0.19526125490665436\n",
      "bi=2770, loss=0.17921200394630432\n",
      "bi=2780, loss=0.1950259953737259\n",
      "bi=2790, loss=0.18375815451145172\n",
      "bi=2800, loss=0.21081678569316864\n",
      "bi=2810, loss=0.16313444077968597\n",
      "bi=2820, loss=0.1764756590127945\n",
      "bi=2830, loss=0.21472781896591187\n",
      "bi=2840, loss=0.22403864562511444\n",
      "bi=2850, loss=0.18737351894378662\n",
      "bi=2860, loss=0.23877562582492828\n",
      "bi=2870, loss=0.18029959499835968\n",
      "bi=2880, loss=0.24256379902362823\n",
      "bi=2890, loss=0.18671822547912598\n",
      "bi=2900, loss=0.22062012553215027\n",
      "bi=2910, loss=0.1848917007446289\n",
      "bi=2920, loss=0.20242968201637268\n",
      "bi=2930, loss=0.26933711767196655\n",
      "bi=2940, loss=0.17102722823619843\n",
      "bi=2950, loss=0.23084567487239838\n",
      "bi=2960, loss=0.1767892986536026\n",
      "bi=2970, loss=0.2381470650434494\n",
      "bi=2980, loss=0.2214604616165161\n",
      "bi=2990, loss=0.21682871878147125\n",
      "bi=3000, loss=0.21684366464614868\n",
      "bi=3010, loss=0.25220003724098206\n",
      "bi=3020, loss=0.1719290167093277\n",
      "bi=3030, loss=0.1747034639120102\n",
      "bi=3040, loss=0.20457910001277924\n",
      "bi=3050, loss=0.1890420764684677\n",
      "bi=3060, loss=0.2656923830509186\n",
      "bi=3070, loss=0.20012745261192322\n",
      "bi=3080, loss=0.2153175324201584\n",
      "bi=3090, loss=0.2599639296531677\n",
      "bi=3100, loss=0.2061840295791626\n",
      "bi=3110, loss=0.27012768387794495\n",
      "bi=3120, loss=0.187052384018898\n",
      "AUC = 0.8265668119753575\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "# Start training processes\n",
    "def _mp_fn(rank, flags):\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "    a = _run()\n",
    "\n",
    "FLAGS={}\n",
    "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=1, start_method='fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
