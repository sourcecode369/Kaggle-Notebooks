{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline by [@shonenkov](https://www.kaggle.com/shonenkov) using multi TPU on PyTorch/XLA\n",
    "\n",
    "Hi everyone!\n",
    "\n",
    "My name is Alex Shonenkov, I am researcher, in Love with NLP and DL.\n",
    "\n",
    "Recently I have published my ideas about this competition:\n",
    "\n",
    "- [[TPU-Inference] Super Fast XLMRoberta](https://www.kaggle.com/shonenkov/tpu-inference-super-fast-xlmroberta)\n",
    "- [NLP Albumentations](https://www.kaggle.com/shonenkov/nlp-albumentations)\n",
    "- [Hack with Parallel Corpus](https://www.kaggle.com/shonenkov/hack-with-parallel-corpus)\n",
    "- [Class Balance with PyTorch/XLA](https://www.kaggle.com/shonenkov/class-balance-with-pytorch-xla)\n",
    "- [open-subtitles-toxic-pseudo-labeling](https://www.kaggle.com/shonenkov/open-subtitles-toxic-pseudo-labeling)\n",
    "\n",
    "if you didn't see this kernels and datasets, I recommend to read all of them because it may help you for better understand this kernel and achieve success in competition :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN IDEA\n",
    "\n",
    "I spent a lot of time for create working kernel on the kaggle, I have tried to optimize it for 16GB RAM. But I was not able to do it for distributed MULTI TPU here, because of my datasets is too big for this aims.\n",
    "\n",
    "Here I would like to demonstrate my training pipeline without running and also I would like to provide you, my firends, prepared Colab notebook with kaggle structure!\n",
    "\n",
    "So lets start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100  3727  100  3727    0     0  49039      0 --:--:-- --:--:-- --:--:-- 49039\r\n",
      "Copying gs://tpu-pytorch/wheels/torch-nightly+20200420-cp36-cp36m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/86.8 MiB.                                     \r\n",
      "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200420-cp36-cp36m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/117.2 MiB.                                    \r\n",
      "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200420-cp36-cp36m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/2.4 MiB.                                      \r\n",
      "\u001b[31mERROR: fastai 1.0.60 requires torchvision, which is not installed.\u001b[0m\r\n",
      "\u001b[31mERROR: catalyst 20.3.3 requires torchvision>=0.2.1, which is not installed.\u001b[0m\r\n",
      "\u001b[31mERROR: allennlp 0.9.0 has requirement spacy<2.2,>=2.1.0, but you'll have spacy 2.2.3 which is incompatible.\u001b[0m\r\n",
      "debconf: delaying package configuration, since apt-utils is not installed\r\n"
     ]
    }
   ],
   "source": [
    "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py > /dev/null\n",
    "!python pytorch-xla-env-setup.py --version 20200420 --apt-packages libomp5 libopenblas-dev > /dev/null\n",
    "!pip install transformers==2.5.1 > /dev/null\n",
    "!pip install pandarallel > /dev/null\n",
    "!pip install catalyst==20.4.2 > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "os.environ['XLA_USE_BF16'] = \"1\"\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "import sklearn\n",
    "\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import XLMRobertaModel, XLMRobertaTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule\n",
    "from catalyst.data.sampler import DistributedSamplerWrapper, BalanceClassSampler\n",
    "\n",
    "import gc\n",
    "import re\n",
    "\n",
    "# !pip install nltk > /dev/null\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(nb_workers=4, progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "MAX_LENGTH = 224\n",
    "BACKBONE_PATH = 'xlm-roberta-large'\n",
    "ROOT_PATH = f'..'\n",
    "# ROOT_PATH = f'/content/drive/My Drive/jigsaw2020-kaggle-public-baseline' # for colab\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [NLP Albumentations](https://www.kaggle.com/shonenkov/nlp-albumentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "from random import shuffle\n",
    "import random\n",
    "import albumentations\n",
    "from albumentations.core.transforms_interface import DualTransform, BasicTransform\n",
    "\n",
    "\n",
    "LANGS = {\n",
    "    'en': 'english',\n",
    "    'it': 'italian', \n",
    "    'fr': 'french', \n",
    "    'es': 'spanish',\n",
    "    'tr': 'turkish', \n",
    "    'ru': 'russian',\n",
    "    'pt': 'portuguese'\n",
    "}\n",
    "\n",
    "def get_sentences(text, lang='en'):\n",
    "    return sent_tokenize(text, LANGS.get(lang, 'english'))\n",
    "\n",
    "def exclude_duplicate_sentences(text, lang='en'):\n",
    "    sentences = []\n",
    "    for sentence in get_sentences(text, lang):\n",
    "        sentence = sentence.strip()\n",
    "        if sentence not in sentences:\n",
    "            sentences.append(sentence)\n",
    "    return ' '.join(sentences)\n",
    "\n",
    "def clean_text(text, lang='en'):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[0-9\"]', '', text)\n",
    "    text = re.sub(r'#[\\S]+\\b', '', text)\n",
    "    text = re.sub(r'@[\\S]+\\b', '', text)\n",
    "    text = re.sub(r'https?\\S+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = exclude_duplicate_sentences(text, lang)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "class NLPTransform(BasicTransform):\n",
    "    \"\"\" Transform for nlp task.\"\"\"\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        return {\"data\": self.apply}\n",
    "    \n",
    "    def update_params(self, params, **kwargs):\n",
    "        if hasattr(self, \"interpolation\"):\n",
    "            params[\"interpolation\"] = self.interpolation\n",
    "        if hasattr(self, \"fill_value\"):\n",
    "            params[\"fill_value\"] = self.fill_value\n",
    "        return params\n",
    "\n",
    "    def get_sentences(self, text, lang='en'):\n",
    "        return sent_tokenize(text, LANGS.get(lang, 'english'))\n",
    "\n",
    "class ShuffleSentencesTransform(NLPTransform):\n",
    "    \"\"\" Do shuffle by sentence \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ShuffleSentencesTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        sentences = self.get_sentences(text, lang)\n",
    "        random.shuffle(sentences)\n",
    "        return ' '.join(sentences), lang\n",
    "\n",
    "class ExcludeDuplicateSentencesTransform(NLPTransform):\n",
    "    \"\"\" Exclude equal sentences \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ExcludeDuplicateSentencesTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        sentences = []\n",
    "        for sentence in self.get_sentences(text, lang):\n",
    "            sentence = sentence.strip()\n",
    "            if sentence not in sentences:\n",
    "                sentences.append(sentence)\n",
    "        return ' '.join(sentences), lang\n",
    "\n",
    "class ExcludeNumbersTransform(NLPTransform):\n",
    "    \"\"\" exclude any numbers \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ExcludeNumbersTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        text = re.sub(r'[0-9]', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text, lang\n",
    "\n",
    "class ExcludeHashtagsTransform(NLPTransform):\n",
    "    \"\"\" Exclude any hashtags with # \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ExcludeHashtagsTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        text = re.sub(r'#[\\S]+\\b', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text, lang\n",
    "\n",
    "class ExcludeUsersMentionedTransform(NLPTransform):\n",
    "    \"\"\" Exclude @users \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ExcludeUsersMentionedTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        text = re.sub(r'@[\\S]+\\b', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text, lang\n",
    "\n",
    "class ExcludeUrlsTransform(NLPTransform):\n",
    "    \"\"\" Exclude urls \"\"\"\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(ExcludeUrlsTransform, self).__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, lang = data\n",
    "        text = re.sub(r'https?\\S+', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text, lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Pseudo-labeling with open-subtitles](https://www.kaggle.com/shonenkov/hack-with-parallel-corpus)\n",
    "\n",
    "More noise with mix of languages can help. I have used [pseudo-labeled open-subtitles dataset](https://www.kaggle.com/shonenkov/open-subtitles-toxic-pseudo-labeling) for this approach. \n",
    "\n",
    "It is some analogue for Cutmix in Computer Vision:\n",
    "\n",
    "<img src='https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F2605845%2Ff29492171d83dfa6b6fcae2af414fcf8%2FCutmix_exmaple.png?generation=1579343294489994&alt=media' align=\"left\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynthesicOpenSubtitlesTransform(NLPTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        super(SynthesicOpenSubtitlesTransform, self).__init__(always_apply, p)\n",
    "        df = pd.read_csv(f'{ROOT_PATH}/input/open-subtitles-toxic-pseudo-labeling/open-subtitles-synthesic.csv', index_col='id')[['comment_text', 'toxic', 'lang']]\n",
    "        df = df[~df['comment_text'].isna()]\n",
    "        df['comment_text'] = df.parallel_apply(lambda x: clean_text(x['comment_text'], x['lang']), axis=1)\n",
    "        df = df.drop_duplicates(subset='comment_text')\n",
    "        df['toxic'] = df['toxic'].round().astype(np.int)\n",
    "\n",
    "        self.synthesic_toxic = df[df['toxic'] == 1].comment_text.values\n",
    "        self.synthesic_non_toxic = df[df['toxic'] == 0].comment_text.values\n",
    "\n",
    "        del df\n",
    "        gc.collect();\n",
    "\n",
    "    def generate_synthesic_sample(self, text, toxic):\n",
    "        texts = [text]\n",
    "        if toxic == 0:\n",
    "            for i in range(random.randint(1,5)):\n",
    "                texts.append(random.choice(self.synthesic_non_toxic))\n",
    "        else:\n",
    "            for i in range(random.randint(0,2)):\n",
    "                texts.append(random.choice(self.synthesic_non_toxic))\n",
    "            \n",
    "            for i in range(random.randint(1,3)):\n",
    "                texts.append(random.choice(self.synthesic_toxic))\n",
    "        random.shuffle(texts)\n",
    "        return ' '.join(texts)\n",
    "\n",
    "    def apply(self, data, **params):\n",
    "        text, toxic = data\n",
    "        text = self.generate_synthesic_sample(text, toxic)\n",
    "        return text, toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8c1fce317c496f9091c45da6e8fcec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_train_transforms():\n",
    "    return albumentations.Compose([\n",
    "        ExcludeUsersMentionedTransform(p=0.95),\n",
    "        ExcludeUrlsTransform(p=0.95),\n",
    "        ExcludeNumbersTransform(p=0.95),\n",
    "        ExcludeHashtagsTransform(p=0.95),\n",
    "        ExcludeDuplicateSentencesTransform(p=0.95),\n",
    "    ], p=1.0)\n",
    "\n",
    "def get_synthesic_transforms():\n",
    "    return SynthesicOpenSubtitlesTransform(p=0.5)\n",
    "\n",
    "\n",
    "train_transforms = get_train_transforms();\n",
    "synthesic_transforms = get_synthesic_transforms()\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(BACKBONE_PATH)\n",
    "shuffle_transforms = ShuffleSentencesTransform(always_apply=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(size, target):\n",
    "    vec = torch.zeros(size, dtype=torch.float32)\n",
    "    vec[target] = 1.\n",
    "    return vec\n",
    "\n",
    "class DatasetRetriever(Dataset):\n",
    "\n",
    "    def __init__(self, labels_or_ids, comment_texts, langs, use_train_transforms=False, test=False):\n",
    "        self.test = test\n",
    "        self.labels_or_ids = labels_or_ids\n",
    "        self.comment_texts = comment_texts\n",
    "        self.langs = langs\n",
    "        self.use_train_transforms = use_train_transforms\n",
    "        \n",
    "    def get_tokens(self, text):\n",
    "        encoded = tokenizer.encode_plus(\n",
    "            text, \n",
    "            add_special_tokens=True, \n",
    "            max_length=MAX_LENGTH, \n",
    "            pad_to_max_length=True\n",
    "        )\n",
    "        return encoded['input_ids'], encoded['attention_mask']\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.comment_texts.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.comment_texts[idx]\n",
    "        lang = self.langs[idx]\n",
    "        if self.test is False:\n",
    "            label = self.labels_or_ids[idx]\n",
    "            target = onehot(2, label)\n",
    "\n",
    "        if self.use_train_transforms:\n",
    "            text, _ = train_transforms(data=(text, lang))['data']\n",
    "            tokens, attention_mask = self.get_tokens(str(text))\n",
    "            token_length = sum(attention_mask)\n",
    "            if token_length > 0.8*MAX_LENGTH:\n",
    "                text, _ = shuffle_transforms(data=(text, lang))['data']\n",
    "            elif token_length < 60:\n",
    "                text, _ = synthesic_transforms(data=(text, label))['data']\n",
    "            else:\n",
    "                tokens, attention_mask = torch.tensor(tokens), torch.tensor(attention_mask)\n",
    "                return target, tokens, attention_mask\n",
    "\n",
    "        tokens, attention_mask = self.get_tokens(str(text))\n",
    "        tokens, attention_mask = torch.tensor(tokens), torch.tensor(attention_mask)\n",
    "\n",
    "        if self.test is False:\n",
    "            return target, tokens, attention_mask\n",
    "        return self.labels_or_ids[idx], tokens, attention_mask\n",
    "\n",
    "    def get_labels(self):\n",
    "        return list(np.char.add(self.labels_or_ids.astype(str), self.langs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here I have used [this kernel](https://www.kaggle.com/shonenkov/prepare-training-data) for merging all train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:2: DtypeWarning:\n",
      "\n",
      "Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0.])\n",
      "torch.Size([224])\n",
      "torch.Size([224])\n",
      "CPU times: user 17.9 s, sys: 2.45 s, total: 20.4 s\n",
      "Wall time: 20.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_train = pd.read_csv(f'{ROOT_PATH}/input/jigsaw-public-baseline-train-data/train_data.csv')\n",
    "\n",
    "\n",
    "train_dataset = DatasetRetriever(\n",
    "    labels_or_ids=df_train['toxic'].values, \n",
    "    comment_texts=df_train['comment_text'].values, \n",
    "    langs=df_train['lang'].values,\n",
    "    use_train_transforms=True,\n",
    ")\n",
    "\n",
    "del df_train\n",
    "gc.collect();\n",
    "\n",
    "for targets, tokens, attention_masks in train_dataset:\n",
    "    break\n",
    "    \n",
    "print(targets)\n",
    "print(tokens.shape)\n",
    "print(attention_masks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Balance\n",
    "\n",
    "After some experiments I have decided that [class balance](https://www.kaggle.com/shonenkov/class-balance-with-pytorch-xla) in this competition is very important. Also I noticed impact if use balancing dataset by languages.\n",
    "\n",
    "Here you can see unique values for get_labels method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0en', '0es', '0fr', '0it', '0pt', '0ru', '0tr', '1en', '1es',\n",
       "       '1fr', '1it', '1pt', '1ru', '1tr'], dtype='<U3')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_dataset.get_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0.])\n",
      "torch.Size([224])\n",
      "torch.Size([224])\n"
     ]
    }
   ],
   "source": [
    "df_val = pd.read_csv(f'{ROOT_PATH}/input/jigsaw-multilingual-toxic-comment-classification/validation.csv', index_col='id')\n",
    "\n",
    "validation_tune_dataset = DatasetRetriever(\n",
    "    labels_or_ids=df_val['toxic'].values, \n",
    "    comment_texts=df_val['comment_text'].values, \n",
    "    langs=df_val['lang'].values,\n",
    "    use_train_transforms=True,\n",
    ")\n",
    "\n",
    "df_val['comment_text'] = df_val.parallel_apply(lambda x: clean_text(x['comment_text'], x['lang']), axis=1)\n",
    "\n",
    "validation_dataset = DatasetRetriever(\n",
    "    labels_or_ids=df_val['toxic'].values, \n",
    "    comment_texts=df_val['comment_text'].values, \n",
    "    langs=df_val['lang'].values,\n",
    "    use_train_transforms=False,\n",
    ")\n",
    "\n",
    "del df_val\n",
    "gc.collect();\n",
    "\n",
    "for targets, tokens, attention_masks in validation_dataset:\n",
    "    break\n",
    "\n",
    "print(targets)\n",
    "print(tokens.shape)\n",
    "print(attention_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([224])\n",
      "torch.Size([224])\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(f'{ROOT_PATH}/input/jigsaw-multilingual-toxic-comment-classification/test.csv', index_col='id')\n",
    "df_test['comment_text'] = df_test.parallel_apply(lambda x: clean_text(x['content'], x['lang']), axis=1)\n",
    "\n",
    "test_dataset = DatasetRetriever(\n",
    "    labels_or_ids=df_test.index.values, \n",
    "    comment_texts=df_test['comment_text'].values, \n",
    "    langs=df_test['lang'].values,\n",
    "    use_train_transforms=False,\n",
    "    test=True\n",
    ")\n",
    "\n",
    "del df_test\n",
    "gc.collect();\n",
    "\n",
    "for ids, tokens, attention_masks in test_dataset:\n",
    "    break\n",
    "\n",
    "print(ids)\n",
    "print(tokens.shape)\n",
    "print(attention_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocAucMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.y_true = np.array([0,1])\n",
    "        self.y_pred = np.array([0.5,0.5])\n",
    "        self.score = 0\n",
    "\n",
    "    def update(self, y_true, y_pred):\n",
    "        y_true = y_true.cpu().numpy().argmax(axis=1)\n",
    "        y_pred = nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,1]\n",
    "        self.y_true = np.hstack((self.y_true, y_true))\n",
    "        self.y_pred = np.hstack((self.y_pred, y_pred))\n",
    "        self.score = sklearn.metrics.roc_auc_score(self.y_true, self.y_pred, labels=np.array([0, 1]))\n",
    "    \n",
    "    @property\n",
    "    def avg(self):\n",
    "        return self.score\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Smoothing is all you need\n",
    "Now we can use translating and augmenting data for training with this Loss: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    def __init__(self, smoothing = 0.1):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        if self.training:\n",
    "            x = x.float()\n",
    "            target = target.float()\n",
    "            logprobs = torch.nn.functional.log_softmax(x, dim = -1)\n",
    "            nll_loss = -logprobs * target\n",
    "            nll_loss = nll_loss.sum(-1)\n",
    "            smooth_loss = -logprobs.mean(dim=-1)\n",
    "            loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return torch.nn.functional.cross_entropy(x, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom TPU Fitter\n",
    "\n",
    "<img src='https://image.made-in-china.com/202f0j10dPkYMNLhhabE/Children-Bicycle-Baby-Kids-BMX-Bike.jpg' width=250 align=\"left\"> \n",
    "\n",
    "P.S. Lets go to do contributing [Catalyst](https://github.com/catalyst-team/catalyst) with TPU backend :)\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/catalyst-team/catalyst-pics/master/pics/catalyst_logo.png' width=100 align=\"center\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "\n",
    "from catalyst.data.sampler import DistributedSamplerWrapper, BalanceClassSampler\n",
    "\n",
    "class TPUFitter:\n",
    "    \n",
    "    def __init__(self, model, device, config):\n",
    "        if not os.path.exists('node_submissions'):\n",
    "            os.makedirs('node_submissions')\n",
    "\n",
    "        self.config = config\n",
    "        self.epoch = 0\n",
    "        self.log_path = 'log.txt'\n",
    "\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "        param_optimizer = list(self.model.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "\n",
    "        self.optimizer = AdamW(optimizer_grouped_parameters, lr=config.lr*xm.xrt_world_size())\n",
    "        self.scheduler = config.SchedulerClass(self.optimizer, **config.scheduler_params)\n",
    "\n",
    "        self.criterion = config.criterion\n",
    "        xm.master_print(f'Fitter prepared. Device is {self.device}')\n",
    "\n",
    "    def fit(self, train_loader, validation_loader):\n",
    "        for e in range(self.config.n_epochs):\n",
    "            if self.config.verbose:\n",
    "                lr = self.optimizer.param_groups[0]['lr']\n",
    "                timestamp = datetime.utcnow().isoformat()\n",
    "                self.log(f'\\n{timestamp}\\nLR: {lr}')\n",
    "\n",
    "            t = time.time()\n",
    "            para_loader = pl.ParallelLoader(train_loader, [self.device])\n",
    "            losses, final_scores = self.train_one_epoch(para_loader.per_device_loader(self.device))\n",
    "            \n",
    "            self.log(f'[RESULT]: Train. Epoch: {self.epoch}, loss: {losses.avg:.5f}, final_score: {final_scores.avg:.5f}, time: {(time.time() - t):.5f}')\n",
    "\n",
    "            t = time.time()\n",
    "            para_loader = pl.ParallelLoader(validation_loader, [self.device])\n",
    "            losses, final_scores = self.validation(para_loader.per_device_loader(self.device))\n",
    "\n",
    "            self.log(f'[RESULT]: Validation. Epoch: {self.epoch}, loss: {losses.avg:.5f}, final_score: {final_scores.avg:.5f}, time: {(time.time() - t):.5f}')\n",
    "\n",
    "            if self.config.validation_scheduler:\n",
    "                self.scheduler.step(metrics=final_scores.avg)\n",
    "\n",
    "            self.epoch += 1\n",
    "    \n",
    "    def run_tuning_and_inference(self, test_loader, validation_tune_loader):\n",
    "        for e in range(2):\n",
    "            self.optimizer.param_groups[0]['lr'] = self.config.lr*xm.xrt_world_size() / (e + 1)\n",
    "            para_loader = pl.ParallelLoader(validation_tune_loader, [self.device])\n",
    "            losses, final_scores = self.train_one_epoch(para_loader.per_device_loader(self.device))\n",
    "            para_loader = pl.ParallelLoader(test_loader, [self.device])\n",
    "            self.run_inference(para_loader.per_device_loader(self.device))\n",
    "\n",
    "    def validation(self, val_loader):\n",
    "        self.model.eval()\n",
    "        losses = AverageMeter()\n",
    "        final_scores = RocAucMeter()\n",
    "\n",
    "        t = time.time()\n",
    "        for step, (targets, inputs, attention_masks) in enumerate(val_loader):\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    xm.master_print(\n",
    "                        f'Valid Step {step}, loss: ' + \\\n",
    "                        f'{losses.avg:.5f}, final_score: {final_scores.avg:.5f}, ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}'\n",
    "                    )\n",
    "            with torch.no_grad():\n",
    "                inputs = inputs.to(self.device, dtype=torch.long) \n",
    "                attention_masks = attention_masks.to(self.device, dtype=torch.long) \n",
    "                targets = targets.to(self.device, dtype=torch.float) \n",
    "\n",
    "                outputs = self.model(inputs, attention_masks)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                \n",
    "                batch_size = inputs.size(0)\n",
    "\n",
    "                final_scores.update(targets, outputs)\n",
    "                losses.update(loss.detach().item(), batch_size)\n",
    "                \n",
    "        return losses, final_scores\n",
    "         \n",
    "    def train_one_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "\n",
    "        losses = AverageMeter()\n",
    "        final_scores = RocAucMeter()\n",
    "        t = time.time()\n",
    "        for step, (targets, inputs, attention_masks) in enumerate(train_loader):   \n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    self.log(\n",
    "                        f'Train Step {step}, loss: ' + \\\n",
    "                        f'{losses.avg:.5f}, final_score: {final_scores.avg:.5f}, ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}'\n",
    "                    )\n",
    "\n",
    "            inputs = inputs.to(self.device, dtype=torch.long)\n",
    "            attention_masks = attention_masks.to(self.device, dtype=torch.long)\n",
    "            targets = targets.to(self.device, dtype=torch.float)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            outputs = self.model(inputs, attention_masks)\n",
    "            loss = self.criterion(outputs, targets)\n",
    "\n",
    "            batch_size = inputs.size(0)\n",
    "            \n",
    "            final_scores.update(targets, outputs)\n",
    "            \n",
    "            losses.update(loss.detach().item(), batch_size)\n",
    "\n",
    "            loss.backward()\n",
    "            xm.optimizer_step(self.optimizer)\n",
    "\n",
    "            if self.config.step_scheduler:\n",
    "                self.scheduler.step()\n",
    "        \n",
    "        self.model.eval()\n",
    "        self.save('last-checkpoint.bin')\n",
    "        return losses, final_scores\n",
    "\n",
    "    def run_inference(self, test_loader):\n",
    "        self.model.eval()\n",
    "        result = {'id': [], 'toxic': []}\n",
    "        t = time.time()\n",
    "        for step, (ids, inputs, attention_masks) in enumerate(test_loader):\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    xm.master_print(f'Prediction Step {step}, time: {(time.time() - t):.5f}')\n",
    "\n",
    "            with torch.no_grad():\n",
    "                inputs = inputs.to(self.device, dtype=torch.long) \n",
    "                attention_masks = attention_masks.to(self.device, dtype=torch.long)\n",
    "                outputs = self.model(inputs, attention_masks)\n",
    "                toxics = nn.functional.softmax(outputs, dim=1).data.cpu().numpy()[:,1]\n",
    "\n",
    "            result['id'].extend(ids.cpu().numpy())\n",
    "            result['toxic'].extend(toxics)\n",
    "\n",
    "        result = pd.DataFrame(result)\n",
    "        node_count = len(glob('node_submissions/*.csv'))\n",
    "        result.to_csv(f'node_submissions/submission_{node_count}_{datetime.utcnow().microsecond}_{random.random()}.csv', index=False)\n",
    "\n",
    "    def save(self, path):        \n",
    "        xm.save(self.model.state_dict(), path)\n",
    "\n",
    "    def log(self, message):\n",
    "        if self.config.verbose:\n",
    "            xm.master_print(message)\n",
    "        with open(self.log_path, 'a+') as logger:\n",
    "            xm.master_print(f'{message}', logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaModel\n",
    "\n",
    "class ToxicSimpleNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ToxicSimpleNNModel, self).__init__()\n",
    "        self.backbone = XLMRobertaModel.from_pretrained(BACKBONE_PATH)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.linear = nn.Linear(\n",
    "            in_features=self.backbone.pooler.dense.out_features*2,\n",
    "            out_features=2,\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_masks):\n",
    "        bs, seq_length = input_ids.shape\n",
    "        seq_x, _ = self.backbone(input_ids=input_ids, attention_mask=attention_masks)\n",
    "        apool = torch.mean(seq_x, 1)\n",
    "        mpool, _ = torch.max(seq_x, 1)\n",
    "        x = torch.cat((apool, mpool), 1)\n",
    "        x = self.dropout(x)\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b761a00d8646859ae054794570ff5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=513.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ab26433e72492eae7492d41a4c117d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2244861551.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net = ToxicSimpleNNModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainGlobalConfig:\n",
    "    num_workers = 0 \n",
    "    batch_size = 16 \n",
    "    n_epochs = 3\n",
    "    lr = 0.5 * 1e-5\n",
    "\n",
    "    # -------------------\n",
    "    verbose = True\n",
    "    verbose_step = 50\n",
    "    # -------------------\n",
    "\n",
    "    # --------------------\n",
    "    step_scheduler = False  # do scheduler.step after optimizer.step\n",
    "    validation_scheduler = True  # do scheduler.step after validation stage loss\n",
    "    SchedulerClass = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "    scheduler_params = dict(\n",
    "        mode='max',\n",
    "        factor=0.7,\n",
    "        patience=0,\n",
    "        verbose=False, \n",
    "        threshold=0.0001,\n",
    "        threshold_mode='abs',\n",
    "        cooldown=0, \n",
    "        min_lr=1e-8,\n",
    "        eps=1e-08\n",
    "    )\n",
    "    # --------------------\n",
    "\n",
    "    # -------------------\n",
    "    criterion = LabelSmoothing()\n",
    "    # -------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mp_fn(rank, flags):\n",
    "    device = xm.xla_device()\n",
    "    net.to(device)\n",
    "\n",
    "    train_sampler = DistributedSamplerWrapper(\n",
    "        sampler=BalanceClassSampler(labels=train_dataset.get_labels(), mode=\"downsampling\"),\n",
    "        num_replicas=xm.xrt_world_size(),\n",
    "        rank=xm.get_ordinal(),\n",
    "        shuffle=True\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        sampler=train_sampler,\n",
    "        pin_memory=False,\n",
    "        drop_last=True,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "    )\n",
    "    validation_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        validation_dataset,\n",
    "        num_replicas=xm.xrt_world_size(),\n",
    "        rank=xm.get_ordinal(),\n",
    "        shuffle=False\n",
    "    )\n",
    "    validation_loader = torch.utils.data.DataLoader(\n",
    "        validation_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        sampler=validation_sampler,\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        num_workers=TrainGlobalConfig.num_workers\n",
    "    )\n",
    "    validation_tune_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        validation_tune_dataset,\n",
    "        num_replicas=xm.xrt_world_size(),\n",
    "        rank=xm.get_ordinal(),\n",
    "        shuffle=True\n",
    "    )\n",
    "    validation_tune_loader = torch.utils.data.DataLoader(\n",
    "        validation_tune_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        sampler=validation_tune_sampler,\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        num_workers=TrainGlobalConfig.num_workers\n",
    "    )\n",
    "    test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        test_dataset,\n",
    "        num_replicas=xm.xrt_world_size(),\n",
    "        rank=xm.get_ordinal(),\n",
    "        shuffle=False\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        sampler=test_sampler,\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        num_workers=TrainGlobalConfig.num_workers\n",
    "    )\n",
    "\n",
    "    if rank == 0:\n",
    "        time.sleep(1)\n",
    "    \n",
    "    fitter = TPUFitter(model=net, device=device, config=TrainGlobalConfig)\n",
    "    fitter.fit(train_loader, validation_loader)\n",
    "    fitter.run_tuning_and_inference(test_loader, validation_tune_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colab Notebook\n",
    "\n",
    "I hope Kaggle Team will increase RAM memory for tpu notebook as soon as possible. But now I recommend you use colab pro with HIGH RAM mode :)\n",
    "\n",
    "[Here](https://drive.google.com/drive/folders/1hbcSRfvtTTlERs7remsRST2amIWAFVry?usp=sharing) I have created public read-only google drive with colab notebook! You can save copy and start training right now!\n",
    "\n",
    "Also you can run this code here with nprocs=1, if you need. It works! But it is very slow (~1.5 P100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLAGS={}\n",
    "# xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.concat([pd.read_csv(path) for path in glob('node_submissions/*.csv')]).groupby('id').mean()\n",
    "# submission['toxic'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's imagine that this logs have got using Kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-04T16:52:20.438990\n",
      "LR: 4e-05\n",
      "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.82617\n",
      "Train Step 50, loss: 0.51566, final_score: 0.85479, time: 200.35051\n",
      "Train Step 100, loss: 0.43166, final_score: 0.92426, time: 251.99104\n",
      "Train Step 150, loss: 0.39472, final_score: 0.94679, time: 303.32809\n",
      "Train Step 200, loss: 0.38015, final_score: 0.95423, time: 354.55723\n",
      "Train Step 250, loss: 0.36591, final_score: 0.96103, time: 405.76366\n",
      "Train Step 300, loss: 0.36124, final_score: 0.96301, time: 457.29157\n",
      "Train Step 350, loss: 0.35468, final_score: 0.96579, time: 508.98310\n",
      "Train Step 400, loss: 0.34817, final_score: 0.96824, time: 560.27298\n",
      "Train Step 450, loss: 0.34598, final_score: 0.96890, time: 611.92743\n",
      "Train Step 500, loss: 0.34399, final_score: 0.96969, time: 663.06764\n",
      "Train Step 550, loss: 0.34247, final_score: 0.97014, time: 714.46248\n",
      "Train Step 600, loss: 0.34056, final_score: 0.97068, time: 766.03350\n",
      "Train Step 650, loss: 0.33792, final_score: 0.97173, time: 817.71023\n",
      "Train Step 700, loss: 0.33521, final_score: 0.97269, time: 869.37578\n",
      "Train Step 750, loss: 0.33432, final_score: 0.97289, time: 920.80785\n",
      "Train Step 800, loss: 0.33203, final_score: 0.97366, time: 972.32708\n",
      "Train Step 850, loss: 0.33050, final_score: 0.97417, time: 1023.88730\n",
      "Train Step 900, loss: 0.33040, final_score: 0.97421, time: 1075.52495\n",
      "Train Step 950, loss: 0.33002, final_score: 0.97440, time: 1127.22216\n",
      "Train Step 1000, loss: 0.32942, final_score: 0.97460, time: 1178.87880\n",
      "Train Step 1050, loss: 0.32741, final_score: 0.97527, time: 1230.41131\n",
      "Train Step 1100, loss: 0.32675, final_score: 0.97548, time: 1281.96718\n",
      "Train Step 1150, loss: 0.32512, final_score: 0.97610, time: 1333.36557\n",
      "Train Step 1200, loss: 0.32437, final_score: 0.97633, time: 1384.80062\n",
      "Train Step 1250, loss: 0.32281, final_score: 0.97682, time: 1436.54636\n",
      "Train Step 1300, loss: 0.32122, final_score: 0.97737, time: 1488.07252\n",
      "Train Step 1350, loss: 0.32010, final_score: 0.97779, time: 1539.98610\n",
      "Train Step 1400, loss: 0.31966, final_score: 0.97790, time: 1591.74166\n",
      "Train Step 1450, loss: 0.31926, final_score: 0.97807, time: 1643.68167\n",
      "Train Step 1500, loss: 0.31856, final_score: 0.97826, time: 1695.54179\n",
      "Train Step 1550, loss: 0.31708, final_score: 0.97875, time: 1747.24074\n",
      "Train Step 1600, loss: 0.31631, final_score: 0.97901, time: 1798.85795\n",
      "Train Step 1650, loss: 0.31635, final_score: 0.97894, time: 1850.48001\n",
      "Train Step 1700, loss: 0.31544, final_score: 0.97920, time: 1902.43657\n",
      "Train Step 1750, loss: 0.31468, final_score: 0.97940, time: 1954.21068\n",
      "Train Step 1800, loss: 0.31439, final_score: 0.97950, time: 2006.29937\n",
      "Train Step 1850, loss: 0.31385, final_score: 0.97973, time: 2058.01552\n",
      "Train Step 1900, loss: 0.31338, final_score: 0.97993, time: 2109.84440\n",
      "Train Step 1950, loss: 0.31279, final_score: 0.98009, time: 2161.52416\n",
      "Train Step 2000, loss: 0.31245, final_score: 0.98022, time: 2213.10101\n",
      "Train Step 2050, loss: 0.31204, final_score: 0.98036, time: 2264.95371\n",
      "Train Step 2100, loss: 0.31163, final_score: 0.98049, time: 2316.80271\n",
      "Train Step 2150, loss: 0.31118, final_score: 0.98058, time: 2368.55198\n",
      "Train Step 2200, loss: 0.31089, final_score: 0.98068, time: 2420.48665\n",
      "Train Step 2250, loss: 0.30999, final_score: 0.98096, time: 2472.39876\n",
      "Train Step 2300, loss: 0.30974, final_score: 0.98102, time: 2524.05419\n",
      "[RESULT]: Train. Epoch: 0, loss: 0.30947, final_score: 0.98111, time: 2561.62316\n",
      "[RESULT]: Validation. Epoch: 0, loss: 0.45466, final_score: 0.95247, time: 99.24068\n",
      "\n",
      "2020-05-04T17:36:41.308890\n",
      "LR: 4e-05\n",
      "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.87386\n",
      "Train Step 50, loss: 0.31293, final_score: 0.98053, time: 52.19552\n",
      "Train Step 100, loss: 0.30277, final_score: 0.98346, time: 103.73965\n",
      "Train Step 150, loss: 0.29949, final_score: 0.98393, time: 155.16630\n",
      "Train Step 200, loss: 0.29830, final_score: 0.98442, time: 206.59688\n",
      "Train Step 250, loss: 0.29589, final_score: 0.98496, time: 258.08602\n",
      "Train Step 300, loss: 0.29044, final_score: 0.98656, time: 309.53231\n",
      "Train Step 350, loss: 0.29310, final_score: 0.98585, time: 361.21536\n",
      "Train Step 400, loss: 0.29141, final_score: 0.98633, time: 412.85508\n",
      "Train Step 450, loss: 0.28982, final_score: 0.98687, time: 464.57073\n",
      "Train Step 500, loss: 0.29105, final_score: 0.98650, time: 516.45296\n",
      "Train Step 550, loss: 0.28987, final_score: 0.98680, time: 568.33928\n",
      "Train Step 600, loss: 0.29074, final_score: 0.98634, time: 619.79560\n",
      "Train Step 650, loss: 0.29030, final_score: 0.98631, time: 671.42823\n",
      "Train Step 700, loss: 0.29158, final_score: 0.98606, time: 723.26909\n",
      "Train Step 750, loss: 0.29135, final_score: 0.98614, time: 774.75574\n",
      "Train Step 800, loss: 0.29070, final_score: 0.98641, time: 826.38022\n",
      "Train Step 850, loss: 0.29039, final_score: 0.98644, time: 878.02439\n",
      "Train Step 900, loss: 0.29034, final_score: 0.98650, time: 929.89079\n",
      "Train Step 950, loss: 0.29049, final_score: 0.98641, time: 981.82135\n",
      "Train Step 1000, loss: 0.29108, final_score: 0.98627, time: 1033.89977\n",
      "Train Step 1050, loss: 0.29176, final_score: 0.98614, time: 1085.75737\n",
      "Train Step 1100, loss: 0.29216, final_score: 0.98599, time: 1137.21495\n",
      "Train Step 1150, loss: 0.29243, final_score: 0.98594, time: 1188.77938\n",
      "Train Step 1200, loss: 0.29158, final_score: 0.98611, time: 1240.78199\n",
      "Train Step 1250, loss: 0.29183, final_score: 0.98596, time: 1292.75725\n",
      "Train Step 1300, loss: 0.29204, final_score: 0.98589, time: 1344.46774\n",
      "Train Step 1350, loss: 0.29193, final_score: 0.98592, time: 1396.31739\n",
      "Train Step 1400, loss: 0.29192, final_score: 0.98594, time: 1448.30803\n",
      "Train Step 1450, loss: 0.29222, final_score: 0.98591, time: 1500.12178\n",
      "Train Step 1500, loss: 0.29243, final_score: 0.98589, time: 1552.02075\n",
      "Train Step 1550, loss: 0.29220, final_score: 0.98594, time: 1604.06369\n",
      "Train Step 1600, loss: 0.29213, final_score: 0.98599, time: 1656.05157\n",
      "Train Step 1650, loss: 0.29231, final_score: 0.98597, time: 1708.04057\n",
      "Train Step 1700, loss: 0.29255, final_score: 0.98597, time: 1759.94502\n",
      "Train Step 1750, loss: 0.29195, final_score: 0.98613, time: 1811.86787\n",
      "Train Step 1800, loss: 0.29159, final_score: 0.98623, time: 1863.84753\n",
      "Train Step 1850, loss: 0.29166, final_score: 0.98617, time: 1915.93650\n",
      "Train Step 1900, loss: 0.29148, final_score: 0.98623, time: 1967.76293\n",
      "Train Step 1950, loss: 0.29090, final_score: 0.98637, time: 2019.82749\n",
      "Train Step 2000, loss: 0.29079, final_score: 0.98642, time: 2071.83670\n",
      "Train Step 2050, loss: 0.29082, final_score: 0.98639, time: 2123.64122\n",
      "Train Step 2100, loss: 0.29004, final_score: 0.98658, time: 2175.61234\n",
      "Train Step 2150, loss: 0.28984, final_score: 0.98665, time: 2227.58902\n",
      "Train Step 2200, loss: 0.28949, final_score: 0.98676, time: 2279.65391\n",
      "Train Step 2250, loss: 0.29013, final_score: 0.98659, time: 2331.64764\n",
      "Train Step 2300, loss: 0.29050, final_score: 0.98651, time: 2384.06174\n",
      "[RESULT]: Train. Epoch: 1, loss: 0.29058, final_score: 0.98648, time: 2427.53442\n",
      "[RESULT]: Validation. Epoch: 1, loss: 0.44523, final_score: 0.95650, time: 28.35599\n",
      "\n",
      "2020-05-04T18:17:37.224802\n",
      "LR: 4e-05\n",
      "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.75165\n",
      "Train Step 50, loss: 0.26416, final_score: 0.99262, time: 51.92467\n",
      "Train Step 100, loss: 0.27299, final_score: 0.99088, time: 103.50740\n",
      "Train Step 150, loss: 0.27628, final_score: 0.99030, time: 155.05243\n",
      "Train Step 200, loss: 0.27750, final_score: 0.98981, time: 206.70986\n",
      "Train Step 250, loss: 0.27816, final_score: 0.98983, time: 258.27796\n",
      "Train Step 300, loss: 0.27922, final_score: 0.98931, time: 309.76611\n",
      "Train Step 350, loss: 0.28097, final_score: 0.98895, time: 361.04921\n",
      "Train Step 400, loss: 0.28135, final_score: 0.98893, time: 412.44446\n",
      "Train Step 450, loss: 0.28222, final_score: 0.98882, time: 463.88209\n",
      "Train Step 500, loss: 0.28114, final_score: 0.98904, time: 515.40198\n",
      "Train Step 550, loss: 0.28224, final_score: 0.98850, time: 567.01739\n",
      "Train Step 600, loss: 0.28275, final_score: 0.98855, time: 618.87824\n",
      "Train Step 650, loss: 0.28227, final_score: 0.98871, time: 670.59830\n",
      "Train Step 700, loss: 0.28476, final_score: 0.98787, time: 722.28040\n",
      "Train Step 750, loss: 0.28578, final_score: 0.98768, time: 774.04823\n",
      "Train Step 800, loss: 0.28646, final_score: 0.98756, time: 826.13989\n",
      "Train Step 850, loss: 0.28685, final_score: 0.98743, time: 877.75621\n",
      "Train Step 900, loss: 0.28638, final_score: 0.98751, time: 929.71196\n",
      "Train Step 950, loss: 0.28580, final_score: 0.98758, time: 981.66511\n",
      "Train Step 1000, loss: 0.28433, final_score: 0.98794, time: 1033.48173\n",
      "Train Step 1050, loss: 0.28406, final_score: 0.98799, time: 1085.34827\n",
      "Train Step 1100, loss: 0.28385, final_score: 0.98813, time: 1137.07452\n",
      "Train Step 1150, loss: 0.28439, final_score: 0.98806, time: 1189.04923\n",
      "Train Step 1200, loss: 0.28457, final_score: 0.98791, time: 1240.59837\n",
      "Train Step 1250, loss: 0.28488, final_score: 0.98782, time: 1292.51401\n",
      "Train Step 1300, loss: 0.28465, final_score: 0.98789, time: 1344.23372\n",
      "Train Step 1350, loss: 0.28490, final_score: 0.98785, time: 1396.03908\n",
      "Train Step 1400, loss: 0.28448, final_score: 0.98801, time: 1447.90557\n",
      "Train Step 1450, loss: 0.28451, final_score: 0.98805, time: 1500.18476\n",
      "Train Step 1500, loss: 0.28422, final_score: 0.98808, time: 1552.09611\n",
      "Train Step 1550, loss: 0.28446, final_score: 0.98801, time: 1603.79828\n",
      "Train Step 1600, loss: 0.28453, final_score: 0.98801, time: 1655.65210\n",
      "Train Step 1650, loss: 0.28415, final_score: 0.98807, time: 1707.60745\n",
      "Train Step 1700, loss: 0.28417, final_score: 0.98801, time: 1759.53869\n",
      "Train Step 1750, loss: 0.28454, final_score: 0.98791, time: 1811.40234\n",
      "Train Step 1800, loss: 0.28475, final_score: 0.98784, time: 1863.32700\n",
      "Train Step 1850, loss: 0.28507, final_score: 0.98773, time: 1914.97625\n",
      "Train Step 1900, loss: 0.28476, final_score: 0.98779, time: 1967.12709\n",
      "Train Step 1950, loss: 0.28457, final_score: 0.98786, time: 2019.14979\n",
      "Train Step 2000, loss: 0.28428, final_score: 0.98788, time: 2071.42615\n",
      "Train Step 2050, loss: 0.28385, final_score: 0.98798, time: 2123.31717\n",
      "Train Step 2100, loss: 0.28368, final_score: 0.98801, time: 2175.50050\n",
      "Train Step 2150, loss: 0.28369, final_score: 0.98800, time: 2227.68828\n",
      "Train Step 2200, loss: 0.28373, final_score: 0.98795, time: 2279.52692\n",
      "Train Step 2250, loss: 0.28406, final_score: 0.98785, time: 2331.70731\n",
      "Train Step 2300, loss: 0.28432, final_score: 0.98780, time: 2384.01696\n",
      "[RESULT]: Train. Epoch: 2, loss: 0.28421, final_score: 0.98786, time: 2426.40250\n",
      "[RESULT]: Validation. Epoch: 2, loss: 0.52592, final_score: 0.95075, time: 28.34848\n",
      "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.09278\n",
      "Train Step 50, loss: 0.33469, final_score: 0.93645, time: 115.72396\n",
      "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.08656\n",
      "Train Step 50, loss: 0.29525, final_score: 0.96969, time: 51.76507\n"
     ]
    }
   ],
   "source": [
    "file = open('../input/jigsaw-public-baseline-results/log.txt', 'r')\n",
    "for line in file.readlines():\n",
    "    print(line[:-1])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model should be trained ~10 epoch, I have run only 3 epoch for this kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "If you want to get high score ~0.945-0.946 such as [[TPU-Inference] Super Fast XLMRoberta](https://www.kaggle.com/shonenkov/tpu-inference-super-fast-xlmroberta) you should do blend such as [here](https://www.kaggle.com/hamditarek/ensemble), but I would like to make submission with only this kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f2c2c79bba8>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission = pd.read_csv('../input/jigsaw-public-baseline-results/submission.csv', index_col='id')\n",
    "submission.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you for reading my kernel!\n",
    "\n",
    "[Here](https://drive.google.com/drive/folders/1hbcSRfvtTTlERs7remsRST2amIWAFVry?usp=sharing) I have created public read-only google drive with colab notebook! You can save copy and start training right now!\n",
    "\n",
    "\n",
    "If you like this format of notebooks I would like continue to make kernels with realizations of my ideas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0aec35724c694aa19d7dedf08dc3518b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0d4fafb6e3f5475698221b95352ee1e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "12ab26433e72492eae7492d41a4c117d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_97a578d6e14446ebbb431100b24773d8",
        "IPY_MODEL_f338eff973044c3f84d54aac17c6949c"
       ],
       "layout": "IPY_MODEL_aaec77b2860444fe81f81c6c4c0f01c7"
      }
     },
     "144602548d3648a4a96a0b12ae9aa02b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "235d224d409d4d20bd3f4a952cf64048": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "3e67cdf9c4a74596acc9c0783e983b5a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b4ea26bbbbd4353a151fba58000e9df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "6cd1e14853c74fbbaf75f5ef4c7f7c99": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7c94b766945c4b1f97de7b7b3a8f94c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "81c3859faf4d461289547c5ef355de30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "93b06aa237a44cdda7b1c48d55601149": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0aec35724c694aa19d7dedf08dc3518b",
       "placeholder": "​",
       "style": "IPY_MODEL_9b2d8bb69f504d2d94e5172cc90471d8",
       "value": " 513/513 [00:00&lt;00:00, 1.50kB/s]"
      }
     },
     "979f66d10e304ecd9ac455d2f991c1cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6cd1e14853c74fbbaf75f5ef4c7f7c99",
       "placeholder": "​",
       "style": "IPY_MODEL_edca496d23754228bd88301a6ea1e6a6",
       "value": " 5.07M/5.07M [00:21&lt;00:00, 234kB/s]"
      }
     },
     "97a578d6e14446ebbb431100b24773d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fcbf3f8ff75a4444b5ffbeb7716b9828",
       "max": 2244861551.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_235d224d409d4d20bd3f4a952cf64048",
       "value": 2244861551.0
      }
     },
     "9b2d8bb69f504d2d94e5172cc90471d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "aaec77b2860444fe81f81c6c4c0f01c7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b33338a5706d431eaa512bd53900386b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7c94b766945c4b1f97de7b7b3a8f94c0",
       "max": 5069051.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5b4ea26bbbbd4353a151fba58000e9df",
       "value": 5069051.0
      }
     },
     "b9a7f0b8fa5f43508ed340bc0d57215a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0d4fafb6e3f5475698221b95352ee1e9",
       "max": 513.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_144602548d3648a4a96a0b12ae9aa02b",
       "value": 513.0
      }
     },
     "c7b761a00d8646859ae054794570ff5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b9a7f0b8fa5f43508ed340bc0d57215a",
        "IPY_MODEL_93b06aa237a44cdda7b1c48d55601149"
       ],
       "layout": "IPY_MODEL_3e67cdf9c4a74596acc9c0783e983b5a"
      }
     },
     "cad82bbeaf0a456f8f82e0581465906e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "edca496d23754228bd88301a6ea1e6a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f338eff973044c3f84d54aac17c6949c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cad82bbeaf0a456f8f82e0581465906e",
       "placeholder": "​",
       "style": "IPY_MODEL_81c3859faf4d461289547c5ef355de30",
       "value": " 2.24G/2.24G [01:06&lt;00:00, 33.9MB/s]"
      }
     },
     "fb8c1fce317c496f9091c45da6e8fcec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b33338a5706d431eaa512bd53900386b",
        "IPY_MODEL_979f66d10e304ecd9ac455d2f991c1cb"
       ],
       "layout": "IPY_MODEL_fd98240709a04ce1b05f37d594cac584"
      }
     },
     "fcbf3f8ff75a4444b5ffbeb7716b9828": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fd98240709a04ce1b05f37d594cac584": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
