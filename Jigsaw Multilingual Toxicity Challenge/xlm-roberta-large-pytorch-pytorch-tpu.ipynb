{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Stable Pytorch TPU training\n",
    "\n",
    "Thanks to all other public kernels in this competition for inspiration, such as:\n",
    "\n",
    "* https://www.kaggle.com/xhlulu/jigsaw-tpu-xlm-roberta\n",
    "* https://www.kaggle.com/shonenkov/tpu-training-super-fast-xlmroberta\n",
    "* https://www.kaggle.com/abhishek/bert-multi-lingual-tpu-training-8-cores-w-valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  ['10.0.0.2:8470']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "try:\n",
    "   tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  \n",
    "   print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "except ValueError:\n",
    "   tpu = None\n",
    "if tpu:\n",
    "   tf.config.experimental_connect_to_cluster(tpu)\n",
    "   tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "   strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "   strategy = tf.distribute.get_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100  4994  100  4994    0     0  68410      0 --:--:-- --:--:-- --:--:-- 68410\r\n",
      "Updating... This may take around 2 minutes.\r\n",
      "Updating TPU runtime to pytorch-nightly ...\r\n",
      "Found existing installation: torch 1.5.0\r\n",
      "Uninstalling torch-1.5.0:\r\n",
      "  Successfully uninstalled torch-1.5.0\r\n",
      "Found existing installation: torchvision 0.6.0a0+35d732a\r\n",
      "Uninstalling torchvision-0.6.0a0+35d732a:\r\n",
      "Done updating TPU runtime\r\n",
      "  Successfully uninstalled torchvision-0.6.0a0+35d732a\r\n",
      "Copying gs://tpu-pytorch/wheels/torch-nightly-cp37-cp37m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/107.6 MiB.                                    \r\n",
      "Copying gs://tpu-pytorch/wheels/torch_xla-nightly-cp37-cp37m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/123.9 MiB.                                    \r\n",
      "Copying gs://tpu-pytorch/wheels/torchvision-nightly-cp37-cp37m-linux_x86_64.whl...\r\n",
      "\r\n",
      "Operation completed over 1 objects/2.4 MiB.                                      \r\n",
      "Processing ./torch-nightly-cp37-cp37m-linux_x86_64.whl\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch==nightly) (0.18.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch==nightly) (1.18.5)\r\n",
      "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\r\n",
      "\u001b[31mERROR: kornia 0.3.1 has requirement torch==1.5.0, but you'll have torch 1.7.0a0+df252c0 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mERROR: allennlp 1.0.0 has requirement torch<1.6.0,>=1.5.0, but you'll have torch 1.7.0a0+df252c0 which is incompatible.\u001b[0m\r\n",
      "Installing collected packages: torch\r\n",
      "Successfully installed torch-1.7.0a0+df252c0\r\n",
      "Processing ./torch_xla-nightly-cp37-cp37m-linux_x86_64.whl\r\n",
      "Installing collected packages: torch-xla\r\n",
      "Successfully installed torch-xla-1.6+ba9876a\r\n",
      "Processing ./torchvision-nightly-cp37-cp37m-linux_x86_64.whl\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly) (7.2.0)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly) (1.7.0a0+df252c0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly) (1.18.5)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->torchvision==nightly) (0.18.2)\r\n",
      "Installing collected packages: torchvision\r\n",
      "Successfully installed torchvision-0.8.0a0+892d0ef\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "The following additional packages will be installed:\r\n",
      "  libgfortran4 libopenblas-base\r\n",
      "The following NEW packages will be installed:\r\n",
      "  libgfortran4 libomp5 libopenblas-base libopenblas-dev\r\n",
      "0 upgraded, 4 newly installed, 0 to remove and 52 not upgraded.\r\n",
      "Need to get 8550 kB of archives.\r\n",
      "After this operation, 97.6 MB of additional disk space will be used.\r\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgfortran4 amd64 7.5.0-3ubuntu1~18.04 [492 kB]\r\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenblas-base amd64 0.2.20+ds-4 [3964 kB]\r\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenblas-dev amd64 0.2.20+ds-4 [3860 kB]\r\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\r\n",
      "Fetched 8550 kB in 1s (6544 kB/s)\r\n",
      "debconf: delaying package configuration, since apt-utils is not installed\r\n",
      "Selecting previously unselected package libgfortran4:amd64.\r\n",
      "(Reading database ... 107461 files and directories currently installed.)\r\n",
      "Preparing to unpack .../libgfortran4_7.5.0-3ubuntu1~18.04_amd64.deb ...\r\n",
      "Unpacking libgfortran4:amd64 (7.5.0-3ubuntu1~18.04) ...\r\n",
      "Selecting previously unselected package libopenblas-base:amd64.\r\n",
      "Preparing to unpack .../libopenblas-base_0.2.20+ds-4_amd64.deb ...\r\n",
      "Unpacking libopenblas-base:amd64 (0.2.20+ds-4) ...\r\n",
      "Selecting previously unselected package libopenblas-dev:amd64.\r\n",
      "Preparing to unpack .../libopenblas-dev_0.2.20+ds-4_amd64.deb ...\r\n",
      "Unpacking libopenblas-dev:amd64 (0.2.20+ds-4) ...\r\n",
      "Selecting previously unselected package libomp5:amd64.\r\n",
      "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\r\n",
      "Unpacking libomp5:amd64 (5.0.1-1) ...\r\n",
      "Setting up libomp5:amd64 (5.0.1-1) ...\r\n",
      "Setting up libgfortran4:amd64 (7.5.0-3ubuntu1~18.04) ...\r\n",
      "Setting up libopenblas-base:amd64 (0.2.20+ds-4) ...\r\n",
      "update-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3 to provide /usr/lib/x86_64-linux-gnu/libblas.so.3 (libblas.so.3-x86_64-linux-gnu) in auto mode\r\n",
      "update-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/liblapack.so.3 to provide /usr/lib/x86_64-linux-gnu/liblapack.so.3 (liblapack.so.3-x86_64-linux-gnu) in auto mode\r\n",
      "Setting up libopenblas-dev:amd64 (0.2.20+ds-4) ...\r\n",
      "update-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/libblas.so to provide /usr/lib/x86_64-linux-gnu/libblas.so (libblas.so-x86_64-linux-gnu) in auto mode\r\n",
      "update-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/liblapack.so to provide /usr/lib/x86_64-linux-gnu/liblapack.so (liblapack.so-x86_64-linux-gnu) in auto mode\r\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\r\n"
     ]
    }
   ],
   "source": [
    "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "!python pytorch-xla-env-setup.py --version nightly  --apt-packages libomp5 libopenblas-dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "16a3df23-8416-46b5-8661-c52345005b6d",
    "_uuid": "993abe0b-2561-4abc-a6a2-b83d8dd4c846"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['XLA_USE_BF16'] = \"1\"\n",
    "os.environ['XLA_TENSOR_ALLOCATOR_MAXSIZE'] = '100000000'\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict, namedtuple\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import torch_xla.utils.serialization as xser\n",
    "\n",
    "import time\n",
    "\n",
    "import logging\n",
    "import transformers\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule, XLMRobertaTokenizer, XLMRobertaModel, XLMRobertaConfig, get_cosine_schedule_with_warmup\n",
    "import sys\n",
    "from sklearn import metrics, model_selection\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from random import shuffle\n",
    "import random\n",
    "\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "import torch_xla\n",
    "import torch_xla.debug.metrics as met\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.utils.utils as xu\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import torch_xla.test.test_utils as test_utils\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"\"\n",
    "\n",
    "MAX_LEN = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../input/jigsaw-public-baseline-train-data/train_data.csv\", usecols=[\"comment_text\", \"toxic\", \"lang\"])\n",
    "\n",
    "df_valid = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/validation.csv', usecols=[\"comment_text\", \"toxic\", \"lang\"])\n",
    "\n",
    "df_test = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test.csv').rename(columns={\"content\": \"comment_text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you!! This would make my life a lot less...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is such an urgent design problem; kudos t...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is this something I'll be able to install on m...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic lang\n",
       "0  This is so cool. It's like, 'would you want yo...      0   en\n",
       "1  Thank you!! This would make my life a lot less...      0   en\n",
       "2  This is such an urgent design problem; kudos t...      0   en\n",
       "3  Is this something I'll be able to install on m...      0   en\n",
       "4               haha you guys are a bunch of losers.      1   en"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21198\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# create (balanced) samples outside the training routine to save memory\n",
    "\n",
    "labels = np.char.add(df_train.toxic.values.astype(str), df_train.lang.values)\n",
    "df_train[\"label\"] = labels\n",
    "\n",
    "min_size = df_train.groupby(\"label\").size().min()\n",
    "\n",
    "print(min_size)\n",
    "\n",
    "upsample = 1\n",
    "samples = []\n",
    "for i in range(3):\n",
    "    print(i)\n",
    "    sample = []\n",
    "    for l in df_train.label.unique():\n",
    "        if l[0] == \"1\":\n",
    "            x = df_train[df_train[\"label\"]==l].sample(min_size, replace=False, random_state=i)\n",
    "            sample.append(x)\n",
    "            sample.append(df_train[df_train[\"label\"]==f\"0{l[1:]}\"].sample(min_size*upsample, replace=False, random_state=i))\n",
    "    sample = pd.concat(sample, axis=0).sample(frac=1)\n",
    "    del sample[\"label\"]\n",
    "    DATA_LENGTH = len(sample)\n",
    "    samples.append(sample)\n",
    "    del sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train\n",
    "df_train = samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            18G        3.3G        3.1G        984K         12G         15G\r\n",
      "Swap:            0B          0B          0B\r\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRoberta(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomRoberta, self).__init__()\n",
    "        self.num_labels = 2\n",
    "        self.roberta = transformers.XLMRobertaModel.from_pretrained(\"xlm-roberta-large\", output_hidden_states=False, num_labels=1)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.ln = nn.LayerNorm(1024)\n",
    "        self.classifier = nn.Linear(1024, self.num_labels)\n",
    "\n",
    "    def forward(self,\n",
    "                input_ids=None,\n",
    "                attention_mask=None,\n",
    "                position_ids=None,\n",
    "                head_mask=None,\n",
    "                inputs_embeds=None):\n",
    "\n",
    "        o1, o2 = self.roberta(input_ids,\n",
    "                               attention_mask=attention_mask,\n",
    "                               position_ids=position_ids,\n",
    "                               head_mask=head_mask,\n",
    "                               inputs_embeds=inputs_embeds)\n",
    "        \n",
    "        x1 = torch.mean(o1, 1)\n",
    "        \n",
    "        x = x1\n",
    "        \n",
    "        x = self.ln(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        logits = self.classifier(x)       \n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395736beae834a698cd83c14f29bbe93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739d29714ed341d6a6b167769fa6cd67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=513.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41d0f6d177948d38277e0c3048e5388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2244861551.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.XLMRobertaTokenizer.from_pretrained('xlm-roberta-large')\n",
    "\n",
    "# use model wrapper for reducing memory usage across TPU cores\n",
    "mx = xmp.MpModelWrapper(CustomRoberta())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset:\n",
    "    def __init__(self, df=None):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def get_tokens(self, text):\n",
    "        encoded = tokenizer.encode_plus(\n",
    "            text, \n",
    "            add_special_tokens=True, \n",
    "            max_length=MAX_LEN, \n",
    "            pad_to_max_length=True\n",
    "        )\n",
    "        return encoded['input_ids'], encoded['attention_mask']\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return LabelEncoder().fit_transform(np.char.add(self.df.toxic.values.astype(str), self.df.lang.values).reshape(-1,1)).astype(np.int16)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        \n",
    "        text = self.df.iloc[item][\"comment_text\"]\n",
    "        lang = self.df.iloc[item][\"lang\"]\n",
    "                \n",
    "        encoded = self.get_tokens(text)\n",
    "        \n",
    "        targets = np.zeros(2)\n",
    "        \n",
    "        if \"toxic\" in self.df.columns:\n",
    "            targets[self.df.iloc[item][\"toxic\"]] = 1\n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(encoded[0]),\n",
    "            'mask': torch.tensor(encoded[1]),\n",
    "            'targets': targets,\n",
    "            'index': item\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = BERTDataset(df_train)\n",
    "valid_dataset = BERTDataset(df_valid)\n",
    "test_dataset = BERTDataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            18G        5.3G        2.3G        992K         11G         13G\r\n",
      "Swap:            0B          0B          0B\r\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocAucMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.y_true = np.array([0,1])\n",
    "        self.y_pred = np.array([0.5,0.5])\n",
    "        self.score = 0\n",
    "\n",
    "    def update(self, y_true, y_pred):\n",
    "        y_true = y_true.cpu().numpy().argmax(axis=1)\n",
    "        y_pred = nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,1]\n",
    "        self.y_true = np.hstack((self.y_true, y_true))\n",
    "        self.y_pred = np.hstack((self.y_pred, y_pred))\n",
    "        self.score = metrics.roc_auc_score(self.y_true, self.y_pred, labels=np.array([0, 1]))\n",
    "    \n",
    "    @property\n",
    "    def avg(self):\n",
    "        return self.score\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def train_loop_fn(data_loader, model, optimizer, device, scheduler=None, epoch=None):\n",
    "        \n",
    "    model.train()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    auc = RocAucMeter()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for bi, d in enumerate(data_loader):\n",
    "\n",
    "        ids = d[\"ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        targets = d[\"targets\"]\n",
    "\n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "        targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=ids,\n",
    "            attention_mask = mask,\n",
    "        )\n",
    "\n",
    "        \n",
    "        #xm.master_print(f'{outputs.shape}')\n",
    "        #xm.master_print(f'{targets.shape}')\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        xm.optimizer_step(optimizer)\n",
    "        \n",
    "        loss = loss.detach().item()\n",
    "        \n",
    "        auc.update(targets, outputs)\n",
    "        losses.update(loss, ids.size(0))\n",
    "        \n",
    "        if bi % 10 == 0:\n",
    "            xm.master_print(f'bi={bi}, loss={losses.avg:<8.4f}, auc={auc.avg:<8.4f} {time.time()-start_time:<2.2f}')\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        #break\n",
    "        #break\n",
    "#         if bi == 2:\n",
    "#             break\n",
    "        \n",
    "    del loss\n",
    "    del losses\n",
    "    del outputs\n",
    "    del ids\n",
    "    del targets\n",
    "    \n",
    "    gc.collect()\n",
    "        \n",
    "    model.eval()\n",
    "\n",
    "def eval_loop_fn(data_loader, model, device):\n",
    "        \n",
    "    #model.eval()\n",
    "    fin_targets = []\n",
    "    fin_outputs = []\n",
    "    fin_index = []\n",
    "    with torch.no_grad():\n",
    "        for bi, d in enumerate(data_loader):\n",
    "\n",
    "            if bi % 10 == 0:\n",
    "                xm.master_print(f'EVAL bi={bi}')\n",
    "\n",
    "            ids = d[\"ids\"]\n",
    "            mask = d[\"mask\"]\n",
    "            targets = d[\"targets\"]\n",
    "            index = d[\"index\"]\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids = ids,\n",
    "                attention_mask = mask,\n",
    "            )\n",
    "\n",
    "            targets_np = targets.cpu().detach().numpy().argmax(axis=1).tolist()\n",
    "            outputs_np = outputs.cpu().detach().numpy()[:,1].tolist()\n",
    "            fin_targets.extend(targets_np)\n",
    "            fin_outputs.extend(outputs_np)    \n",
    "            fin_index.extend(index.tolist()) \n",
    "\n",
    "    return fin_outputs, fin_targets, fin_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "       super(SmoothLoss, self).__init__()\n",
    "    def forward(self, pred, target):\n",
    "       pred = pred.log_softmax(dim=1)\n",
    "       return torch.mean(torch.sum(-target * pred, dim=1))\n",
    "        \n",
    "def loss_fn(outputs, targets):\n",
    "    return SmoothLoss()(outputs, targets)\n",
    "\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "\n",
    "EPOCHS = 1\n",
    "\n",
    "LR = 2e-5\n",
    "\n",
    "def _run():\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    xm.master_print('starting run')\n",
    "    \n",
    "    valid_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "              valid_dataset,\n",
    "              num_replicas=xm.xrt_world_size(),\n",
    "              rank=xm.get_ordinal(),\n",
    "              shuffle=False)\n",
    "\n",
    "    valid_data_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=VALID_BATCH_SIZE,\n",
    "        sampler=valid_sampler,\n",
    "        drop_last=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "              test_dataset,\n",
    "              num_replicas=xm.xrt_world_size(),\n",
    "              rank=xm.get_ordinal(),\n",
    "              shuffle=False)\n",
    "\n",
    "    test_data_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=VALID_BATCH_SIZE,\n",
    "        sampler=test_sampler,\n",
    "        drop_last=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    device = xm.xla_device()\n",
    "    model = mx.to(device)\n",
    "    xm.master_print('done loading model')\n",
    "\n",
    "\n",
    "    num_train_steps = int(len(df_train[0]) / TRAIN_BATCH_SIZE / xm.xrt_world_size())\n",
    "\n",
    "    optimizer = AdamW([{'params': model.roberta.parameters(), 'lr': LR},\n",
    "                    {'params': [param for name, param in model.named_parameters() if 'roberta' not in name], 'lr': 1e-3} ], lr=LR, weight_decay=0)\n",
    "\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps = 0,\n",
    "        num_training_steps = num_train_steps * EPOCHS\n",
    "    )\n",
    "\n",
    "    xm.master_print(f'num_train_steps = {num_train_steps}, world_size={xm.xrt_world_size()}')\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        # loading dataset for epoch\n",
    "        train_dataset = BERTDataset(df_train[epoch])\n",
    "    \n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "              train_dataset,\n",
    "              num_replicas=xm.xrt_world_size(),\n",
    "              rank=xm.get_ordinal(),\n",
    "              shuffle=True)\n",
    "\n",
    "        train_data_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=TRAIN_BATCH_SIZE,\n",
    "            sampler=train_sampler,\n",
    "            drop_last=True,\n",
    "            num_workers=0,\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        train_sampler.set_epoch(epoch)\n",
    "        \n",
    "        para_loader = pl.ParallelLoader(train_data_loader, [device])\n",
    "        xm.master_print('parallel loader created... training now')\n",
    "        train_loop_fn(para_loader.per_device_loader(device), model, optimizer, device, scheduler=scheduler, epoch=epoch)\n",
    "        \n",
    "        #del train_dataset\n",
    "        #del train_sampler\n",
    "        #del train_data_loader\n",
    "        del para_loader\n",
    "        gc.collect()\n",
    "        \n",
    "        # using xm functionality for memory-reduced model saving\n",
    "        if epoch == EPOCHS-1:\n",
    "            xm.master_print('saving model')\n",
    "            xser.save(model.state_dict(), f\"{PATH}model.bin\", master_only=True)\n",
    "            xm.master_print('model saved')\n",
    "        \n",
    "        para_loader = pl.ParallelLoader(valid_data_loader, [device])\n",
    "        o, t, i = eval_loop_fn(para_loader.per_device_loader(device), model, device)\n",
    "        auc = metrics.roc_auc_score(np.array(t), o)\n",
    "        #del o,t,i\n",
    "        gc.collect()\n",
    "        \n",
    "        del para_loader\n",
    "\n",
    "        print(f'[xla:{xm.get_ordinal()}] AUC = {auc}')\n",
    "        \n",
    "        \n",
    "        def reduce_fn(vals):\n",
    "            return sum(vals) / len(vals)\n",
    "\n",
    "        auc = xm.mesh_reduce('auc_reduce', auc, reduce_fn)\n",
    "        xm.master_print(f'AUC AVG = {auc}')\n",
    "        \n",
    "        para_loader = pl.ParallelLoader(test_data_loader, [device])\n",
    "        o, t, i = eval_loop_fn(para_loader.per_device_loader(device), model, device)\n",
    "        \n",
    "        del t\n",
    "        gc.collect()\n",
    "        \n",
    "    return o, i\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting run\n",
      "done loading model\n",
      "num_train_steps = 1159, world_size=8\n",
      "parallel loader created... training now\n",
      "bi=0, loss=0.7305  , auc=0.6042   47.40\n",
      "bi=10, loss=0.6818  , auc=0.5874   222.36\n",
      "bi=20, loss=0.6462  , auc=0.6731   238.10\n",
      "bi=30, loss=0.5826  , auc=0.7567   253.78\n",
      "bi=40, loss=0.5315  , auc=0.8084   269.58\n",
      "bi=50, loss=0.4919  , auc=0.8420   285.28\n",
      "bi=60, loss=0.4575  , auc=0.8660   300.88\n",
      "bi=70, loss=0.4303  , auc=0.8821   316.74\n",
      "bi=80, loss=0.4080  , auc=0.8948   332.62\n",
      "bi=90, loss=0.3978  , auc=0.8999   348.50\n",
      "bi=100, loss=0.3870  , auc=0.9061   364.22\n",
      "bi=110, loss=0.3741  , auc=0.9128   380.05\n",
      "bi=120, loss=0.3670  , auc=0.9160   395.77\n",
      "bi=130, loss=0.3563  , auc=0.9213   411.39\n",
      "bi=140, loss=0.3483  , auc=0.9249   427.27\n",
      "bi=150, loss=0.3429  , auc=0.9274   442.96\n",
      "bi=160, loss=0.3381  , auc=0.9296   458.75\n",
      "bi=170, loss=0.3325  , auc=0.9319   474.28\n",
      "bi=180, loss=0.3272  , auc=0.9342   490.45\n",
      "bi=190, loss=0.3223  , auc=0.9362   506.15\n",
      "bi=200, loss=0.3185  , auc=0.9377   521.81\n",
      "bi=210, loss=0.3141  , auc=0.9394   537.44\n",
      "bi=220, loss=0.3102  , auc=0.9410   553.63\n",
      "bi=230, loss=0.3076  , auc=0.9420   569.31\n",
      "bi=240, loss=0.3035  , auc=0.9437   585.02\n",
      "bi=250, loss=0.2992  , auc=0.9453   600.56\n",
      "bi=260, loss=0.2991  , auc=0.9452   616.76\n",
      "bi=270, loss=0.2967  , auc=0.9460   632.55\n",
      "bi=280, loss=0.2955  , auc=0.9465   648.24\n",
      "bi=290, loss=0.2919  , auc=0.9478   663.93\n",
      "bi=300, loss=0.2913  , auc=0.9480   679.98\n",
      "bi=310, loss=0.2891  , auc=0.9487   695.84\n",
      "bi=320, loss=0.2878  , auc=0.9491   711.72\n",
      "bi=330, loss=0.2869  , auc=0.9494   727.55\n",
      "bi=340, loss=0.2844  , auc=0.9503   743.31\n",
      "bi=350, loss=0.2837  , auc=0.9505   759.01\n",
      "bi=360, loss=0.2821  , auc=0.9511   774.86\n",
      "bi=370, loss=0.2814  , auc=0.9513   790.69\n",
      "bi=380, loss=0.2818  , auc=0.9511   806.50\n",
      "bi=390, loss=0.2801  , auc=0.9517   822.33\n",
      "bi=400, loss=0.2792  , auc=0.9520   838.24\n",
      "bi=410, loss=0.2774  , auc=0.9526   854.08\n",
      "bi=420, loss=0.2768  , auc=0.9527   869.99\n",
      "bi=430, loss=0.2770  , auc=0.9526   885.87\n",
      "bi=440, loss=0.2767  , auc=0.9527   901.87\n",
      "bi=450, loss=0.2752  , auc=0.9533   918.18\n",
      "bi=460, loss=0.2749  , auc=0.9534   934.18\n",
      "bi=470, loss=0.2748  , auc=0.9534   950.03\n",
      "bi=480, loss=0.2742  , auc=0.9536   966.37\n",
      "bi=490, loss=0.2731  , auc=0.9539   982.53\n",
      "bi=500, loss=0.2727  , auc=0.9541   998.70\n",
      "bi=510, loss=0.2713  , auc=0.9545   1014.49\n",
      "bi=520, loss=0.2713  , auc=0.9546   1030.37\n",
      "bi=530, loss=0.2708  , auc=0.9547   1046.13\n",
      "bi=540, loss=0.2695  , auc=0.9551   1061.99\n",
      "bi=550, loss=0.2683  , auc=0.9555   1077.99\n",
      "bi=560, loss=0.2680  , auc=0.9556   1094.03\n",
      "bi=570, loss=0.2662  , auc=0.9562   1109.78\n",
      "bi=580, loss=0.2650  , auc=0.9566   1125.67\n",
      "bi=590, loss=0.2640  , auc=0.9569   1141.46\n",
      "bi=600, loss=0.2627  , auc=0.9573   1157.73\n",
      "bi=610, loss=0.2624  , auc=0.9574   1173.52\n",
      "bi=620, loss=0.2620  , auc=0.9575   1189.41\n",
      "bi=630, loss=0.2615  , auc=0.9576   1205.34\n",
      "bi=640, loss=0.2612  , auc=0.9577   1221.51\n",
      "bi=650, loss=0.2604  , auc=0.9579   1237.38\n",
      "bi=660, loss=0.2605  , auc=0.9579   1253.43\n",
      "bi=670, loss=0.2591  , auc=0.9584   1269.33\n",
      "bi=680, loss=0.2585  , auc=0.9585   1285.16\n",
      "bi=690, loss=0.2576  , auc=0.9588   1300.94\n",
      "bi=700, loss=0.2575  , auc=0.9589   1316.82\n",
      "bi=710, loss=0.2560  , auc=0.9594   1332.74\n",
      "bi=720, loss=0.2551  , auc=0.9596   1348.59\n",
      "bi=730, loss=0.2541  , auc=0.9599   1364.42\n",
      "bi=740, loss=0.2531  , auc=0.9602   1380.34\n",
      "bi=750, loss=0.2533  , auc=0.9602   1396.55\n",
      "bi=760, loss=0.2522  , auc=0.9605   1412.67\n",
      "bi=770, loss=0.2517  , auc=0.9607   1428.39\n",
      "bi=780, loss=0.2518  , auc=0.9606   1444.37\n",
      "bi=790, loss=0.2515  , auc=0.9607   1460.24\n",
      "bi=800, loss=0.2507  , auc=0.9609   1476.24\n",
      "bi=810, loss=0.2503  , auc=0.9611   1492.21\n",
      "bi=820, loss=0.2495  , auc=0.9613   1508.47\n",
      "bi=830, loss=0.2494  , auc=0.9613   1524.22\n",
      "bi=840, loss=0.2484  , auc=0.9616   1540.02\n",
      "bi=850, loss=0.2486  , auc=0.9615   1555.84\n",
      "bi=860, loss=0.2481  , auc=0.9617   1571.98\n",
      "bi=870, loss=0.2479  , auc=0.9617   1587.74\n",
      "bi=880, loss=0.2476  , auc=0.9618   1603.67\n",
      "bi=890, loss=0.2475  , auc=0.9619   1619.41\n",
      "bi=900, loss=0.2472  , auc=0.9620   1635.41\n",
      "bi=910, loss=0.2469  , auc=0.9621   1651.21\n",
      "bi=920, loss=0.2464  , auc=0.9622   1667.02\n",
      "bi=930, loss=0.2462  , auc=0.9623   1682.89\n",
      "bi=940, loss=0.2461  , auc=0.9623   1699.20\n",
      "bi=950, loss=0.2465  , auc=0.9622   1715.03\n",
      "bi=960, loss=0.2464  , auc=0.9622   1730.85\n",
      "bi=970, loss=0.2464  , auc=0.9622   1746.94\n",
      "bi=980, loss=0.2458  , auc=0.9623   1762.90\n",
      "bi=990, loss=0.2453  , auc=0.9625   1778.69\n",
      "bi=1000, loss=0.2451  , auc=0.9625   1794.68\n",
      "bi=1010, loss=0.2445  , auc=0.9627   1810.60\n",
      "bi=1020, loss=0.2437  , auc=0.9629   1826.54\n",
      "bi=1030, loss=0.2435  , auc=0.9630   1842.66\n",
      "bi=1040, loss=0.2434  , auc=0.9630   1858.63\n",
      "bi=1050, loss=0.2428  , auc=0.9632   1874.88\n",
      "bi=1060, loss=0.2425  , auc=0.9633   1890.82\n",
      "bi=1070, loss=0.2428  , auc=0.9632   1906.58\n",
      "bi=1080, loss=0.2424  , auc=0.9633   1922.51\n",
      "bi=1090, loss=0.2419  , auc=0.9635   1938.76\n",
      "bi=1100, loss=0.2419  , auc=0.9635   1954.45\n",
      "bi=1110, loss=0.2420  , auc=0.9634   1970.47\n",
      "bi=1120, loss=0.2416  , auc=0.9636   1986.42\n",
      "bi=1130, loss=0.2419  , auc=0.9635   2002.78\n",
      "bi=1140, loss=0.2416  , auc=0.9636   2018.69\n",
      "bi=1150, loss=0.2415  , auc=0.9636   2034.66\n",
      "saving model\n",
      "model saved\n",
      "EVAL bi=0\n",
      "EVAL bi=10\n",
      "EVAL bi=20\n",
      "EVAL bi=30\n",
      "[xla:6] AUC = 0.9473965002134016\n",
      "[xla:0] AUC = 0.9562443211318796\n",
      "[xla:4] AUC = 0.9368581920531257\n",
      "[xla:3] AUC = 0.9389319470056274\n",
      "[xla:5] AUC = 0.9434747492876854\n",
      "[xla:7] AUC = 0.9431982254486792\n",
      "[xla:1] AUC = 0.9429435686120178\n",
      "[xla:2] AUC = 0.9562855414398065\n",
      "AUC AVG = 0.9456666306490279\n",
      "EVAL bi=0\n",
      "EVAL bi=10\n",
      "EVAL bi=20\n",
      "EVAL bi=30\n",
      "EVAL bi=40\n",
      "EVAL bi=50\n",
      "EVAL bi=60\n",
      "EVAL bi=70\n",
      "EVAL bi=80\n",
      "EVAL bi=90\n",
      "EVAL bi=100\n",
      "EVAL bi=110\n",
      "EVAL bi=120\n",
      "EVAL bi=130\n",
      "EVAL bi=140\n",
      "EVAL bi=150\n",
      "EVAL bi=160\n",
      "EVAL bi=170\n",
      "EVAL bi=180\n",
      "EVAL bi=190\n",
      "EVAL bi=200\n",
      "EVAL bi=210\n",
      "EVAL bi=220\n",
      "EVAL bi=230\n",
      "EVAL bi=240\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "# Start training processes\n",
    "def _mp_fn(rank, flags):\n",
    "    \n",
    "    # not the cleanest way, but works\n",
    "    # collect individual core outputs and save\n",
    "    # can also do test inference outside training routine loading saved model\n",
    "    test_preds, test_index = _run()\n",
    "    np.save(f\"test_preds_{rank}\", test_preds)\n",
    "    np.save(f\"test_index_{rank}\", test_index)\n",
    "    return test_preds\n",
    "\n",
    "FLAGS={}\n",
    "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL bi=0\n",
      "EVAL bi=50\n",
      "EVAL bi=100\n",
      "0.9455145849095122\n",
      "es\n",
      "0.9292075865875409\n",
      "it\n",
      "0.9152701618159894\n",
      "tr\n",
      "0.9849393656716418\n"
     ]
    }
   ],
   "source": [
    "# showcase for loading data and inference\n",
    "\n",
    "TRAIN_BATCH_SIZE = 64\n",
    "\n",
    "valid_data_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    drop_last=False,\n",
    "    num_workers=0,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "device = xm.xla_device()\n",
    "model = mx.to(device).eval()\n",
    "model.load_state_dict(xser.load(f\"{PATH}model.bin\"))\n",
    "\n",
    "fin_targets = []\n",
    "test_preds = []\n",
    "for bi, d in enumerate(valid_data_loader):\n",
    "\n",
    "    if bi % 50 == 0:\n",
    "        xm.master_print(f'EVAL bi={bi}')\n",
    "\n",
    "    ids = d[\"ids\"]\n",
    "    mask = d[\"mask\"]\n",
    "    targets = d[\"targets\"]\n",
    "    index = d[\"index\"]\n",
    "\n",
    "    ids = ids.to(device, dtype=torch.long)\n",
    "    mask = mask.to(device, dtype=torch.long)\n",
    "    targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "    outputs = model(\n",
    "        input_ids = ids,\n",
    "        attention_mask = mask,\n",
    "    )  \n",
    "\n",
    "    targets_np = targets.cpu().detach().numpy().tolist()\n",
    "    outputs_np = outputs.cpu().detach().numpy().tolist()\n",
    "    fin_targets.extend(targets_np)\n",
    "    test_preds.extend(outputs_np)   \n",
    "\n",
    "test_preds = np.array(test_preds)\n",
    "auc = metrics.roc_auc_score(df_valid.toxic.values, test_preds[:,1])\n",
    "print(auc)\n",
    "np.save(\"oof\", test_preds)\n",
    "\n",
    "for lang in df_valid.lang.unique():\n",
    "    print(lang)\n",
    "    print(metrics.roc_auc_score(df_valid[df_valid.lang==lang].toxic.values, test_preds[:,1][df_valid.lang==lang]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load individual outputs\n",
    "test_preds = np.zeros(len(df_test))\n",
    "for i in range(8):\n",
    "    test_preds[np.load(f\"test_index_{i}.npy\", allow_pickle=True).reshape(-1)] = np.load(f\"test_preds_{i}.npy\", allow_pickle=True).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/sample_submission.csv')\n",
    "sub['toxic'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.617188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.149414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-2.171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-2.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.417969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>-2.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.839844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.291016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.468750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     toxic\n",
       "0   0 -2.078125\n",
       "1   1 -1.617188\n",
       "2   2  0.149414\n",
       "3   3 -2.171875\n",
       "4   4 -2.640625\n",
       "5   5 -0.417969\n",
       "6   6 -2.593750\n",
       "7   7 -0.839844\n",
       "8   8  0.291016\n",
       "9   9  0.468750"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "09d589fb408642b9be637b0ebf48891d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "108388ef28a84ebd868055fdc4c489a9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_09d589fb408642b9be637b0ebf48891d",
       "max": 5069051.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c29a82ad77cd4c319d4cbc323df8ed7f",
       "value": 5069051.0
      }
     },
     "17c830efa4e94d17a98b9ac7af8f8fe4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "227e512f3ebc4fbeb7fac53bfac41510": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2792373d1d124f8294b1b42d04a8c998": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3652dac23e7047cea6a9ce401b3cf57e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "395736beae834a698cd83c14f29bbe93": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_108388ef28a84ebd868055fdc4c489a9",
        "IPY_MODEL_d68490bc2757445a8113531b802a901c"
       ],
       "layout": "IPY_MODEL_e2eb52e7373b4eccbd2f86e72a8f23e1"
      }
     },
     "72850aa9ff0c448dbbf880af1136b901": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f2411975460e4c6b8794686b673e7c97",
       "placeholder": "​",
       "style": "IPY_MODEL_755e49e48f074fe5a71b927c69fe7808",
       "value": " 513/513 [01:14&lt;00:00, 6.87B/s]"
      }
     },
     "739d29714ed341d6a6b167769fa6cd67": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b8d2d27c921445b9b4394763bb625c6b",
        "IPY_MODEL_72850aa9ff0c448dbbf880af1136b901"
       ],
       "layout": "IPY_MODEL_a689cd29b45a4556a19eabf1556d37a1"
      }
     },
     "755e49e48f074fe5a71b927c69fe7808": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a3191081b3b64e6ba9e938d1af28f216": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "a689cd29b45a4556a19eabf1556d37a1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b41d0f6d177948d38277e0c3048e5388": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bf09111f744f42589cfe3cbda3cebc38",
        "IPY_MODEL_d0ae8db4d86646bdba94e4c9e68ab742"
       ],
       "layout": "IPY_MODEL_2792373d1d124f8294b1b42d04a8c998"
      }
     },
     "b8d2d27c921445b9b4394763bb625c6b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c9b1745e43614bc3bcd9738ffc5362aa",
       "max": 513.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_eb2e553ab84c4e3baaef52ed017514ec",
       "value": 513.0
      }
     },
     "bf09111f744f42589cfe3cbda3cebc38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_17c830efa4e94d17a98b9ac7af8f8fe4",
       "max": 2244861551.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a3191081b3b64e6ba9e938d1af28f216",
       "value": 2244861551.0
      }
     },
     "c29a82ad77cd4c319d4cbc323df8ed7f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "c9b1745e43614bc3bcd9738ffc5362aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d0ae8db4d86646bdba94e4c9e68ab742": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3652dac23e7047cea6a9ce401b3cf57e",
       "placeholder": "​",
       "style": "IPY_MODEL_227e512f3ebc4fbeb7fac53bfac41510",
       "value": " 2.24G/2.24G [01:14&lt;00:00, 30.2MB/s]"
      }
     },
     "d68490bc2757445a8113531b802a901c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f65cf8b7cccb4cae9a6d8ceb288b7591",
       "placeholder": "​",
       "style": "IPY_MODEL_f7f03d047e2d4ed1a6364288ecd77a4a",
       "value": " 5.07M/5.07M [00:04&lt;00:00, 1.21MB/s]"
      }
     },
     "e2eb52e7373b4eccbd2f86e72a8f23e1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eb2e553ab84c4e3baaef52ed017514ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "f2411975460e4c6b8794686b673e7c97": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f65cf8b7cccb4cae9a6d8ceb288b7591": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f7f03d047e2d4ed1a6364288ecd77a4a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
