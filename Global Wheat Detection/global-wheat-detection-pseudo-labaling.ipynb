{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Global Wheat Detection - Pseudo-labeling\n",
    "\n",
    "You can get the training scripts [here](https://github.com/ufownl/global-wheat-detection).\n",
    "\n",
    "* YOLOv3 from [GluonCV](https://gluon-cv.mxnet.io/)\n",
    "* Use Darknet53 backbone\n",
    "* Use [WBF](https://github.com/ZFTurbo/Weighted-Boxes-Fusion) over TTA\n",
    "* Use multi-rounds pseudo-labeling technique"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import pandas as pd\n",
    "import gluoncv as gcv\n",
    "from multiprocessing import cpu_count\n",
    "from multiprocessing.dummy import Pool\n",
    "\n",
    "\n",
    "def load_dataset(root):\n",
    "    csv = pd.read_csv(os.path.join(root, \"train.csv\"))\n",
    "    data = {}\n",
    "    for i in csv.index:\n",
    "        key = csv[\"image_id\"][i]\n",
    "        bbox = json.loads(csv[\"bbox\"][i])\n",
    "        bbox = [bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3], 0.0]\n",
    "        if key in data:\n",
    "            data[key].append(bbox)\n",
    "        else:\n",
    "            data[key] = [bbox]\n",
    "    return sorted(\n",
    "        [(k, os.path.join(root, \"train\", k + \".jpg\"), v) for k, v in data.items()],\n",
    "        key=lambda x: x[0]\n",
    "    )\n",
    "\n",
    "def load_image(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        buf = f.read()\n",
    "    return mx.image.imdecode(buf)\n",
    "\n",
    "def get_batches(dataset, batch_size, width=512, height=512, net=None, ctx=mx.cpu()):\n",
    "    batches = len(dataset) // batch_size\n",
    "    sampler = Sampler(dataset, width, height, net)\n",
    "    stack_fn = [gcv.data.batchify.Stack()]\n",
    "    pad_fn = [gcv.data.batchify.Pad(pad_val=-1)]\n",
    "    if net is None:\n",
    "        batchify_fn = gcv.data.batchify.Tuple(*(stack_fn + pad_fn))\n",
    "    else:\n",
    "        batchify_fn = gcv.data.batchify.Tuple(*(stack_fn * 6 + pad_fn))\n",
    "    with Pool(cpu_count() * 2) as p:\n",
    "        for i in range(batches):\n",
    "            start = i * batch_size\n",
    "            samples = p.map(sampler, range(start, start + batch_size))\n",
    "            batch = batchify_fn(samples)\n",
    "            yield [x.as_in_context(ctx) for x in batch]\n",
    "\n",
    "def gauss_blur(image, level):\n",
    "    return cv2.blur(image, (level * 2 + 1, level * 2 + 1))\n",
    "\n",
    "def gauss_noise(image):\n",
    "    for i in range(image.shape[2]):\n",
    "        c = image[:, :, i]\n",
    "        diff = 255 - c.max();\n",
    "        noise = np.random.normal(0, random.randint(1, 6), c.shape)\n",
    "        noise = (noise - noise.min()) / (noise.max() - noise.min())\n",
    "        noise = diff * noise\n",
    "        image[:, :, i] = c + noise.astype(np.uint8)\n",
    "    return image\n",
    "\n",
    "\n",
    "# This class was modified from YOLO3DefaultTrainTransform of GluonCV\n",
    "class YOLO3TrainTransform:\n",
    "    def __init__(self, width, height, net, mean=(0.485, 0.456, 0.406),\n",
    "                 std=(0.229, 0.224, 0.225), **kwargs):\n",
    "        self._width = width\n",
    "        self._height = height\n",
    "        self._mean = mean\n",
    "        self._std = std\n",
    "\n",
    "        # in case network has reset_ctx to gpu\n",
    "        self._fake_x = mx.nd.zeros((1, 3, height, width))\n",
    "        net = copy.deepcopy(net)\n",
    "        net.collect_params().reset_ctx(None)\n",
    "        with mx.autograd.train_mode():\n",
    "            _, self._anchors, self._offsets, self._feat_maps, _, _, _, _ = net(self._fake_x)\n",
    "        self._target_generator = gcv.model_zoo.yolo.yolo_target.YOLOV3PrefetchTargetGenerator(\n",
    "            num_class=len(net.classes), **kwargs)\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        # random expansion with prob 0.5\n",
    "        if np.random.uniform(0, 1) > 0.5:\n",
    "            img, expand = gcv.data.transforms.image.random_expand(img, max_ratio=1.5, fill=114, keep_ratio=False)\n",
    "            bbox = gcv.data.transforms.bbox.translate(label, x_offset=expand[0], y_offset=expand[1])\n",
    "        else:\n",
    "            img, bbox = img, label\n",
    "\n",
    "        # random cropping\n",
    "        h, w, _ = img.shape\n",
    "        bbox, crop = gcv.data.transforms.experimental.bbox.random_crop_with_constraints(bbox, (w, h))\n",
    "        x0, y0, w, h = crop\n",
    "        img = mx.image.fixed_crop(img, x0, y0, w, h)\n",
    "\n",
    "        # resize with random interpolation\n",
    "        h, w, _ = img.shape\n",
    "        interp = np.random.randint(0, 5)\n",
    "        img = gcv.data.transforms.image.imresize(img, self._width, self._height, interp=interp)\n",
    "        bbox = gcv.data.transforms.bbox.resize(bbox, (w, h), (self._width, self._height))\n",
    "\n",
    "        # random horizontal&vertical flip\n",
    "        h, w, _ = img.shape\n",
    "        img, flips = gcv.data.transforms.image.random_flip(img, px=0.5, py=0.5)\n",
    "        bbox = gcv.data.transforms.bbox.flip(bbox, (w, h), flip_x=flips[0], flip_y=flips[1])\n",
    "\n",
    "        # random color jittering\n",
    "        img = gcv.data.transforms.experimental.image.random_color_distort(img)\n",
    "\n",
    "        # to tensor\n",
    "        img = mx.nd.image.to_tensor(img)\n",
    "        img = mx.nd.image.normalize(img, mean=self._mean, std=self._std)\n",
    "\n",
    "        # generate training target so cpu workers can help reduce the workload on gpu\n",
    "        gt_bboxes = mx.nd.array(bbox[np.newaxis, :, :4])\n",
    "        gt_ids = mx.nd.array(bbox[np.newaxis, :, 4:5])\n",
    "        gt_mixratio = mx.nd.array(bbox[np.newaxis, :, -1:])\n",
    "        objectness, center_targets, scale_targets, weights, class_targets = self._target_generator(\n",
    "            self._fake_x, self._feat_maps, self._anchors, self._offsets,\n",
    "            gt_bboxes, gt_ids, gt_mixratio)\n",
    "        return (img, objectness[0], center_targets[0], scale_targets[0], weights[0],\n",
    "                class_targets[0], gt_bboxes[0])\n",
    "\n",
    "\n",
    "class Sampler:\n",
    "    def __init__(self, dataset, width, height, net=None, **kwargs):\n",
    "        self._dataset = dataset\n",
    "        if net is None:\n",
    "            self._training_mode = False\n",
    "            self._transform = gcv.data.transforms.presets.yolo.YOLO3DefaultValTransform(width, height, **kwargs)\n",
    "        else:\n",
    "            self._training_mode = True\n",
    "            self._transform = YOLO3TrainTransform(width, height, net, **kwargs)\n",
    "\n",
    "    def __call__(self, idx):\n",
    "        if self._training_mode:\n",
    "            raw, bboxes = self._load_mixup(idx)\n",
    "            raw = raw.asnumpy()\n",
    "            blur = random.randint(0, 3)\n",
    "            if blur > 0:\n",
    "                raw = gauss_blur(raw, blur)\n",
    "            raw = gauss_noise(raw)\n",
    "            h, w, _ = raw.shape\n",
    "            rot = random.randint(0, 3)\n",
    "            if rot > 0:\n",
    "                raw = np.rot90(raw, k=rot)\n",
    "                if rot == 1:\n",
    "                    raw_bboxes = bboxes.copy()\n",
    "                    bboxes[:, [0, 2]] = raw_bboxes[:, [1, 3]]\n",
    "                    bboxes[:, [1, 3]] = w - raw_bboxes[:, [2, 0]]\n",
    "                elif rot == 2:\n",
    "                    bboxes[:, [0, 1, 2, 3]] = np.array([[w, h, w, h]]) - bboxes[:, [2, 3, 0, 1]]\n",
    "                elif rot == 3:\n",
    "                    raw_bboxes = bboxes.copy()\n",
    "                    bboxes[:, [0, 2]] = h - raw_bboxes[:, [1, 3]]\n",
    "                    bboxes[:, [1, 3]] = raw_bboxes[:, [2, 0]]\n",
    "                raw_bboxes = bboxes.copy()\n",
    "                bboxes[:, 0] = np.min(raw_bboxes[:, [0, 2]], axis=1)\n",
    "                bboxes[:, 1] = np.min(raw_bboxes[:, [1, 3]], axis=1)\n",
    "                bboxes[:, 2] = np.max(raw_bboxes[:, [0, 2]], axis=1)\n",
    "                bboxes[:, 3] = np.max(raw_bboxes[:, [1, 3]], axis=1)\n",
    "            raw = mx.nd.array(raw)\n",
    "        else:\n",
    "            raw = load_image(self._dataset[idx][1])\n",
    "            bboxes = np.array(self._dataset[idx][2])\n",
    "        res = self._transform(raw, bboxes)\n",
    "        return [mx.nd.array(x) for x in res]\n",
    "\n",
    "    def _load_mixup(self, idx1):\n",
    "        r = random.gauss(0.5, 0.5 / 1.96)\n",
    "        if r > 0.0:\n",
    "            raw1 = load_image(self._dataset[idx1][1])\n",
    "            bboxes1 = np.array(self._dataset[idx1][2])\n",
    "            if r >= 1.0:\n",
    "                return raw1, np.hstack([bboxes1, np.full((bboxes1.shape[0], 1), 1.0)])\n",
    "        idx2 = random.randint(0, len(self._dataset) - 1)\n",
    "        raw2 = load_image(self._dataset[idx2][1])\n",
    "        bboxes2 = np.array(self._dataset[idx2][2])\n",
    "        if r <= 0.0:\n",
    "            return raw2, np.hstack([bboxes2, np.full((bboxes2.shape[0], 1), 1.0)])\n",
    "        h = max(raw1.shape[0], raw2.shape[0])\n",
    "        w = max(raw1.shape[1], raw2.shape[1])\n",
    "        mix_raw = mx.nd.zeros(shape=(h, w, 3), dtype=\"float32\")\n",
    "        mix_raw[:raw1.shape[0], :raw1.shape[1], :] += raw1.astype(\"float32\") * r\n",
    "        mix_raw[:raw2.shape[0], :raw2.shape[1], :] += raw2.astype(\"float32\") * (1.0 - r)\n",
    "        mix_bboxes = np.vstack([\n",
    "            np.hstack([bboxes1, np.full((bboxes1.shape[0], 1), r)]),\n",
    "            np.hstack([bboxes2, np.full((bboxes2.shape[0], 1), 1.0 - r)])\n",
    "        ])\n",
    "        return mix_raw.astype(\"uint8\"), mix_bboxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import gluoncv as gcv\n",
    "\n",
    "\n",
    "def load_model(path, ctx=mx.cpu()):\n",
    "    net = gcv.model_zoo.yolo3_darknet53_custom([\"wheat\"], pretrained_base=False)\n",
    "    net.set_nms(post_nms=150)\n",
    "    net.load_parameters(path, ctx=ctx)\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 20K\r\n",
      "---------- 1 root root 18K Jul 31 14:55 __notebook__.ipynb\r\n",
      "lrwxrwxrwx 1 root root  50 Jul 31 14:55 ensemble_boxes -> /kaggle/input/weighted-boxes-fusion/ensemble_boxes\r\n"
     ]
    }
   ],
   "source": [
    "!ln -snf /kaggle/input/weighted-boxes-fusion/ensemble_boxes && ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import gluoncv as gcv\n",
    "from ensemble_boxes import *\n",
    "\n",
    "\n",
    "def inference(models, path):\n",
    "    raw = load_image(path)\n",
    "    rh, rw, _ = raw.shape\n",
    "    classes_list = []\n",
    "    scores_list = []\n",
    "    bboxes_list = []\n",
    "    for _ in range(5):\n",
    "        img, flips = gcv.data.transforms.image.random_flip(raw, px=0.5, py=0.5)\n",
    "        x, _ = gcv.data.transforms.presets.yolo.transform_test(img, short=img_s)\n",
    "        _, _, xh, xw = x.shape\n",
    "        rot = random.randint(0, 3)\n",
    "        if rot > 0:\n",
    "            x = np.rot90(x.asnumpy(), k=rot, axes=(2, 3))\n",
    "        for model in models:\n",
    "            classes, scores, bboxes = model(mx.nd.array(x, ctx=context))\n",
    "            if rot > 0:\n",
    "                if rot == 1:\n",
    "                    raw_bboxes = bboxes.copy()\n",
    "                    bboxes[0, :, [0, 2]] = xh - raw_bboxes[0, :, [1, 3]]\n",
    "                    bboxes[0, :, [1, 3]] = raw_bboxes[0, :, [2, 0]]\n",
    "                elif rot == 2:\n",
    "                    bboxes[0, :, [0, 1, 2, 3]] = mx.nd.array([[xw], [xh], [xw], [xh]], ctx=context) - bboxes[0, :, [2, 3, 0, 1]]\n",
    "                elif rot == 3:\n",
    "                    raw_bboxes = bboxes.copy()\n",
    "                    bboxes[0, :, [0, 2]] = raw_bboxes[0, :, [1, 3]]\n",
    "                    bboxes[0, :, [1, 3]] = xw - raw_bboxes[0, :, [2, 0]]\n",
    "                raw_bboxes = bboxes.copy()\n",
    "                bboxes[0, :, 0] = raw_bboxes[0, :, [0, 2]].min(axis=0)\n",
    "                bboxes[0, :, 1] = raw_bboxes[0, :, [1, 3]].min(axis=0)\n",
    "                bboxes[0, :, 2] = raw_bboxes[0, :, [0, 2]].max(axis=0)\n",
    "                bboxes[0, :, 3] = raw_bboxes[0, :, [1, 3]].max(axis=0)\n",
    "            bboxes[0, :, :] = gcv.data.transforms.bbox.flip(bboxes[0, :, :], (xw, xh), flip_x=flips[0], flip_y=flips[1])\n",
    "            bboxes[0, :, 0::2] = (bboxes[0, :, 0::2] / (xw - 1)).clip(0.0, 1.0)\n",
    "            bboxes[0, :, 1::2] = (bboxes[0, :, 1::2] / (xh - 1)).clip(0.0, 1.0)\n",
    "            classes_list.append([\n",
    "                int(classes[0, i].asscalar()) for i in range(classes.shape[1])\n",
    "                    if classes[0, i].asscalar() >= 0.0\n",
    "\n",
    "            ])\n",
    "            scores_list.append([\n",
    "                scores[0, i].asscalar() for i in range(classes.shape[1])\n",
    "                    if classes[0, i].asscalar() >= 0.0\n",
    "\n",
    "            ])\n",
    "            bboxes_list.append([\n",
    "                bboxes[0, i].asnumpy().tolist() for i in range(classes.shape[1])\n",
    "                    if classes[0, i].asscalar() >= 0.0\n",
    "            ])\n",
    "    bboxes, scores, classes = weighted_boxes_fusion(bboxes_list, scores_list, classes_list)\n",
    "    bboxes[:, 0::2] *= rw - 1\n",
    "    bboxes[:, 1::2] *= rh - 1\n",
    "    return bboxes, scores, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model...\n",
      "Loading training set...\n",
      "Loading test images...\n",
      "Pseudo labaling...\n",
      "/kaggle/input/global-wheat-detection/test/348a992bb.jpg\n",
      "/kaggle/input/global-wheat-detection/test/796707dd7.jpg\n",
      "/kaggle/input/global-wheat-detection/test/aac893a91.jpg\n",
      "/kaggle/input/global-wheat-detection/test/f5a1f0358.jpg\n",
      "/kaggle/input/global-wheat-detection/test/cb8d261a3.jpg\n",
      "/kaggle/input/global-wheat-detection/test/cc3532ff6.jpg\n",
      "/kaggle/input/global-wheat-detection/test/51f1be19e.jpg\n",
      "/kaggle/input/global-wheat-detection/test/51b3e36ab.jpg\n",
      "/kaggle/input/global-wheat-detection/test/53f253011.jpg\n",
      "/kaggle/input/global-wheat-detection/test/2fd875eaa.jpg\n",
      "Training set:  10\n",
      "Validation set:  338\n",
      "Re-training...\n",
      "[Epoch 0  Batch 1]  batch_loss 118.7437438965  average_loss 118.7437438965  elapsed 12.30s\n",
      "[Epoch 1]  training_loss 118.7437438965  validation_score 0.7460022569  best_score 0.0000000000  duration 24.89s\n",
      "[Epoch 1  Batch 1]  batch_loss 110.7816390991  average_loss 110.7816390991  elapsed 8.06s\n",
      "[Epoch 2]  training_loss 110.7816390991  validation_score 0.7444503307  best_score 0.7460022569  duration 21.12s\n",
      "[Epoch 2  Batch 1]  batch_loss 109.2162246704  average_loss 109.2162246704  elapsed 7.76s\n",
      "[Epoch 3]  training_loss 109.2162246704  validation_score 0.7425000668  best_score 0.7460022569  duration 20.65s\n",
      "[Epoch 3  Batch 1]  batch_loss 77.6874313354  average_loss 77.6874313354  elapsed 7.06s\n",
      "[Epoch 4]  training_loss 77.6874313354  validation_score 0.7406104207  best_score 0.7460022569  duration 19.78s\n",
      "[Epoch 4  Batch 1]  batch_loss 74.8613052368  average_loss 74.8613052368  elapsed 7.80s\n",
      "[Epoch 5]  training_loss 74.8613052368  validation_score 0.7380056381  best_score 0.7460022569  duration 20.85s\n",
      "Loading re-trained model...\n",
      "Pseudo labaling...\n",
      "/kaggle/input/global-wheat-detection/test/348a992bb.jpg\n",
      "/kaggle/input/global-wheat-detection/test/796707dd7.jpg\n",
      "/kaggle/input/global-wheat-detection/test/aac893a91.jpg\n",
      "/kaggle/input/global-wheat-detection/test/f5a1f0358.jpg\n",
      "/kaggle/input/global-wheat-detection/test/cb8d261a3.jpg\n",
      "/kaggle/input/global-wheat-detection/test/cc3532ff6.jpg\n",
      "/kaggle/input/global-wheat-detection/test/51f1be19e.jpg\n",
      "/kaggle/input/global-wheat-detection/test/51b3e36ab.jpg\n",
      "/kaggle/input/global-wheat-detection/test/53f253011.jpg\n",
      "/kaggle/input/global-wheat-detection/test/2fd875eaa.jpg\n",
      "Training set:  10\n",
      "Validation set:  338\n",
      "Re-training...\n",
      "[Epoch 0  Batch 1]  batch_loss 62.7266159058  average_loss 62.7266159058  elapsed 5.85s\n",
      "[Epoch 1]  training_loss 62.7266159058  validation_score 0.7444767952  best_score 0.7460022569  duration 18.63s\n",
      "[Epoch 1  Batch 1]  batch_loss 97.9472351074  average_loss 97.9472351074  elapsed 6.83s\n",
      "[Epoch 2]  training_loss 97.9472351074  validation_score 0.7435486913  best_score 0.7460022569  duration 19.98s\n",
      "[Epoch 2  Batch 1]  batch_loss 93.5131149292  average_loss 93.5131149292  elapsed 7.35s\n",
      "[Epoch 3]  training_loss 93.5131149292  validation_score 0.7413906455  best_score 0.7460022569  duration 20.13s\n",
      "[Epoch 3  Batch 1]  batch_loss 80.7812500000  average_loss 80.7812500000  elapsed 7.06s\n",
      "[Epoch 4]  training_loss 80.7812500000  validation_score 0.7391956449  best_score 0.7460022569  duration 19.62s\n",
      "[Epoch 4  Batch 1]  batch_loss 109.1060104370  average_loss 109.1060104370  elapsed 7.46s\n",
      "[Epoch 5]  training_loss 109.1060104370  validation_score 0.7360672355  best_score 0.7460022569  duration 20.51s\n",
      "Loading re-trained model...\n",
      "Pseudo labaling...\n",
      "/kaggle/input/global-wheat-detection/test/348a992bb.jpg\n",
      "/kaggle/input/global-wheat-detection/test/796707dd7.jpg\n",
      "/kaggle/input/global-wheat-detection/test/aac893a91.jpg\n",
      "/kaggle/input/global-wheat-detection/test/f5a1f0358.jpg\n",
      "/kaggle/input/global-wheat-detection/test/cb8d261a3.jpg\n",
      "/kaggle/input/global-wheat-detection/test/cc3532ff6.jpg\n",
      "/kaggle/input/global-wheat-detection/test/51f1be19e.jpg\n",
      "/kaggle/input/global-wheat-detection/test/51b3e36ab.jpg\n",
      "/kaggle/input/global-wheat-detection/test/53f253011.jpg\n",
      "/kaggle/input/global-wheat-detection/test/2fd875eaa.jpg\n",
      "Training set:  10\n",
      "Validation set:  338\n",
      "Re-training...\n",
      "[Epoch 0  Batch 1]  batch_loss 76.0282363892  average_loss 76.0282363892  elapsed 6.21s\n",
      "[Epoch 1]  training_loss 76.0282363892  validation_score 0.7444652915  best_score 0.7460022569  duration 18.77s\n",
      "[Epoch 1  Batch 1]  batch_loss 81.9939575195  average_loss 81.9939575195  elapsed 6.71s\n",
      "[Epoch 2]  training_loss 81.9939575195  validation_score 0.7427688241  best_score 0.7460022569  duration 19.91s\n",
      "[Epoch 2  Batch 1]  batch_loss 64.1757431030  average_loss 64.1757431030  elapsed 7.45s\n",
      "[Epoch 3]  training_loss 64.1757431030  validation_score 0.7406875491  best_score 0.7460022569  duration 20.06s\n",
      "[Epoch 3  Batch 1]  batch_loss 80.1046066284  average_loss 80.1046066284  elapsed 7.05s\n",
      "[Epoch 4]  training_loss 80.1046066284  validation_score 0.7389176488  best_score 0.7460022569  duration 19.96s\n",
      "[Epoch 4  Batch 1]  batch_loss 143.5652618408  average_loss 143.5652618408  elapsed 6.97s\n",
      "[Epoch 5]  training_loss 143.5652618408  validation_score 0.7365406156  best_score 0.7460022569  duration 20.43s\n",
      "Loading re-trained model...\n",
      "Inference...\n",
      "/kaggle/input/global-wheat-detection/test/348a992bb.jpg\n",
      "/kaggle/input/global-wheat-detection/test/796707dd7.jpg\n",
      "/kaggle/input/global-wheat-detection/test/aac893a91.jpg\n",
      "/kaggle/input/global-wheat-detection/test/f5a1f0358.jpg\n",
      "/kaggle/input/global-wheat-detection/test/cb8d261a3.jpg\n",
      "/kaggle/input/global-wheat-detection/test/cc3532ff6.jpg\n",
      "/kaggle/input/global-wheat-detection/test/51f1be19e.jpg\n",
      "/kaggle/input/global-wheat-detection/test/51b3e36ab.jpg\n",
      "/kaggle/input/global-wheat-detection/test/53f253011.jpg\n",
      "/kaggle/input/global-wheat-detection/test/2fd875eaa.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import mxnet as mx\n",
    "import pandas as pd\n",
    "from mxnet.contrib import amp\n",
    "\n",
    "amp.init()\n",
    "\n",
    "rounds = 3\n",
    "max_epochs = 5\n",
    "learning_rate = 0.001\n",
    "batch_size = 8\n",
    "img_s = 512\n",
    "threshold = 0.1\n",
    "context = mx.gpu()\n",
    "\n",
    "print(\"Loading pre-trained model...\")\n",
    "model = load_model(\"/kaggle/input/global-wheat-detection-private/global-wheat-yolo3-darknet53.params\", ctx=context)\n",
    "\n",
    "print(\"Loading training set...\")\n",
    "dataset = load_dataset(\"/kaggle/input/global-wheat-detection\")\n",
    "\n",
    "print(\"Loading test images...\")\n",
    "test_images = [\n",
    "    (os.path.join(dirname, filename), os.path.splitext(filename)[0])\n",
    "        for dirname, _, filenames in os.walk('/kaggle/input/global-wheat-detection/test') for filename in filenames\n",
    "]\n",
    "\n",
    "best_score = 0.0\n",
    "metrics = [gcv.utils.metrics.VOCMApMetric(iou_thresh=iou) for iou in [0.5, 0.55, 0.6, 0.65, 0.7, 0.75]]\n",
    "for pseudo_models in [[model]] * rounds:\n",
    "    print(\"Pseudo labaling...\")\n",
    "    pseudo_set = []\n",
    "    for path, image_id in test_images:\n",
    "        print(path)\n",
    "        bboxes, scores, classes = inference(pseudo_models, path)\n",
    "        label = [\n",
    "            [round(x) for x in bboxes[i].tolist()] + [0.0] for i in range(classes.shape[0])\n",
    "                if model.classes[int(classes[i])] == \"wheat\" and scores[i] > threshold\n",
    "        ]\n",
    "        if len(label) > 0:\n",
    "            pseudo_set.append((image_id, path, label))\n",
    "\n",
    "    training_set = pseudo_set\n",
    "    validation_set = dataset[int(len(dataset) * 0.9):]\n",
    "    print(\"Training set: \", len(training_set))\n",
    "    print(\"Validation set: \", len(validation_set))\n",
    "\n",
    "    print(\"Re-training...\")\n",
    "    trainer = mx.gluon.Trainer(model.collect_params(), \"Nadam\", {\n",
    "        \"learning_rate\": learning_rate\n",
    "    }, kvstore='local', update_on_kvstore=False)\n",
    "    amp.init_trainer(trainer)\n",
    "    for epoch in range(max_epochs):\n",
    "        ts = time.time()\n",
    "        random.shuffle(training_set)\n",
    "        training_total_L = 0.0\n",
    "        training_batches = 0\n",
    "        for x, objectness, center_targets, scale_targets, weights, class_targets, gt_bboxes in get_batches(training_set, batch_size, width=img_s, height=img_s, net=model, ctx=context):\n",
    "            training_batches += 1\n",
    "            with mx.autograd.record():\n",
    "                obj_loss, center_loss, scale_loss, cls_loss = model(x, gt_bboxes, objectness, center_targets, scale_targets, weights, class_targets)\n",
    "                L = obj_loss + center_loss + scale_loss + cls_loss\n",
    "                with amp.scale_loss(L, trainer) as scaled_L:\n",
    "                    scaled_L.backward()\n",
    "            trainer.step(x.shape[0])\n",
    "            training_batch_L = mx.nd.mean(L).asscalar()\n",
    "            if training_batch_L != training_batch_L:\n",
    "                raise ValueError()\n",
    "            training_total_L += training_batch_L\n",
    "            print(\"[Epoch %d  Batch %d]  batch_loss %.10f  average_loss %.10f  elapsed %.2fs\" % (\n",
    "                epoch, training_batches, training_batch_L, training_total_L / training_batches, time.time() - ts\n",
    "            ))\n",
    "        training_avg_L = training_total_L / training_batches\n",
    "        for metric in metrics:\n",
    "            metric.reset()\n",
    "        for x, label in get_batches(validation_set, batch_size, width=img_s, height=img_s, ctx=context):\n",
    "            classes, scores, bboxes = model(x)\n",
    "            for metric in metrics:\n",
    "                metric.update(\n",
    "                    bboxes,\n",
    "                    classes.reshape((0, -1)),\n",
    "                    scores.reshape((0, -1)),\n",
    "                    label[:, :, :4],\n",
    "                    label[:, :, 4:5].reshape((0, -1))\n",
    "                )\n",
    "        score = mx.nd.array([metric.get()[1] for metric in metrics], ctx=context).mean()\n",
    "        print(\"[Epoch %d]  training_loss %.10f  validation_score %.10f  best_score %.10f  duration %.2fs\" % (\n",
    "            epoch + 1, training_avg_L, score.asscalar(), best_score, time.time() - ts\n",
    "        ))\n",
    "        if score.asscalar() > best_score:\n",
    "            best_score = score.asscalar()\n",
    "            model.save_parameters(\"global-wheat-yolo3-darknet53.params\")\n",
    "\n",
    "    print(\"Loading re-trained model...\")\n",
    "    model = load_model(\"global-wheat-yolo3-darknet53.params\", ctx=context)\n",
    "\n",
    "print(\"Inference...\")\n",
    "results = []\n",
    "for path, image_id in test_images:\n",
    "    print(path)\n",
    "    bboxes, scores, classes = inference([model], path)\n",
    "    bboxes[:, 2:4] -= bboxes[:, 0:2]\n",
    "    results.append({\n",
    "        \"image_id\": image_id,\n",
    "        \"PredictionString\": \" \".join([\n",
    "            \" \".join([str(x) for x in [scores[i]] + [round(x) for x in bboxes[i].tolist()]])\n",
    "                for i in range(classes.shape[0])\n",
    "                    if model.classes[int(classes[i])] == \"wheat\" and scores[i] > threshold\n",
    "        ])\n",
    "    })\n",
    "pd.DataFrame(results, columns=['image_id', 'PredictionString']).to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm global-wheat-yolo3-darknet53.params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
