{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"!git clone https://github.com/ultralytics/yolov5","execution_count":2,"outputs":[{"output_type":"stream","text":"Cloning into 'yolov5'...\nremote: Enumerating objects: 12, done.\u001b[K\nremote: Counting objects: 100% (12/12), done.\u001b[K\nremote: Compressing objects: 100% (9/9), done.\u001b[K\nremote: Total 678 (delta 3), reused 8 (delta 3), pack-reused 666\u001b[K\nReceiving objects: 100% (678/678), 3.36 MiB | 23.06 MiB/s, done.\nResolving deltas: 100% (438/438), done.\n","name":"stdout"}]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"!mv yolov5/* ./","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"!pip install -r requirements.txt","execution_count":4,"outputs":[{"output_type":"stream","text":"Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI (from -r requirements.txt (line 13))\n  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-s5ov_kfi\n  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-s5ov_kfi\nRequirement already satisfied: Cython in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (0.29.19)\nCollecting numpy==1.17\n  Downloading numpy-1.17.0-cp37-cp37m-manylinux1_x86_64.whl (20.3 MB)\n\u001b[K     |████████████████████████████████| 20.3 MB 565 kB/s eta 0:00:01    |▎                               | 204 kB 2.9 MB/s eta 0:00:07     |█████                           | 3.2 MB 2.9 MB/s eta 0:00:06     |████████▋                       | 5.5 MB 2.9 MB/s eta 0:00:06     |██████████████▉                 | 9.4 MB 2.9 MB/s eta 0:00:04     |████████████████▉               | 10.7 MB 2.9 MB/s eta 0:00:04     |███████████████████             | 12.1 MB 2.9 MB/s eta 0:00:03\n\u001b[?25hRequirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (4.2.0.34)\nRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (1.5.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (3.2.1)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (5.4.1)\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (2.2.2)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 9)) (5.3.1)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 10)) (0.6.0a0+82fd1c8)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 11)) (1.4.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 12)) (4.45.0)\nRequirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools==2.0->-r requirements.txt (line 13)) (46.1.3.post20200325)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->-r requirements.txt (line 5)) (0.18.2)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 6)) (0.10.0)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 6)) (2.4.7)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.2.0)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 6)) (2.8.1)\nRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 8)) (1.29.0)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 8)) (2.23.0)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 8)) (1.14.0)\nRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 8)) (3.11.4)\nRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 8)) (0.34.2)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 8)) (3.2.1)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 8)) (1.0.1)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 8)) (0.9.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 8)) (0.4.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 8)) (1.6.0.post3)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r requirements.txt (line 8)) (1.14.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 8)) (2020.4.5.1)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 8)) (2.9)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 8)) (1.24.3)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 8)) (3.0.4)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 8)) (1.2.0)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (3.1.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (0.2.7)\nRequirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (4.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 8)) (3.0.1)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (0.4.8)\nBuilding wheels for collected packages: pycocotools\n  Building wheel for pycocotools (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0-cp37-cp37m-linux_x86_64.whl size=274038 sha256=4345e1d7fee6d8e2309ce6541fae4ea9b8f91ca458883cf9f8e1f91bf207ca72\n  Stored in directory: /tmp/pip-ephem-wheel-cache-laft2aoq/wheels/e2/6b/1d/344ac773c7495ea0b85eb228bc66daec7400a143a92d36b7b1\nSuccessfully built pycocotools\n\u001b[31mERROR: osmnx 0.14.0 has requirement geopandas>=0.7, but you'll have geopandas 0.6.3 which is incompatible.\u001b[0m\n\u001b[31mERROR: osmnx 0.14.0 has requirement numpy>=1.18, but you'll have numpy 1.17.0 which is incompatible.\u001b[0m\n\u001b[31mERROR: kmeans-smote 0.1.2 has requirement imbalanced-learn<0.5,>=0.4.0, but you'll have imbalanced-learn 0.6.2 which is incompatible.\u001b[0m\n\u001b[31mERROR: kmeans-smote 0.1.2 has requirement numpy<1.16,>=1.13, but you'll have numpy 1.17.0 which is incompatible.\u001b[0m\n\u001b[31mERROR: kmeans-smote 0.1.2 has requirement scikit-learn<0.21,>=0.19.0, but you'll have scikit-learn 0.23.1 which is incompatible.\u001b[0m\n\u001b[31mERROR: hypertools 0.6.2 has requirement scikit-learn<0.22,>=0.19.1, but you'll have scikit-learn 0.23.1 which is incompatible.\u001b[0m\n\u001b[31mERROR: dask-ml 1.5.0 has requirement numpy>=1.17.3, but you'll have numpy 1.17.0 which is incompatible.\u001b[0m\n\u001b[31mERROR: allennlp 0.9.0 has requirement spacy<2.2,>=2.1.0, but you'll have spacy 2.2.3 which is incompatible.\u001b[0m\nInstalling collected packages: numpy, pycocotools\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.18.1\n    Uninstalling numpy-1.18.1:\n      Successfully uninstalled numpy-1.18.1\n","name":"stdout"},{"output_type":"stream","text":"Successfully installed numpy-1.18.1 pycocotools-2.0\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/global-wheat-detection/train.csv')\nbboxs = np.stack(df['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))\nfor i, column in enumerate(['x', 'y', 'w', 'h']):\n    df[column] = bboxs[:,i]\ndf.drop(columns=['bbox'], inplace=True)\ndf['x_center'] = df['x'] + df['w']/2\ndf['y_center'] = df['y'] + df['h']/2\ndf['classes'] = 0\nfrom tqdm.auto import tqdm\nimport shutil as sh\ndf = df[['image_id','x', 'y', 'w', 'h','x_center','y_center','classes']]","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"    image_id      x      y      w      h  x_center  y_center  classes\n0  b6ab77fd7  834.0  222.0   56.0   36.0     862.0     240.0        0\n1  b6ab77fd7  226.0  548.0  130.0   58.0     291.0     577.0        0\n2  b6ab77fd7  377.0  504.0   74.0  160.0     414.0     584.0        0\n3  b6ab77fd7  834.0   95.0  109.0  107.0     888.5     148.5        0\n4  b6ab77fd7   26.0  144.0  124.0  117.0      88.0     202.5        0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>x</th>\n      <th>y</th>\n      <th>w</th>\n      <th>h</th>\n      <th>x_center</th>\n      <th>y_center</th>\n      <th>classes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b6ab77fd7</td>\n      <td>834.0</td>\n      <td>222.0</td>\n      <td>56.0</td>\n      <td>36.0</td>\n      <td>862.0</td>\n      <td>240.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b6ab77fd7</td>\n      <td>226.0</td>\n      <td>548.0</td>\n      <td>130.0</td>\n      <td>58.0</td>\n      <td>291.0</td>\n      <td>577.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b6ab77fd7</td>\n      <td>377.0</td>\n      <td>504.0</td>\n      <td>74.0</td>\n      <td>160.0</td>\n      <td>414.0</td>\n      <td>584.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b6ab77fd7</td>\n      <td>834.0</td>\n      <td>95.0</td>\n      <td>109.0</td>\n      <td>107.0</td>\n      <td>888.5</td>\n      <td>148.5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b6ab77fd7</td>\n      <td>26.0</td>\n      <td>144.0</td>\n      <td>124.0</td>\n      <td>117.0</td>\n      <td>88.0</td>\n      <td>202.5</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"index = list(set(df.image_id))","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"source = 'train'\nif True:\n    for fold in [0]:\n        val_index = index[len(index)*fold//5:len(index)*(fold+1)//5]\n        for name,mini in tqdm(df.groupby('image_id')):\n            if name in val_index:\n                path2save = 'val2017/'\n            else:\n                path2save = 'train2017/'\n            if not os.path.exists('convertor/fold{}/labels/'.format(fold)+path2save):\n                os.makedirs('convertor/fold{}/labels/'.format(fold)+path2save)\n            with open('convertor/fold{}/labels/'.format(fold)+path2save+name+\".txt\", 'w+') as f:\n                row = mini[['classes','x_center','y_center','w','h']].astype(float).values\n                row = row/1024\n                row = row.astype(str)\n                for j in range(len(row)):\n                    text = ' '.join(row[j])\n                    f.write(text)\n                    f.write(\"\\n\")\n            if not os.path.exists('convertor/fold{}/images/{}'.format(fold,path2save)):\n                os.makedirs('convertor/fold{}/images/{}'.format(fold,path2save))\n            sh.copy(\"../input/global-wheat-detection/{}/{}.jpg\".format(source,name),'convertor/fold{}/images/{}/{}.jpg'.format(fold,path2save,name))","execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=3373.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ee0d84ff1684b0f9abe47ae8b74572a"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python train.py --img 1024 --batch 2 --epochs 1 --data ../input/configyolo5/wheat0.yaml --cfg ../input/configyolo5/yolov5x.yaml --name yolov5x_fold0","execution_count":null,"outputs":[{"output_type":"stream","text":"Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n{'lr0': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'giou': 0.05, 'cls': 0.58, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.014, 'hsv_s': 0.68, 'hsv_v': 0.36, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.5, 'shear': 0.0}\nNamespace(adam=False, batch_size=2, bucket='', cache_images=False, cfg='../input/configyolo5/yolov5x.yaml', data='../input/configyolo5/wheat0.yaml', device='', epochs=1, evolve=False, img_size=[1024], multi_scale=False, name='yolov5x_fold0', noautoanchor=False, nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='')\nUsing CUDA device0 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', total_memory=16280MB)\n\n2020-06-22 15:42:01.186229: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\nStart Tensorboard with \"tensorboard --logdir=runs\", view at http://localhost:6006/\n\n              from  n    params  module                                  arguments                     \n  0             -1  1      8800  models.common.Focus                     [3, 80, 3]                    \n  1             -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n  2             -1  4    513920  models.common.Bottleneck                [160, 160]                    \n  3             -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n  4             -1  1   3311680  models.common.BottleneckCSP             [320, 320, 12]                \n  5             -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n  6             -1  1  13228160  models.common.BottleneckCSP             [640, 640, 12]                \n  7             -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n  8             -1  1   4099840  models.common.SPP                       [1280, 1280, [5, 9, 13]]      \n  9             -1  1  36481280  models.common.BottleneckCSP             [1280, 1280, 8]               \n 10             -1  1  20087040  models.common.BottleneckCSP             [1280, 1280, 4, False]        \n 11             -1  1     23058  torch.nn.modules.conv.Conv2d            [1280, 18, 1, 1]              \n 12             -2  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 13        [-1, 6]  1         0  models.common.Concat                    [1]                           \n 14             -1  1   1230080  models.common.Conv                      [1920, 640, 1, 1]             \n 15             -1  1   5025920  models.common.BottleneckCSP             [640, 640, 4, False]          \n 16             -1  1     11538  torch.nn.modules.conv.Conv2d            [640, 18, 1, 1]               \n 17             -2  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 18        [-1, 4]  1         0  models.common.Concat                    [1]                           \n 19             -1  1    307840  models.common.Conv                      [960, 320, 1, 1]              \n 20             -1  1   1258560  models.common.BottleneckCSP             [320, 320, 4, False]          \n 21             -1  1      5778  torch.nn.modules.conv.Conv2d            [320, 18, 1, 1]               \n 22   [-1, 16, 11]  1         0  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]]]\nModel Summary: 381 layers, 9.53903e+07 parameters, 9.53903e+07 gradients\n\nOptimizer groups: 126 .bias, 132 conv.weight, 123 other\nReading image shapes: 100%|███████████████| 2699/2699 [00:00<00:00, 8716.50it/s]\nCaching labels convertor/fold0/labels/train2017 (2699 found, 0 missing, 0 empty,\nSaving labels to convertor/fold0/labels/train2017.npy for faster future loading\nReading image shapes: 100%|█████████████████| 674/674 [00:00<00:00, 9278.25it/s]\nCaching labels convertor/fold0/labels/val2017 (674 found, 0 missing, 0 empty, 0 \n\nAnalyzing anchors... Best Possible Recall (BPR) = 0.9991\nImage sizes 1024 train, 1024 test\nUsing 2 dataloader workers\nStarting training for 1 epochs...\n\n     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n       0/0     11.4G    0.1138    0.1664         0    0.2803        58      1024","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}