{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install pretrainedmodels\n# !pip install torchtoolbox\n# !pip install torchviz\n# !pip install efficientnet_pytorch\n!git clone https://github.com/4uiiurz1/pytorch-auto-augment > /dev/null\n\nVERSION = \"20200516\"  #@param [\"1.5\" , \"20200516\", \"nightly\"]\n!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --version $VERSION --apt-packages libomp5 libopenblas-dev","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting pretrainedmodels\n  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n\u001b[K     |████████████████████████████████| 58 kB 2.8 MB/s eta 0:00:011\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (1.5.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (0.6.0a0+35d732a)\nRequirement already satisfied: munch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (2.5.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (4.45.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels) (0.18.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels) (1.18.5)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->pretrainedmodels) (7.2.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from munch->pretrainedmodels) (1.14.0)\nBuilding wheels for collected packages: pretrainedmodels\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60962 sha256=39f5be71947e71771e0939ab0ced7e202e0599f2c11ef0585ef10bf40affb183\n  Stored in directory: /root/.cache/pip/wheels/ed/27/e8/9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\nSuccessfully built pretrainedmodels\nInstalling collected packages: pretrainedmodels\nSuccessfully installed pretrainedmodels-0.7.4\nCloning into 'pytorch-auto-augment'...\nremote: Enumerating objects: 20, done.\u001b[K\nremote: Total 20 (delta 0), reused 0 (delta 0), pack-reused 20\u001b[K\nUnpacking objects: 100% (20/20), done.\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  4139  100  4139    0     0   115k      0 --:--:-- --:--:-- --:--:--  115k\nUpdating TPU and VM. This may take around 2 minutes.\nUpdating TPU runtime to pytorch-dev20200516 ...\nFound existing installation: torch 1.5.0\nUninstalling torch-1.5.0:\n  Successfully uninstalled torch-1.5.0\nFound existing installation: torchvision 0.6.0a0+35d732a\nUninstalling torchvision-0.6.0a0+35d732a:\nDone updating TPU runtime\n  Successfully uninstalled torchvision-0.6.0a0+35d732a\nCopying gs://tpu-pytorch/wheels/torch-nightly+20200516-cp37-cp37m-linux_x86_64.whl...\n\\ [1 files][ 91.1 MiB/ 91.1 MiB]                                                \nOperation completed over 1 objects/91.1 MiB.                                     \nCopying gs://tpu-pytorch/wheels/torch_xla-nightly+20200516-cp37-cp37m-linux_x86_64.whl...\n\\ [1 files][119.8 MiB/119.8 MiB]                                                \nOperation completed over 1 objects/119.8 MiB.                                    \nCopying gs://tpu-pytorch/wheels/torchvision-nightly+20200516-cp37-cp37m-linux_x86_64.whl...\n/ [1 files][  2.3 MiB/  2.3 MiB]                                                \nOperation completed over 1 objects/2.3 MiB.                                      \nProcessing ./torch-nightly+20200516-cp37-cp37m-linux_x86_64.whl\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch==nightly+20200516) (1.18.5)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch==nightly+20200516) (0.18.2)\n\u001b[31mERROR: pretrainedmodels 0.7.4 requires torchvision, which is not installed.\u001b[0m\n\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n\u001b[31mERROR: kornia 0.3.1 has requirement torch==1.5.0, but you'll have torch 1.6.0a0+83df3be which is incompatible.\u001b[0m\n\u001b[31mERROR: allennlp 1.0.0 has requirement torch<1.6.0,>=1.5.0, but you'll have torch 1.6.0a0+83df3be which is incompatible.\u001b[0m\nInstalling collected packages: torch\nSuccessfully installed torch-1.6.0a0+83df3be\nProcessing ./torch_xla-nightly+20200516-cp37-cp37m-linux_x86_64.whl\nInstalling collected packages: torch-xla\nSuccessfully installed torch-xla-1.6+2191422\nProcessing ./torchvision-nightly+20200516-cp37-cp37m-linux_x86_64.whl\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly+20200516) (1.6.0a0+83df3be)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly+20200516) (1.18.5)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly+20200516) (7.2.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->torchvision==nightly+20200516) (0.18.2)\nInstalling collected packages: torchvision\nSuccessfully installed torchvision-0.7.0a0+348dd5a\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following additional packages will be installed:\n  libgfortran4 libopenblas-base\nThe following NEW packages will be installed:\n  libgfortran4 libomp5 libopenblas-base libopenblas-dev\n0 upgraded, 4 newly installed, 0 to remove and 52 not upgraded.\nNeed to get 8550 kB of archives.\nAfter this operation, 97.6 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgfortran4 amd64 7.5.0-3ubuntu1~18.04 [492 kB]\nGet:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenblas-base amd64 0.2.20+ds-4 [3964 kB]\nGet:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenblas-dev amd64 0.2.20+ds-4 [3860 kB]\nGet:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\nFetched 8550 kB in 0s (40.0 MB/s) \ndebconf: delaying package configuration, since apt-utils is not installed\nSelecting previously unselected package libgfortran4:amd64.\n(Reading database ... 107461 files and directories currently installed.)\nPreparing to unpack .../libgfortran4_7.5.0-3ubuntu1~18.04_amd64.deb ...\nUnpacking libgfortran4:amd64 (7.5.0-3ubuntu1~18.04) ...\nSelecting previously unselected package libopenblas-base:amd64.\nPreparing to unpack .../libopenblas-base_0.2.20+ds-4_amd64.deb ...\nUnpacking libopenblas-base:amd64 (0.2.20+ds-4) ...\nSelecting previously unselected package libopenblas-dev:amd64.\nPreparing to unpack .../libopenblas-dev_0.2.20+ds-4_amd64.deb ...\nUnpacking libopenblas-dev:amd64 (0.2.20+ds-4) ...\nSelecting previously unselected package libomp5:amd64.\nPreparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\nUnpacking libomp5:amd64 (5.0.1-1) ...\nSetting up libomp5:amd64 (5.0.1-1) ...\nSetting up libgfortran4:amd64 (7.5.0-3ubuntu1~18.04) ...\nSetting up libopenblas-base:amd64 (0.2.20+ds-4) ...\nupdate-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3 to provide /usr/lib/x86_64-linux-gnu/libblas.so.3 (libblas.so.3-x86_64-linux-gnu) in auto mode\nupdate-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/liblapack.so.3 to provide /usr/lib/x86_64-linux-gnu/liblapack.so.3 (liblapack.so.3-x86_64-linux-gnu) in auto mode\nSetting up libopenblas-dev:amd64 (0.2.20+ds-4) ...\nupdate-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/libblas.so to provide /usr/lib/x86_64-linux-gnu/libblas.so (libblas.so-x86_64-linux-gnu) in auto mode\nupdate-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/liblapack.so to provide /usr/lib/x86_64-linux-gnu/liblapack.so (liblapack.so-x86_64-linux-gnu) in auto mode\nProcessing triggers for libc-bin (2.27-3ubuntu1) ...\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Importing Dependencies"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%autosave 30\nimport os\nos.environ['XLA_USE_BF16'] = \"1\"\nimport sys\nsys.path.insert(0, './pytorch-auto-augment')\nimport gc\ngc.enable()\nimport time\nimport glob\nimport random\nfrom datetime import datetime\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom skimage import io\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport tqdm as tqdm\nfrom PIL import Image\n\nimport torch\nimport torchvision\nfrom torchvision import transforms, models\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import SequentialSampler, BatchSampler, RandomSampler\n\nimport torch_xla\nimport torch_xla.core.xla_model as xm\nimport torch_xla.debug.metrics as met\nimport torch_xla.distributed.data_parallel as dp\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.distributed.xla_multiprocessing as xmp\nimport torch_xla.utils.utils as xu\n\n# from torchviz import make_dot\nimport albumentations as A\nfrom auto_augment import AutoAugment, Cutout\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom catalyst.data.sampler import DistributedSamplerWrapper, BalanceClassSampler\nimport pretrainedmodels\n# from efficientnet_pytorch import EfficientNet\n\nimport sklearn\nfrom sklearn import metrics\nfrom sklearn.model_selection import GroupKFold\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\")","execution_count":2,"outputs":[{"output_type":"display_data","data":{"application/javascript":"IPython.notebook.set_autosave_interval(30000)"},"metadata":{}},{"output_type":"stream","text":"Autosaving every 30 seconds\n","name":"stdout"},{"output_type":"stream","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n/opt/conda/lib/python3.7/site-packages/tqdm/std.py:666: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n  from pandas import Panel\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"### Configuration"},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nSEED = 2020\nseed_everything(SEED)","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = []\n\nfor label, kind in enumerate(['Cover', 'JMiPOD', 'JUNIWARD', 'UERD']):\n    for path in glob.glob('../input/alaska2-image-steganalysis/Cover/*.jpg'):\n        dataset.append({\n            'kind': kind,\n            'image_name': path.split('/')[-1],\n            'label': label\n        })\n        \nrandom.shuffle(dataset)\ndataset = pd.DataFrame(dataset)\ngkf = GroupKFold(n_splits=5)\ndataset.loc[:, 'fold'] = 0\nfor fold_number, (train_index, val_index) in enumerate(gkf.split(X=dataset.index, y=dataset['label'], groups=dataset['image_name'])):\n    dataset.loc[dataset.iloc[val_index].index, 'fold'] = fold_number","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Augmentations"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_train_transforms():\n    return transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        # AutoAugment(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n    ])\n\ndef get_valid_transforms():\n    return transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n    ])","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"def one_hot(size, target):\n    vec = torch.zeros(size, dtype=torch.float32)\n    vec[target] = 1.\n    return vec\n\nDATA_ROOT_PATH = '/kaggle/input/alaska2-image-steganalysis/'\n\nclass AlaskaDataset(Dataset):\n    def __init__(self, kinds, image_names, labels, transforms=None):\n        super().__init__()\n        self.kinds = kinds\n        self.image_names = image_names\n        self.labels = labels\n        self.transforms = transforms\n\n    def __getitem__(self, index: int):\n        kind, image_name, label = self.kinds[index], self.image_names[index], self.labels[index]\n        image = cv2.imread(f'{DATA_ROOT_PATH}/{kind}/{image_name}', cv2.IMREAD_COLOR)\n        image = cv2.resize(image, (331, 331), cv2.INTER_AREA)\n        if self.transforms:\n            image = self.transforms(image)\n        target = one_hot(4, label)\n        return image, target\n\n    def __len__(self) -> int:\n        return self.image_names.shape[0]\n    \n    def get_labels(self):\n        return list(self.labels)","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loader"},{"metadata":{"trusted":true},"cell_type":"code","source":"fold_number = 0\nSERIAL_EXEC = xmp.MpSerialExecutor()\n\ntrain_dataset = AlaskaDataset(\n    kinds=dataset[dataset['fold'] != fold_number].kind.values,\n    image_names=dataset[dataset['fold'] != fold_number].image_name.values,\n    labels=dataset[dataset['fold'] != fold_number].label.values,\n    transforms=get_train_transforms(),\n)\n\nvalidation_dataset = AlaskaDataset(\n    kinds=dataset[dataset['fold'] == fold_number].kind.values,\n    image_names=dataset[dataset['fold'] == fold_number].image_name.values,\n    labels=dataset[dataset['fold'] == fold_number].label.values,\n    transforms=get_valid_transforms(),\n)","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SE_ResNext50_32x4d(nn.Module):\n    def __init__(self, pretrained=None):\n        super(SE_ResNext50_32x4d, self).__init__()\n        self.model = pretrainedmodels.__dict__['se_resnext50_32x4d'](pretrained=None)\n        if pretrained is not None:\n            # https://www.kaggle.com/abhishek/pretrained-model-weights-pytorch - Download\n            self.model.load_state_dict(\n                torch.load('../input/pretrained-model-weights-pytorch/se_resnext50_32x4d-a260b3a4.pth')\n            )\n        self.dropout = nn.Dropout(p=0.1)\n        self.high_dropout = nn.Dropout(p=0.5)\n        self.classifier = nn.Linear(in_features=2048, out_features=4)\n    \n    def forward(self, images):\n        batch_size, _, _, _ = images.shape\n        features = self.model.features(images)\n        avg_pool = F.adaptive_avg_pool2d(features, 1).reshape(batch_size, -1)\n        logits = torch.mean(\n            torch.stack(\n                [self.classifier(self.dropout(avg_pool)) for _ in range(5)],\n                dim=0,\n            ),\n            dim=0,\n        )\n        return logits","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def alaska_weighted_auc(y_true, y_valid):\n    tpr_thresholds = [0.0, 0.4, 1.0]\n    weights = [2, 1]\n    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_valid, pos_label=1)\n    areas = np.array(tpr_thresholds[1:]) - np.array(tpr_thresholds[:-1])\n    normalization = np.dot(areas, weights)\n    competition_metric = 0\n    for idx, weight in enumerate(weights):\n        y_min = tpr_thresholds[idx]\n        y_max = tpr_thresholds[idx + 1]\n        mask = (y_min < tpr) & (tpr < y_max)\n        x_padding = np.linspace(fpr[mask][-1], 1, 100)\n        x = np.concatenate([fpr[mask], x_padding])\n        y = np.concatenate([tpr[mask], [y_max] * len(x_padding)])\n        y = y - y_min \n        score = metrics.auc(x, y)\n        submetric = score * weight\n        best_subscore = (y_max - y_min) * weight\n        competition_metric += submetric\n    return competition_metric / normalization\n        \nclass RocAucMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.y_true = np.array([0,1])\n        self.y_pred = np.array([0.5,0.5])\n        self.score = 0\n\n    def update(self, y_true, y_pred):\n        y_true = y_true.cpu().numpy().argmax(axis=1).clip(min=0, max=1).astype(int)\n        y_pred = 1 - nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,0]\n        self.y_true = np.hstack((self.y_true, y_true))\n        self.y_pred = np.hstack((self.y_pred, y_pred))\n        self.score = alaska_weighted_auc(self.y_true, self.y_pred)\n    \n    @property\n    def avg(self):\n        return self.score","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"class LabelSmoothing(nn.Module):\n    def __init__(self, smoothing = 0.05):\n        super(LabelSmoothing, self).__init__()\n        self.confidence = 1.0 - smoothing\n        self.smoothing = smoothing\n\n    def forward(self, x, target):\n        if self.training:\n            x = x.float()\n            target = target.float()\n            logprobs = torch.nn.functional.log_softmax(x, dim = -1)\n            nll_loss = -logprobs * target\n            nll_loss = nll_loss.sum(-1)\n            smooth_loss = -logprobs.mean(dim=-1)\n            loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n            return loss.mean()\n        else:\n            return torch.nn.functional.cross_entropy(x, target)","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Engine"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Engine:\n    \n    def __init__(self, model, device, config):\n        self.config = config\n        self.model = model\n        self.device = device\n        self.model.to(self.device)\n        model_params = list(self.model.named_parameters())\n        no_decay = ['LayerNorm.weight', 'LayerNorm.bias', 'Bias']\n        optimizer_grouped_parameters = [\n            {\n                'params': [param for name, param in model_params \n                           if any(nd in name for nd in no_decay) and 'classfier' not in name],\n                'lr': 1e-4,\n                'weight_decay':0.00\n            },\n            {\n                'params': [param for name, param in model_params \n                           if any(nd not in name for nd in no_decay) and 'classifier' not in name],\n                'lr': 1e-4,\n                'weight_decay': 0.001\n            },\n            {\n                'params': [param for name, param in model_params if 'classifier' in name],\n                'lr': 1e-3\n            }\n        ]\n        self.optimizer = optim.AdamW(optimizer_grouped_parameters, \n                                     lr=self.config.lr*xm.xrt_world_size())\n        scheduler_params = dict(mode='max',\n                                factor=0.8,\n                                patience=2,\n                                verbose=False, \n                                threshold=0.0001,\n                                threshold_mode='abs',\n                                cooldown=0, \n                                min_lr=1e-8,\n                                eps=1e-08\n                            )\n        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, \n                                                              **scheduler_params)\n        self.criterion = LabelSmoothing().to(self.device)\n        \n        self.epoch = 0\n        self.best_score = 0\n        self.best_loss = 10**5\n        \n        self.folder = 'TPU_SE_ResNext50_32x4d'\n        self.base_dir = f'./{self.folder}'\n        self.log_path = f'{self.base_dir}/log.txt'\n        time.sleep(1)\n        if not os.path.exists(self.base_dir):\n            os.makedirs(self.base_dir)\n        xm.master_print(f'Engine Prepared. Device is {self.device}')\n    \n    def train(self, train_loader):\n        tracker = xm.RateTracker()\n        self.model.train()\n        total_loss = AverageMeter()\n        total_score = RocAucMeter()\n        start_time = time.time()\n        for step, (images, labels) in enumerate(train_loader):\n            if self.config.verbose and step!=0:\n                if step%self.config.log_step==0:\n                    print(f'[xla:{xm.get_ordinal()}]({step}) \\\n                          Train Step={step}/{len(train_loader)} \\\n                          Rate={tracker.rate():.2f} \\\n                          GlobalRate={tracker.global_rate():.2f} \\\n                          Total Loss={total_loss.avg:.3f} \\\n                          RoC Auc Score={total_score.avg:.3f} \\\n                          Total Time={time.time()-start_time:.2f}secs', \n                          end='\\r', \n                          flush=True\n                         )\n            batch_size, _, _, _ = images.shape\n            images = torch.tensor(images, device=self.device, dtype=torch.float32)\n            targets = torch.tensor(labels, device=self.device, dtype=torch.float32)\n            self.optimizer.zero_grad()\n            logits = self.model(images)\n            loss = self.criterion(logits, targets)\n            loss.backward()\n            xm.optimizer_step(self.optimizer)\n            total_score.update(targets, logits)\n            total_loss.update(loss.detach().item(), batch_size)\n            if self.config.step_scheduler:\n                self.scheduler.step()\n        return total_loss, total_score\n    \n    def validation(self, val_loader):\n        tracker = xm.RateTracker()\n        self.model.eval()\n        total_loss = AverageMeter()\n        total_score = RocAucMeter()\n        start_time = time.time()\n        for step, (images, labels) in enumerate(val_loader):\n            if self.config.verbose and step!=0:\n                if step%self.config.log_step==0:\n                    print(f'[xla:{xm.get_ordinal()}]({step}) \\\n                          Validation Step={step}/{len(val_loader)} \\\n                          Rate={tracker.rate():.2f} \\\n                          GlobalRate={tracker.global_rate():.2f} \\\n                          Total Loss={total_loss.avg:.3f} \\\n                          RoC Auc Score={total_score.avg:.3f} \\\n                          Total Time={time.time()-start_time:.2f}secs', \n                          end='\\r', \n                          flush=True\n                         )\n            with torch.no_grad():\n                batch_size, _, _, _ = images.shape\n                images = torch.tensor(images, device=self.device, dtype=torch.float32)\n                targets = torch.tensor(labels, device=self.device, dtype=torch.float32)\n                logits = self.model(images)\n                loss = self.criterion(logits, targets)\n                total_loss.update(loss.detach().item(), batch_size)\n                total_score.update(targets, logits)\n        return total_loss, total_score\n    \n    def fit(self, train_loader, val_loader):\n        for n_epoch in range(self.config.n_epochs):\n            if self.config.verbose:\n                lr1, lr2 = self.optimizer.param_groups[0]['lr'], self.optimizer.param_groups[-1]['lr']\n                timestamp = datetime.utcnow().isoformat()\n                self.log(f'\\n{timestamp}\\nLR Backbone:{lr1} LR Head: {lr2}')\n            \n            tracker = xm.RateTracker()\n            start_time = time.time()\n            para_loader = pl.ParallelLoader(train_loader, [self.device])\n            total_loss, total_score = self.train(para_loader.per_device_loader(self.device))\n            self.log(\n                f'[TRAIN RESULT]: Epoch={self.epoch+1} \\\n                Rate={tracker.rate():.2f} \\\n                GlobalRate={tracker.global_rate():.2f} \\\n                Total Loss={total_loss.avg:.3f} \\\n                RoC Auc Score={total_score.avg:.3f} \\\n                Total Time={time.time()-start_time:.2f}secs')\n            \n            tracker = xm.RateTracker()\n            start_time = time.time()\n            para_loader = pl.ParallelLoader(val_loader, [self.device])\n            total_loss, total_score = self.validation(para_loader.per_device_loader(self.device))\n            self.log(\n                f'[VALIDATION RESULT]: Epoch={self.epoch+1} \\\n                Rate={tracker.rate():.2f} \\\n                GlobalRate={tracker.global_rate():.2f} \\\n                Total Loss={total_loss.avg:.3f} \\\n                RoC Auc Score={total_score.avg:.3f} \\\n                Total Time={time.time()-start_time:.2f}secs')\n            \n            if self.config.epoch_scheduler:\n                self.scheduler.step(metrics=total_score.avg)\n            \n            if n_epoch%20==0:\n                self.save(f'{self.base_dir}/checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n                \n            if self.config.metrics_debug:\n                xm.master_print(met.metrics_report(), flush=True)\n\n            self.epoch+=1\n            \n    def save(self, path):\n        self.model.eval()        \n        xm.save(self.model.state_dict(), path)\n\n    def log(self, message):\n        if self.config.verbose:\n            xm.master_print(message)\n        with open(self.log_path, 'a+') as logger:\n            xm.master_print(f'{message}\\n', logger)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Config:\n    lr = 1e-4\n    n_epochs = 5\n    batch_size = 32\n    num_workers = 4\n    step_scheduler = False\n    epoch_scheduler = True\n    verbose = True\n    log_step = 1\n    metrics_debug = True","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _mp_fn(rank, flags):\n    #xm.set_rng_state(SEED)\n    device = xm.xla_device()\n    \n    train_sampler = DistributedSamplerWrapper(\n        sampler=BalanceClassSampler(labels=train_dataset.get_labels(), mode=\"downsampling\"),\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=True\n    )\n    \n    train_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        batch_size=Config.batch_size,\n        sampler=train_sampler,\n        pin_memory=False,\n        drop_last=True,\n        num_workers=Config.num_workers,\n    )\n    \n    validation_sampler = torch.utils.data.distributed.DistributedSampler(\n        validation_dataset,\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=False\n    )\n    \n    validation_loader = torch.utils.data.DataLoader(\n        validation_dataset,\n        batch_size=Config.batch_size,\n        sampler=validation_sampler,\n        pin_memory=False,\n        drop_last=False,\n        num_workers=Config.num_workers\n    )\n    \n    engine = Engine(model=SE_ResNext50_32x4d(pretrained='imagenet'), device=device, config=Config)\n    if rank == 0:\n        time.sleep(1)\n    engine.fit(train_loader, validation_loader)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FLAGS={}\nxmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')","execution_count":15,"outputs":[{"output_type":"stream","text":"Engine Prepared. Device is xla:1\n\n2020-07-06T20:22:54.195706\nLR Backbone:0.0001 LR Head: 0.001\n[TRAIN RESULT]: Epoch=1                 Rate=0.00                 GlobalRate=0.00                 Total Loss=1.323                 RoC Auc Score=0.635                 Total Time=1582.83secs                RoC Auc Score=0.646                           Total Time=1580.40secs\n","name":"stdout"},{"output_type":"stream","text":"Exception in device=TPU:6: name 'train_loader' is not defined\nException in device=TPU:2: name 'train_loader' is not defined\nException in device=TPU:3: name 'train_loader' is not defined\nException in device=TPU:4: name 'train_loader' is not defined\nException in device=TPU:1: name 'train_loader' is not defined\nException in device=TPU:0: name 'train_loader' is not defined\nException in device=TPU:5: name 'train_loader' is not defined\nException in device=TPU:7: name 'train_loader' is not defined\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 231, in _start_fn\n    fn(gindex, *args)\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 231, in _start_fn\n    fn(gindex, *args)\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"<ipython-input-14-c8e8d77a8882>\", line 40, in _mp_fn\n    engine.fit(train_loader, validation_loader)\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 231, in _start_fn\n    fn(gindex, *args)\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 231, in _start_fn\n    fn(gindex, *args)\n  File \"<ipython-input-12-973b07933a13>\", line 140, in fit\n    total_loss, total_score = self.validation(para_loader.per_device_loader(self.device))\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 231, in _start_fn\n    fn(gindex, *args)\n  File \"<ipython-input-14-c8e8d77a8882>\", line 40, in _mp_fn\n    engine.fit(train_loader, validation_loader)\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 231, in _start_fn\n    fn(gindex, *args)\n  File \"<ipython-input-14-c8e8d77a8882>\", line 40, in _mp_fn\n    engine.fit(train_loader, validation_loader)\n  File \"<ipython-input-12-973b07933a13>\", line 104, in validation\n    Total Time={time.time()-start_time:.2f}secs',\n  File \"<ipython-input-12-973b07933a13>\", line 140, in fit\n    total_loss, total_score = self.validation(para_loader.per_device_loader(self.device))\n  File \"<ipython-input-14-c8e8d77a8882>\", line 40, in _mp_fn\n    engine.fit(train_loader, validation_loader)\nNameError: name 'train_loader' is not defined\n  File \"<ipython-input-12-973b07933a13>\", line 140, in fit\n    total_loss, total_score = self.validation(para_loader.per_device_loader(self.device))\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"<ipython-input-12-973b07933a13>\", line 104, in validation\n    Total Time={time.time()-start_time:.2f}secs',\n  File \"<ipython-input-12-973b07933a13>\", line 140, in fit\n    total_loss, total_score = self.validation(para_loader.per_device_loader(self.device))\n  File \"<ipython-input-12-973b07933a13>\", line 104, in validation\n    Total Time={time.time()-start_time:.2f}secs',\n  File \"<ipython-input-12-973b07933a13>\", line 104, in validation\n    Total Time={time.time()-start_time:.2f}secs',\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 231, in _start_fn\n    fn(gindex, *args)\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 231, in _start_fn\n    fn(gindex, *args)\nNameError: name 'train_loader' is not defined\n  File \"<ipython-input-14-c8e8d77a8882>\", line 40, in _mp_fn\n    engine.fit(train_loader, validation_loader)\n  File \"<ipython-input-14-c8e8d77a8882>\", line 40, in _mp_fn\n    engine.fit(train_loader, validation_loader)\nNameError: name 'train_loader' is not defined\n  File \"<ipython-input-12-973b07933a13>\", line 140, in fit\n    total_loss, total_score = self.validation(para_loader.per_device_loader(self.device))\n  File \"<ipython-input-14-c8e8d77a8882>\", line 40, in _mp_fn\n    engine.fit(train_loader, validation_loader)\n  File \"<ipython-input-14-c8e8d77a8882>\", line 40, in _mp_fn\n    engine.fit(train_loader, validation_loader)\nNameError: name 'train_loader' is not defined\n  File \"<ipython-input-12-973b07933a13>\", line 140, in fit\n    total_loss, total_score = self.validation(para_loader.per_device_loader(self.device))\n  File \"<ipython-input-12-973b07933a13>\", line 140, in fit\n    total_loss, total_score = self.validation(para_loader.per_device_loader(self.device))\n  File \"<ipython-input-12-973b07933a13>\", line 104, in validation\n    Total Time={time.time()-start_time:.2f}secs',\n  File \"<ipython-input-12-973b07933a13>\", line 140, in fit\n    total_loss, total_score = self.validation(para_loader.per_device_loader(self.device))\n  File \"<ipython-input-12-973b07933a13>\", line 104, in validation\n    Total Time={time.time()-start_time:.2f}secs',\n  File \"<ipython-input-12-973b07933a13>\", line 104, in validation\n    Total Time={time.time()-start_time:.2f}secs',\n  File \"<ipython-input-12-973b07933a13>\", line 104, in validation\n    Total Time={time.time()-start_time:.2f}secs',\nNameError: name 'train_loader' is not defined\nNameError: name 'train_loader' is not defined\nNameError: name 'train_loader' is not defined\nNameError: name 'train_loader' is not defined\n","name":"stderr"},{"output_type":"error","ename":"Exception","evalue":"process 2 terminated with exit code 17","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-2479bae6159a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_mp_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fork'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mdaemon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         start_method=start_method)\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 raise Exception(\n\u001b[1;32m    112\u001b[0m                     \u001b[0;34m\"process %d terminated with exit code %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;34m(\u001b[0m\u001b[0merror_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                 )\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: process 2 terminated with exit code 17"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}