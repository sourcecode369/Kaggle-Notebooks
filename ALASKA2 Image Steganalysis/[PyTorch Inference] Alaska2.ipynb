{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install efficientnet_pytorch","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%autosave 20\nimport os\nimport gc\ngc.enable()\nimport time\nfrom glob import glob\nimport random\nfrom datetime import datetime\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\nfrom PIL import Image\nfrom tqdm import tqdm \n\nimport torch\nimport torchvision\n# import pretrainedmodels\nimport efficientnet_pytorch\nfrom torchvision import transforms, models\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n# from torch.cuda import amp\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import BatchSampler, SequentialSampler\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom albumentations import (\n    Compose, HorizontalFlip, CLAHE, HueSaturationValue,\n    RandomBrightness, RandomContrast, RandomGamma, OneOf, Resize,\n    ToFloat, ShiftScaleRotate, GridDistortion, RandomRotate90, Cutout,\n    RGBShift, RandomBrightness, RandomContrast, Blur, MotionBlur, MedianBlur, GaussNoise, CoarseDropout,\n    IAAAdditiveGaussianNoise, GaussNoise, OpticalDistortion, RandomSizedCrop, VerticalFlip\n)\nfrom catalyst.data.sampler import DistributedSamplerWrapper, BalanceClassSampler\n# from apex import amp\n\nimport sklearn\nfrom sklearn import metrics\nfrom sklearn.model_selection import GroupKFold\n\nimport warnings\nwarnings.simplefilter('ignore')\nwarnings.filterwarnings(\"ignore\")\n\nprint(torch.__version__)\nprint(\"\\nCUDNN VERSION: {}\\n\".format(torch.backends.cudnn.version()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fix_seed(seed=2020):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nfix_seed()\nprint('Seeding Completed.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class EfficientNetB2(nn.Module):\n    def __init__(self, pretrained=None):\n        super(EfficientNetB2, self).__init__()\n        self.model = efficientnet_pytorch.EfficientNet.from_name('efficientnet-b2')\n        if pretrained is not None:\n            self.model.load_state_dict(\n                torch.load('../input/efficientnet-pytorch/efficientnet-b2-27687264.pth')\n            )\n        self.dropout = nn.Dropout(p=0.1)\n        self.classifier = nn.Linear(in_features=1408, out_features=4)\n    \n    def forward(self, images):\n        batch_size, _, _, _ = images.shape\n        features = self.model.extract_features(images)\n        avg_pool = F.adaptive_avg_pool2d(features, 1).reshape(batch_size, -1)\n        \n        # Multi Sample Dropout\n#         logits = torch.mean(\n#             torch.stack(\n#                 [self.classifier(self.dropout(avg_pool)) for _ in range(5)],\n#                 dim=0,\n#             ),\n#             dim=0,\n#         )\n        logits = self.classifier(avg_pool)\n        return logits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = EfficientNetB2(pretrained=None)\nnet = nn.DataParallel(net)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = torch.load('../input/alaska-2-checkpoints/best-checkpoint-001epoch.bin')\nnet.load_state_dict(checkpoint['model_state_dict']);\nnet.eval();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUGMENTATIONS_TEST = Compose([\n    ToFloat(max_value=255),\n    ToTensorV2()\n], p=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Alaska2TestDataset(Dataset):\n\n    def __init__(self, df, augmentations=None):\n\n        self.data = df\n        self.augment = augmentations\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        fn = self.data.loc[idx][0]\n        im = cv2.imread(fn)[:, :, ::-1]\n\n        if self.augment:\n            # Apply transformations\n            im = self.augment(image=im)\n\n        return im\n\n\ntest_filenames = sorted(glob(f\"../input/alaska2-image-steganalysis/Test/*.jpg\"))\ntest_df = pd.DataFrame({'ImageFileName': list(\n    test_filenames)}, columns=['ImageFileName'])\n\nbatch_size = 16\nnum_workers = 4\ntest_dataset = Alaska2TestDataset(test_df, augmentations=AUGMENTATIONS_TEST)\ntest_loader = torch.utils.data.DataLoader(test_dataset,\n                                          batch_size=batch_size,\n                                          num_workers=num_workers,\n                                          shuffle=False,\n                                          drop_last=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\ntk0 = tqdm(test_loader)\nwith torch.no_grad():\n    for i, im in enumerate(tk0):\n        inputs = im[\"image\"].cuda()\n        # flip vertical\n        im = inputs.flip(2)\n        outputs = net(im)\n        # fliplr\n        im = inputs.flip(3)\n        outputs = (0.25*outputs + 0.25*net(im))\n        outputs = (outputs + 0.5*net(inputs))        \n        preds.extend(F.softmax(outputs, 1).cpu().numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = np.array(preds)\nlabels = preds.argmax(1)\nnew_preds = np.zeros((len(preds),))\nnew_preds[labels != 0] = preds[labels != 0, 1:].sum(1)\nnew_preds[labels == 0] = 1 - preds[labels == 0, 0]\n\ntest_df['Id'] = test_df['ImageFileName'].apply(lambda x: x.split(os.sep)[-1])\ntest_df['Label'] = new_preds\n\ntest_df = test_df.drop('ImageFileName', axis=1)\ntest_df.to_csv('submission_eb0.csv', index=False)\nprint(test_df.head())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}