{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install pretrainedmodels\n# !pip install torchtoolbox\n# !pip install torchviz\n# !pip install efficientnet_pytorch\n!git clone https://github.com/4uiiurz1/pytorch-auto-augment > /dev/null\n\nVERSION = \"20200516\"  #@param [\"1.5\" , \"20200516\", \"nightly\"]\n!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --version $VERSION --apt-packages libomp5 libopenblas-dev","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Importing Dependencies"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%autosave 30\nimport os\nos.environ['XLA_USE_BF16'] = \"1\"\nimport sys\nsys.path.insert(0, './pytorch-auto-augment')\nimport gc\ngc.enable()\nimport time\nimport glob\nimport random\nfrom datetime import datetime\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom skimage import io\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport tqdm as tqdm\nfrom PIL import Image\n\nimport torch\nimport torchvision\nfrom torchvision import transforms, models\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import SequentialSampler, BatchSampler, RandomSampler\n\nimport torch_xla\nimport torch_xla.core.xla_model as xm\nimport torch_xla.debug.metrics as met\nimport torch_xla.distributed.data_parallel as dp\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.distributed.xla_multiprocessing as xmp\nimport torch_xla.utils.utils as xu\n\n# from torchviz import make_dot\nimport albumentations as A\nfrom auto_augment import AutoAugment, Cutout\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom catalyst.data.sampler import DistributedSamplerWrapper, BalanceClassSampler\nimport pretrainedmodels\n# from efficientnet_pytorch import EfficientNet\n\nimport sklearn\nfrom sklearn import metrics\nfrom sklearn.model_selection import GroupKFold\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Configuration"},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nSEED = 2020\nseed_everything(SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = []\n\nfor label, kind in enumerate(['Cover', 'JMiPOD', 'JUNIWARD', 'UERD']):\n    for path in glob.glob('../input/alaska2-image-steganalysis/Cover/*.jpg'):\n        dataset.append({\n            'kind': kind,\n            'image_name': path.split('/')[-1],\n            'label': label\n        })\n        \nrandom.shuffle(dataset)\ndataset = pd.DataFrame(dataset)\ngkf = GroupKFold(n_splits=5)\ndataset.loc[:, 'fold'] = 0\nfor fold_number, (train_index, val_index) in enumerate(gkf.split(X=dataset.index, y=dataset['label'], groups=dataset['image_name'])):\n    dataset.loc[dataset.iloc[val_index].index, 'fold'] = fold_number","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Augmentations"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_train_transforms():\n    return transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        # AutoAugment(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n    ])\n\ndef get_valid_transforms():\n    return transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n    ])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"def one_hot(size, target):\n    vec = torch.zeros(size, dtype=torch.float32)\n    vec[target] = 1.\n    return vec\n\nDATA_ROOT_PATH = '/kaggle/input/alaska2-image-steganalysis/'\n\nclass AlaskaDataset(Dataset):\n    def __init__(self, kinds, image_names, labels, transforms=None):\n        super().__init__()\n        self.kinds = kinds\n        self.image_names = image_names\n        self.labels = labels\n        self.transforms = transforms\n\n    def __getitem__(self, index: int):\n        kind, image_name, label = self.kinds[index], self.image_names[index], self.labels[index]\n        image = cv2.imread(f'{DATA_ROOT_PATH}/{kind}/{image_name}', cv2.IMREAD_COLOR)\n        image = cv2.resize(image, (331, 331), cv2.INTER_AREA)\n        if self.transforms:\n            image = self.transforms(image)\n        target = one_hot(4, label)\n        return image, target\n\n    def __len__(self) -> int:\n        return self.image_names.shape[0]\n    \n    def get_labels(self):\n        return list(self.labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loader"},{"metadata":{"trusted":true},"cell_type":"code","source":"fold_number = 0\nSERIAL_EXEC = xmp.MpSerialExecutor()\n\ntrain_dataset = AlaskaDataset(\n    kinds=dataset[dataset['fold'] != fold_number].kind.values,\n    image_names=dataset[dataset['fold'] != fold_number].image_name.values,\n    labels=dataset[dataset['fold'] != fold_number].label.values,\n    transforms=get_train_transforms(),\n)\n\nvalidation_dataset = AlaskaDataset(\n    kinds=dataset[dataset['fold'] == fold_number].kind.values,\n    image_names=dataset[dataset['fold'] == fold_number].image_name.values,\n    labels=dataset[dataset['fold'] == fold_number].label.values,\n    transforms=get_valid_transforms(),\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SE_ResNext50_32x4d(nn.Module):\n    def __init__(self, pretrained=None):\n        super(SE_ResNext50_32x4d, self).__init__()\n        self.model = pretrainedmodels.__dict__['se_resnext50_32x4d'](pretrained=None)\n        if pretrained is not None:\n            # https://www.kaggle.com/abhishek/pretrained-model-weights-pytorch - Download\n            self.model.load_state_dict(\n                torch.load('../input/pretrained-model-weights-pytorch/se_resnext50_32x4d-a260b3a4.pth')\n            )\n        self.dropout = nn.Dropout(p=0.1)\n        self.high_dropout = nn.Dropout(p=0.5)\n        self.classifier = nn.Linear(in_features=2048, out_features=4)\n    \n    def forward(self, images):\n        batch_size, _, _, _ = images.shape\n        features = self.model.features(images)\n        avg_pool = F.adaptive_avg_pool2d(features, 1).reshape(batch_size, -1)\n        logits = torch.mean(\n            torch.stack(\n                [self.classifier(self.dropout(avg_pool)) for _ in range(5)],\n                dim=0,\n            ),\n            dim=0,\n        )\n        return logits","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def alaska_weighted_auc(y_true, y_valid):\n    tpr_thresholds = [0.0, 0.4, 1.0]\n    weights = [2, 1]\n    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_valid, pos_label=1)\n    areas = np.array(tpr_thresholds[1:]) - np.array(tpr_thresholds[:-1])\n    normalization = np.dot(areas, weights)\n    competition_metric = 0\n    for idx, weight in enumerate(weights):\n        y_min = tpr_thresholds[idx]\n        y_max = tpr_thresholds[idx + 1]\n        mask = (y_min < tpr) & (tpr < y_max)\n        x_padding = np.linspace(fpr[mask][-1], 1, 100)\n        x = np.concatenate([fpr[mask], x_padding])\n        y = np.concatenate([tpr[mask], [y_max] * len(x_padding)])\n        y = y - y_min \n        score = metrics.auc(x, y)\n        submetric = score * weight\n        best_subscore = (y_max - y_min) * weight\n        competition_metric += submetric\n    return competition_metric / normalization\n        \nclass RocAucMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.y_true = np.array([0,1])\n        self.y_pred = np.array([0.5,0.5])\n        self.score = 0\n\n    def update(self, y_true, y_pred):\n        y_true = y_true.cpu().numpy().argmax(axis=1).clip(min=0, max=1).astype(int)\n        y_pred = 1 - nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,0]\n        self.y_true = np.hstack((self.y_true, y_true))\n        self.y_pred = np.hstack((self.y_pred, y_pred))\n        self.score = alaska_weighted_auc(self.y_true, self.y_pred)\n    \n    @property\n    def avg(self):\n        return self.score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"class LabelSmoothing(nn.Module):\n    def __init__(self, smoothing = 0.05):\n        super(LabelSmoothing, self).__init__()\n        self.confidence = 1.0 - smoothing\n        self.smoothing = smoothing\n\n    def forward(self, x, target):\n        if self.training:\n            x = x.float()\n            target = target.float()\n            logprobs = torch.nn.functional.log_softmax(x, dim = -1)\n            nll_loss = -logprobs * target\n            nll_loss = nll_loss.sum(-1)\n            smooth_loss = -logprobs.mean(dim=-1)\n            loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n            return loss.mean()\n        else:\n            return torch.nn.functional.cross_entropy(x, target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Engine"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Engine:\n    \n    def __init__(self, model, device, config):\n        self.config = config\n        self.model = model\n        self.device = device\n        self.model.to(self.device)\n        model_params = list(self.model.named_parameters())\n        no_decay = ['LayerNorm.weight', 'LayerNorm.bias', 'Bias']\n        optimizer_grouped_parameters = [\n            {\n                'params': [param for name, param in model_params \n                           if any(nd in name for nd in no_decay) and 'classfier' not in name],\n                'lr': 1e-4,\n                'weight_decay':0.00\n            },\n            {\n                'params': [param for name, param in model_params \n                           if any(nd not in name for nd in no_decay) and 'classifier' not in name],\n                'lr': 1e-4,\n                'weight_decay': 0.001\n            },\n            {\n                'params': [param for name, param in model_params if 'classifier' in name],\n                'lr': 1e-3\n            }\n        ]\n        self.optimizer = optim.AdamW(optimizer_grouped_parameters, \n                                     lr=self.config.lr*xm.xrt_world_size())\n        scheduler_params = dict(mode='max',\n                                factor=0.8,\n                                patience=2,\n                                verbose=False, \n                                threshold=0.0001,\n                                threshold_mode='abs',\n                                cooldown=0, \n                                min_lr=1e-8,\n                                eps=1e-08\n                            )\n        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, \n                                                              **scheduler_params)\n        self.criterion = LabelSmoothing().to(self.device)\n        \n        self.epoch = 0\n        self.best_score = 0\n        self.best_loss = 10**5\n        \n        self.folder = 'TPU_SE_ResNext50_32x4d'\n        self.base_dir = f'./{self.folder}'\n        self.log_path = f'{self.base_dir}/log.txt'\n        time.sleep(1)\n        if not os.path.exists(self.base_dir):\n            os.makedirs(self.base_dir)\n        xm.master_print(f'Engine Prepared. Device is {self.device}')\n    \n    def train(self, train_loader):\n        tracker = xm.RateTracker()\n        self.model.train()\n        total_loss = AverageMeter()\n        total_score = RocAucMeter()\n        start_time = time.time()\n        for step, (images, labels) in enumerate(train_loader):\n            if self.config.verbose and step!=0:\n                if step%self.config.log_step==0:\n                    print(f'[xla:{xm.get_ordinal()}]({step}) \\\n                          Train Step={step}/{len(train_loader)} \\\n                          Rate={tracker.rate():.2f} \\\n                          GlobalRate={tracker.global_rate():.2f} \\\n                          Total Loss={total_loss.avg:.3f} \\\n                          RoC Auc Score={total_score.avg:.3f} \\\n                          Total Time={time.time()-start_time:.2f}secs', \n                          end='\\r', \n                          flush=True\n                         )\n            batch_size, _, _, _ = images.shape\n            images = torch.tensor(images, device=self.device, dtype=torch.float32)\n            targets = torch.tensor(labels, device=self.device, dtype=torch.float32)\n            self.optimizer.zero_grad()\n            logits = self.model(images)\n            loss = self.criterion(logits, targets)\n            loss.backward()\n            xm.optimizer_step(self.optimizer)\n            total_score.update(targets, logits)\n            total_loss.update(loss.detach().item(), batch_size)\n            if self.config.step_scheduler:\n                self.scheduler.step()\n        return total_loss, total_score\n    \n    def validation(self, val_loader):\n        tracker = xm.RateTracker()\n        self.model.eval()\n        total_loss = AverageMeter()\n        total_score = RocAucMeter()\n        start_time = time.time()\n        for step, (images, labels) in enumerate(val_loader):\n            if self.config.verbose and step!=0:\n                if step%self.config.log_step==0:\n                    print(f'[xla:{xm.get_ordinal()}]({step}) \\\n                          Validation Step={step}/{len(train_loader)} \\\n                          Rate={tracker.rate():.2f} \\\n                          GlobalRate={tracker.global_rate():.2f} \\\n                          Total Loss={total_loss.avg:.3f} \\\n                          RoC Auc Score={total_score.avg:.3f} \\\n                          Total Time={time.time()-start_time:.2f}secs', \n                          end='\\r', \n                          flush=True\n                         )\n            with torch.no_grad():\n                batch_size, _, _, _ = images.shape\n                images = torch.tensor(images, device=self.device, dtype=torch.float32)\n                targets = torch.tensor(labels, device=self.device, dtype=torch.float32)\n                logits = self.model(images)\n                loss = self.criterion(logits, targets)\n                total_loss.update(loss.detach().item(), batch_size)\n                total_score.update(targets, logits)\n        return total_loss, total_score\n    \n    def fit(self, train_loader, val_loader):\n        for n_epoch in range(self.config.n_epochs):\n            if self.config.verbose:\n                lr1, lr2 = self.optimizer.param_groups[0]['lr'], self.optimizer.param_groups[-1]['lr']\n                timestamp = datetime.utcnow().isoformat()\n                self.log(f'\\n{timestamp}\\nLR Backbone:{lr1} LR Head: {lr2}')\n            \n            tracker = xm.RateTracker()\n            start_time = time.time()\n            para_loader = pl.ParallelLoader(train_loader, [self.device])\n            total_loss, total_score = self.train(para_loader.per_device_loader(self.device))\n            self.log(\n                f'[TRAIN RESULT]: Epoch={self.epoch+1} \\\n                Rate={tracker.rate():.2f} \\\n                GlobalRate={tracker.global_rate():.2f} \\\n                Total Loss={total_loss.avg:.3f} \\\n                RoC Auc Score={total_score.avg:.3f} \\\n                Total Time={time.time()-start_time:.2f}secs')\n            \n            tracker = xm.RateTracker()\n            start_time = time.time()\n            para_loader = pl.ParallelLoader(val_loader, [self.device])\n            total_loss, total_score = self.validation(para_loader.per_device_loader(self.device))\n            self.log(\n                f'[VALIDATION RESULT]: Epoch={self.epoch+1} \\\n                Rate={tracker.rate():.2f} \\\n                GlobalRate={tracker.global_rate():.2f} \\\n                Total Loss={total_loss.avg:.3f} \\\n                RoC Auc Score={total_score.avg:.3f} \\\n                Total Time={time.time()-start_time:.2f}secs')\n            \n            if self.config.epoch_scheduler:\n                self.scheduler.step(metrics=total_score.avg)\n            \n            if n_epoch%20==0:\n                self.save(f'{self.base_dir}/checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n                \n            if self.config.metrics_debug:\n                xm.master_print(met.metrics_report(), flush=True)\n\n            self.epoch+=1\n            \n    def save(self, path):\n        self.model.eval()        \n        xm.save(self.model.state_dict(), path)\n\n    def log(self, message):\n        if self.config.verbose:\n            xm.master_print(message)\n        with open(self.log_path, 'a+') as logger:\n            xm.master_print(f'{message}\\n', logger)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Config:\n    lr = 1e-4\n    n_epochs = 5\n    batch_size = 32\n    num_workers = 4\n    step_scheduler = False\n    epoch_scheduler = True\n    verbose = True\n    log_step = 1\n    metrics_debug = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _mp_fn(rank, flags):\n    #xm.set_rng_state(SEED)\n    device = xm.xla_device()\n    \n    train_sampler = DistributedSamplerWrapper(\n        sampler=BalanceClassSampler(labels=train_dataset.get_labels(), mode=\"downsampling\"),\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=True\n    )\n    \n    train_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        batch_size=Config.batch_size,\n        sampler=train_sampler,\n        pin_memory=False,\n        drop_last=True,\n        num_workers=Config.num_workers,\n    )\n    \n    validation_sampler = torch.utils.data.distributed.DistributedSampler(\n        validation_dataset,\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=False\n    )\n    \n    validation_loader = torch.utils.data.DataLoader(\n        validation_dataset,\n        batch_size=Config.batch_size,\n        sampler=validation_sampler,\n        pin_memory=False,\n        drop_last=False,\n        num_workers=Config.num_workers\n    )\n    \n    engine = Engine(model=SE_ResNext50_32x4d(pretrained='imagenet'), device=device, config=Config)\n    if rank == 0:\n        time.sleep(1)\n    engine.fit(train_loader, validation_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FLAGS={}\nxmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}