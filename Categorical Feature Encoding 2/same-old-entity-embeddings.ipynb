{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics, preprocessing\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    def fallback_auc(y_true, y_pred):\n",
    "        try:\n",
    "            return metrics.roc_auc_score(y_true, y_pred)\n",
    "        except:\n",
    "            return 0.5\n",
    "    return tf.py_function(fallback_auc, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(data, catcols):    \n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for c in catcols:\n",
    "        num_unique_values = int(data[c].nunique())\n",
    "        embed_dim = int(min(np.ceil((num_unique_values)/2), 50))\n",
    "        inp = layers.Input(shape=(1,))\n",
    "        out = layers.Embedding(num_unique_values + 1, embed_dim, name=c)(inp)\n",
    "        out = layers.SpatialDropout1D(0.3)(out)\n",
    "        out = layers.Reshape(target_shape=(embed_dim, ))(out)\n",
    "        inputs.append(inp)\n",
    "        outputs.append(out)\n",
    "    \n",
    "    x = layers.Concatenate()(outputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Dense(300, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Dense(300, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    y = layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/cat-in-the-dat-ii/train.csv\")\n",
    "test = pd.read_csv(\"../input/cat-in-the-dat-ii/test.csv\")\n",
    "sample = pd.read_csv(\"../input/cat-in-the-dat-ii/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"target\"] = -1\n",
    "data = pd.concat([train, test]).reset_index(drop=True)\n",
    "\n",
    "features = [x for x in train.columns if x not in [\"id\", \"target\"]]\n",
    "\n",
    "for feat in features:\n",
    "    lbl_enc = preprocessing.LabelEncoder()\n",
    "    data[feat] = lbl_enc.fit_transform(data[feat].fillna(\"-1\").astype(str).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data.target != -1].reset_index(drop=True)\n",
    "test = data[data.target == -1].reset_index(drop=True)\n",
    "test_data = [test.loc[:, features].values[:, k] for k in range(test.loc[:, features].values.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 20s 35us/sample - loss: 0.4687 - auc: 0.7009 - val_loss: 0.4168 - val_auc: 0.7755\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 13s 23us/sample - loss: 0.4086 - auc: 0.7700 - val_loss: 0.4026 - val_auc: 0.7795\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.4033 - auc: 0.7780 - val_loss: 0.4053 - val_auc: 0.7794\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.4006 - auc: 0.7822 - val_loss: 0.4019 - val_auc: 0.7796\n",
      "Epoch 5/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.3982 - auc: 0.7856\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 14s 25us/sample - loss: 0.3982 - auc: 0.7857 - val_loss: 0.4056 - val_auc: 0.7782\n",
      "Epoch 6/100\n",
      "587999/587999 [==============================] - 14s 23us/sample - loss: 0.3935 - auc: 0.7925 - val_loss: 0.4045 - val_auc: 0.7769\n",
      "Epoch 7/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.3907 - auc: 0.7965Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.3907 - auc: 0.7966 - val_loss: 0.4099 - val_auc: 0.7757\n",
      "Epoch 00007: early stopping\n",
      "0.7793393948635317\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 20s 33us/sample - loss: 0.4690 - auc: 0.7009 - val_loss: 0.4042 - val_auc: 0.7910\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 13s 23us/sample - loss: 0.4088 - auc: 0.7691 - val_loss: 0.3924 - val_auc: 0.7948\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.4033 - auc: 0.7782 - val_loss: 0.3927 - val_auc: 0.7959\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.4005 - auc: 0.7826 - val_loss: 0.3950 - val_auc: 0.7934\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 15s 25us/sample - loss: 0.3986 - auc: 0.7854 - val_loss: 0.3948 - val_auc: 0.7929\n",
      "Epoch 6/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.3966 - auc: 0.7884\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 14s 23us/sample - loss: 0.3966 - auc: 0.7885 - val_loss: 0.3974 - val_auc: 0.7935\n",
      "Epoch 7/100\n",
      "587999/587999 [==============================] - 14s 23us/sample - loss: 0.3903 - auc: 0.7969 - val_loss: 0.3969 - val_auc: 0.7919\n",
      "Epoch 8/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.3868 - auc: 0.8023Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.3868 - auc: 0.8022 - val_loss: 0.4007 - val_auc: 0.7879\n",
      "Epoch 00008: early stopping\n",
      "0.7961669257777828\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 19s 33us/sample - loss: 0.4674 - auc: 0.7023 - val_loss: 0.4041 - val_auc: 0.7871\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.4084 - auc: 0.7699 - val_loss: 0.3955 - val_auc: 0.7915\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 15s 25us/sample - loss: 0.4033 - auc: 0.7783 - val_loss: 0.3949 - val_auc: 0.7924\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.4010 - auc: 0.7819 - val_loss: 0.3944 - val_auc: 0.7939\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.3991 - auc: 0.7846 - val_loss: 0.3949 - val_auc: 0.7921\n",
      "Epoch 6/100\n",
      "587999/587999 [==============================] - 14s 23us/sample - loss: 0.3965 - auc: 0.7882 - val_loss: 0.3958 - val_auc: 0.7916\n",
      "Epoch 7/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.3940 - auc: 0.7921\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 15s 25us/sample - loss: 0.3941 - auc: 0.7920 - val_loss: 0.3992 - val_auc: 0.7892\n",
      "Epoch 8/100\n",
      "587999/587999 [==============================] - 14s 25us/sample - loss: 0.3859 - auc: 0.8035 - val_loss: 0.4012 - val_auc: 0.7835\n",
      "Epoch 9/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.3810 - auc: 0.8102Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.3810 - auc: 0.8102 - val_loss: 0.4050 - val_auc: 0.7795\n",
      "Epoch 00009: early stopping\n",
      "0.7927274869214816\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 21s 35us/sample - loss: 0.4701 - auc: 0.6997 - val_loss: 0.4108 - val_auc: 0.7749\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.4085 - auc: 0.7697 - val_loss: 0.4030 - val_auc: 0.7789\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 15s 25us/sample - loss: 0.4031 - auc: 0.7784 - val_loss: 0.4028 - val_auc: 0.7795\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.4004 - auc: 0.7825 - val_loss: 0.4039 - val_auc: 0.7772\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 15s 25us/sample - loss: 0.3986 - auc: 0.7852 - val_loss: 0.4067 - val_auc: 0.7774\n",
      "Epoch 6/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.3965 - auc: 0.7883\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.3965 - auc: 0.7883 - val_loss: 0.4052 - val_auc: 0.7769\n",
      "Epoch 7/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.3906 - auc: 0.7968Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.3905 - auc: 0.7969 - val_loss: 0.4084 - val_auc: 0.7731\n",
      "Epoch 00007: early stopping\n",
      "0.7774859907074058\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 20s 35us/sample - loss: 0.4677 - auc: 0.7020 - val_loss: 0.4117 - val_auc: 0.7733\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.4085 - auc: 0.7698 - val_loss: 0.4021 - val_auc: 0.7793\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.4034 - auc: 0.7782 - val_loss: 0.4028 - val_auc: 0.7788\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 14s 23us/sample - loss: 0.4006 - auc: 0.7822 - val_loss: 0.4034 - val_auc: 0.7774\n",
      "Epoch 5/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.3986 - auc: 0.7852\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 15s 25us/sample - loss: 0.3986 - auc: 0.7854 - val_loss: 0.4034 - val_auc: 0.7766\n",
      "Epoch 6/100\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.3937 - auc: 0.7921 - val_loss: 0.4054 - val_auc: 0.7735\n",
      "Epoch 7/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.3915 - auc: 0.7951Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 14s 23us/sample - loss: 0.3916 - auc: 0.7951 - val_loss: 0.4080 - val_auc: 0.7706\n",
      "Epoch 00007: early stopping\n",
      "0.7799385123253213\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 20s 34us/sample - loss: 0.4700 - auc: 0.7002 - val_loss: 0.4077 - val_auc: 0.7794\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 14s 23us/sample - loss: 0.4087 - auc: 0.7693 - val_loss: 0.3984 - val_auc: 0.7836\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.4033 - auc: 0.7780 - val_loss: 0.3989 - val_auc: 0.7840\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 14s 23us/sample - loss: 0.4007 - auc: 0.7821 - val_loss: 0.3986 - val_auc: 0.7835\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 15s 26us/sample - loss: 0.3985 - auc: 0.7853 - val_loss: 0.4012 - val_auc: 0.7818\n",
      "Epoch 6/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.3966 - auc: 0.7877\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.3966 - auc: 0.7877 - val_loss: 0.4019 - val_auc: 0.7799\n",
      "Epoch 7/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.3905 - auc: 0.7967Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.3905 - auc: 0.7968 - val_loss: 0.4048 - val_auc: 0.7769\n",
      "Epoch 00007: early stopping\n",
      "0.785014699388673\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 20s 34us/sample - loss: 0.4700 - auc: 0.6991 - val_loss: 0.4130 - val_auc: 0.7766\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.4087 - auc: 0.7693 - val_loss: 0.4008 - val_auc: 0.7810\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.4032 - auc: 0.7784 - val_loss: 0.4000 - val_auc: 0.7815\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 15s 25us/sample - loss: 0.4009 - auc: 0.7823 - val_loss: 0.4012 - val_auc: 0.7799\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 15s 25us/sample - loss: 0.3987 - auc: 0.7850 - val_loss: 0.4036 - val_auc: 0.7768\n",
      "Epoch 6/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.3964 - auc: 0.7885\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.3964 - auc: 0.7885 - val_loss: 0.4044 - val_auc: 0.7763\n",
      "Epoch 7/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.3904 - auc: 0.7969Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.3904 - auc: 0.7969 - val_loss: 0.4060 - val_auc: 0.7733\n",
      "Epoch 00007: early stopping\n",
      "0.7800401446569134\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 20s 34us/sample - loss: 0.4709 - auc: 0.6973 - val_loss: 0.4101 - val_auc: 0.7807\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 14s 23us/sample - loss: 0.4083 - auc: 0.7699 - val_loss: 0.3980 - val_auc: 0.7879\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.4032 - auc: 0.7785 - val_loss: 0.3972 - val_auc: 0.7886\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 15s 26us/sample - loss: 0.4005 - auc: 0.7825 - val_loss: 0.3977 - val_auc: 0.7874\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.3987 - auc: 0.7851 - val_loss: 0.3987 - val_auc: 0.7874\n",
      "Epoch 6/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.3965 - auc: 0.7883\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.3965 - auc: 0.7882 - val_loss: 0.3979 - val_auc: 0.7877\n",
      "Epoch 7/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.3904 - auc: 0.7970Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.3903 - auc: 0.7970 - val_loss: 0.4000 - val_auc: 0.7841\n",
      "Epoch 00007: early stopping\n",
      "0.7865422641301791\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "421888/587999 [====================>.........] - ETA: 5s - loss: 0.4933 - auc: 0.67670.7888652758162318\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 21s 35us/sample - loss: 0.4702 - auc: 0.6971 - val_loss: 0.4092 - val_auc: 0.7583\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.4088 - auc: 0.7691 - val_loss: 0.3988 - val_auc: 0.7637\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.4032 - auc: 0.7783 - val_loss: 0.3970 - val_auc: 0.7658\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 15s 26us/sample - loss: 0.4010 - auc: 0.7820 - val_loss: 0.3982 - val_auc: 0.7653\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 16s 28us/sample - loss: 0.3989 - auc: 0.7848 - val_loss: 0.3992 - val_auc: 0.7628\n",
      "Epoch 6/100\n",
      "586752/587999 [============================>.] - ETA: 0s - loss: 0.3966 - auc: 0.7882\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 15s 26us/sample - loss: 0.3966 - auc: 0.7882 - val_loss: 0.3994 - val_auc: 0.7632\n",
      "Epoch 7/100\n",
      "587999/587999 [==============================] - 15s 26us/sample - loss: 0.3904 - auc: 0.7971 - val_loss: 0.4023 - val_auc: 0.7608\n",
      "Epoch 8/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.3865 - auc: 0.8026Restoring model weights from the end of the best epoch.\n",
      "587999/587999 [==============================] - 15s 26us/sample - loss: 0.3865 - auc: 0.8026 - val_loss: 0.4058 - val_auc: 0.7573\n",
      "Epoch 00008: early stopping\n",
      "0.788034377324369\n",
      "Train on 587999 samples, validate on 12001 samples\n",
      "Epoch 1/100\n",
      "587999/587999 [==============================] - 21s 35us/sample - loss: 0.4697 - auc: 0.6993 - val_loss: 0.4089 - val_auc: 0.7620\n",
      "Epoch 2/100\n",
      "587999/587999 [==============================] - 15s 25us/sample - loss: 0.4082 - auc: 0.7702 - val_loss: 0.3973 - val_auc: 0.7635\n",
      "Epoch 3/100\n",
      "587999/587999 [==============================] - 15s 26us/sample - loss: 0.4035 - auc: 0.7780 - val_loss: 0.3958 - val_auc: 0.7660\n",
      "Epoch 4/100\n",
      "587999/587999 [==============================] - 15s 25us/sample - loss: 0.4008 - auc: 0.7819 - val_loss: 0.3970 - val_auc: 0.7646\n",
      "Epoch 5/100\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.3986 - auc: 0.7853 - val_loss: 0.3981 - val_auc: 0.7641\n",
      "Epoch 6/100\n",
      "587776/587999 [============================>.] - ETA: 0s - loss: 0.3967 - auc: 0.7878\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "587999/587999 [==============================] - 14s 24us/sample - loss: 0.3967 - auc: 0.7879 - val_loss: 0.3991 - val_auc: 0.7627\n",
      "Epoch 7/100\n",
      "586752/588000 [============================>.] - ETA: 0s - loss: 0.3940 - auc: 0.7922Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588000/588000 [==============================] - 14s 23us/sample - loss: 0.3940 - auc: 0.7922 - val_loss: 0.4009 - val_auc: 0.7544\n",
      "Epoch 00007: early stopping\n",
      "0.7852061195160522\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "588000/588000 [==============================] - 19s 33us/sample - loss: 0.4716 - auc: 0.6971 - val_loss: 0.4059 - val_auc: 0.7401\n",
      "Epoch 2/100\n",
      "588000/588000 [==============================] - 14s 23us/sample - loss: 0.4084 - auc: 0.7700 - val_loss: 0.3951 - val_auc: 0.7434\n",
      "Epoch 3/100\n",
      "588000/588000 [==============================] - 15s 25us/sample - loss: 0.4008 - auc: 0.7819 - val_loss: 0.3985 - val_auc: 0.7573\n",
      "Epoch 5/100\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3987 - auc: 0.7851\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588000/588000 [==============================] - 14s 23us/sample - loss: 0.3987 - auc: 0.7852 - val_loss: 0.3991 - val_auc: 0.7587\n",
      "Epoch 6/100\n",
      "588000/588000 [==============================] - 14s 24us/sample - loss: 0.3931 - auc: 0.7927 - val_loss: 0.4023 - val_auc: 0.7551\n",
      "Epoch 7/100\n",
      "588001/588001 [==============================] - 18s 31us/sample - loss: 0.4695 - auc: 0.6995 - val_loss: 0.4078 - val_auc: 0.7652\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 15s 25us/sample - loss: 0.4083 - auc: 0.7704 - val_loss: 0.4001 - val_auc: 0.7683\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 14s 23us/sample - loss: 0.4030 - auc: 0.7788 - val_loss: 0.3990 - val_auc: 0.7701\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 14s 23us/sample - loss: 0.4007 - auc: 0.7822 - val_loss: 0.3995 - val_auc: 0.7688\n",
      "Epoch 5/100\n",
      "588001/588001 [==============================] - 13s 23us/sample - loss: 0.3988 - auc: 0.7850 - val_loss: 0.3999 - val_auc: 0.7691\n",
      "Epoch 6/100\n",
      "586752/588001 [============================>.] - ETA: 0s - loss: 0.3966 - auc: 0.7881\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588001/588001 [==============================] - 14s 24us/sample - loss: 0.3967 - auc: 0.7880 - val_loss: 0.4028 - val_auc: 0.7660\n",
      "Epoch 7/100\n",
      "588001/588001 [==============================] - 14s 24us/sample - loss: 0.3908 - auc: 0.7965 - val_loss: 0.4024 - val_auc: 0.7642\n",
      "Epoch 8/100\n",
      "586752/588001 [============================>.] - ETA: 0s - loss: 0.3872 - auc: 0.8016Restoring model weights from the end of the best epoch.\n",
      "588001/588001 [==============================] - 14s 23us/sample - loss: 0.3873 - auc: 0.8015 - val_loss: 0.4054 - val_auc: 0.7629\n",
      "Epoch 00008: early stopping\n",
      "0.783321984449564\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 20s 34us/sample - loss: 0.4710 - auc: 0.6991 - val_loss: 0.4055 - val_auc: 0.7614\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 14s 24us/sample - loss: 0.4085 - auc: 0.7697 - val_loss: 0.3982 - val_auc: 0.7660\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 14s 23us/sample - loss: 0.4032 - auc: 0.7785 - val_loss: 0.3981 - val_auc: 0.7648\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 14s 23us/sample - loss: 0.4006 - auc: 0.7824 - val_loss: 0.3977 - val_auc: 0.7648\n",
      "Epoch 5/100\n",
      " 74752/588001 [==>...........................] - ETA: 12s - loss: 0.3956 - auc: 0.78980.7824614368490312\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 20s 34us/sample - loss: 0.4687 - auc: 0.7004 - val_loss: 0.4055 - val_auc: 0.7566\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 14s 23us/sample - loss: 0.4082 - auc: 0.7701 - val_loss: 0.4006 - val_auc: 0.7582\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 14s 23us/sample - loss: 0.4033 - auc: 0.7781 - val_loss: 0.3988 - val_auc: 0.7599\n",
      "Epoch 4/100\n",
      "588001/588001 [==============================] - 14s 24us/sample - loss: 0.4005 - auc: 0.7824 - val_loss: 0.3996 - val_auc: 0.7592\n",
      "Epoch 5/100\n",
      "588001/588001 [==============================] - 15s 26us/sample - loss: 0.3990 - auc: 0.7845 - val_loss: 0.4005 - val_auc: 0.7585\n",
      "Epoch 6/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.3966 - auc: 0.7882\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "588001/588001 [==============================] - 15s 25us/sample - loss: 0.3966 - auc: 0.7881 - val_loss: 0.4042 - val_auc: 0.7574\n",
      "Epoch 7/100\n",
      "588001/588001 [==============================] - 14s 24us/sample - loss: 0.3908 - auc: 0.7965 - val_loss: 0.4034 - val_auc: 0.7556\n",
      "Epoch 8/100\n",
      "587776/588001 [============================>.] - ETA: 0s - loss: 0.3873 - auc: 0.8014Restoring model weights from the end of the best epoch.\n",
      "588001/588001 [==============================] - 14s 24us/sample - loss: 0.3873 - auc: 0.8013 - val_loss: 0.4061 - val_auc: 0.7516\n",
      "Epoch 00008: early stopping\n",
      "0.7848125411830724\n",
      "Train on 588001 samples, validate on 11999 samples\n",
      "Epoch 1/100\n",
      "588001/588001 [==============================] - 18s 31us/sample - loss: 0.4680 - auc: 0.7016 - val_loss: 0.4099 - val_auc: 0.7571\n",
      "Epoch 2/100\n",
      "588001/588001 [==============================] - 13s 22us/sample - loss: 0.4086 - auc: 0.7693 - val_loss: 0.3982 - val_auc: 0.7608\n",
      "Epoch 3/100\n",
      "588001/588001 [==============================] - 13s 23us/sample - loss: 0.4034 - auc: 0.7781 - val_loss: 0.3977 - val_auc: 0.7609\n",
      "Epoch 4/100\n",
      "491520/588001 [========================>.....] - ETA: 2s - loss: 0.4004 - auc: 0.7831"
     ]
    }
   ],
   "source": [
    "oof_preds = np.zeros((len(train)))\n",
    "test_preds = np.zeros((len(test)))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=50)\n",
    "for train_index, test_index in skf.split(train, train.target.values):\n",
    "    X_train, X_test = train.iloc[train_index, :], train.iloc[test_index, :]\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    y_train, y_test = X_train.target.values, X_test.target.values\n",
    "    model = create_model(data, features)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[auc])\n",
    "    X_train = [X_train.loc[:, features].values[:, k] for k in range(X_train.loc[:, features].values.shape[1])]\n",
    "    X_test = [X_test.loc[:, features].values[:, k] for k in range(X_test.loc[:, features].values.shape[1])]\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor='val_auc', min_delta=0.001, patience=5,\n",
    "                                 verbose=1, mode='max', baseline=None, restore_best_weights=True)\n",
    "\n",
    "    rlr = callbacks.ReduceLROnPlateau(monitor='val_auc', factor=0.5,\n",
    "                                      patience=3, min_lr=1e-6, mode='max', verbose=1)\n",
    "    \n",
    "    model.fit(X_train,\n",
    "              utils.to_categorical(y_train),\n",
    "              validation_data=(X_test, utils.to_categorical(y_test)),\n",
    "              verbose=1,\n",
    "              batch_size=1024,\n",
    "              callbacks=[es, rlr],\n",
    "              epochs=100\n",
    "             )\n",
    "    valid_fold_preds = model.predict(X_test)[:, 1]\n",
    "    test_fold_preds = model.predict(test_data)[:, 1]\n",
    "    oof_preds[test_index] = valid_fold_preds.ravel()\n",
    "    test_preds += test_fold_preds.ravel()\n",
    "    print(metrics.roc_auc_score(y_test, valid_fold_preds))\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AUC=0.7855992564272951\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall AUC={}\".format(metrics.roc_auc_score(train.target.values, oof_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving submission file\n"
     ]
    }
   ],
   "source": [
    "test_preds /= 50\n",
    "test_ids = test.id.values\n",
    "print(\"Saving submission file\")\n",
    "submission = pd.DataFrame.from_dict({\n",
    "    'id': test_ids,\n",
    "    'target': test_preds\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
