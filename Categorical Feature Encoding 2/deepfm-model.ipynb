{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This kernel uses Deepfm model from deepctr package**\n",
    "\n",
    "**Deepfm :** [Deepfm using deepctr](https://deepctr-doc.readthedocs.io/en/v0.6.3/deepctr.models.deepfm.html)\n",
    "\n",
    "Guo H, Tang R, Ye Y, et al. Deepfm: a factorization-machine based neural network for ctr prediction[J]. arXiv preprint arXiv:1703.04247, 2017.(https://arxiv.org/abs/1703.04247)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --no-warn-conflicts -q deepctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from deepctr.inputs import  SparseFeat, DenseFeat, get_feature_names\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from deepctr.models import DeepFM\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, Callback\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, OneHotEncoder\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import utils\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/cat-in-the-dat-ii/train.csv')\n",
    "test = pd.read_csv('../input/cat-in-the-dat-ii/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['target'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['null'] = data.isna().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = [feat for feat in train.columns if feat not in ['id','target']]\n",
    "\n",
    "data[sparse_features] = data[sparse_features].fillna('-1', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat].fillna('-1').astype(str).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data.target != -1].reset_index(drop=True)\n",
    "test  = data[data.target == -1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique()) for feat in sparse_features]\n",
    "\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    def fallback_auc(y_true, y_pred):\n",
    "        try:\n",
    "            return roc_auc_score(y_true, y_pred)\n",
    "        except:\n",
    "            return 0.5\n",
    "    return tf.py_function(fallback_auc, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(K.epsilon()+pt_1))-K.mean((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0 + K.epsilon()))\n",
    "    return focal_loss_fixed\n",
    "\n",
    "get_custom_objects().update({'focal_loss_fn': focal_loss()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "\n",
    "get_custom_objects().update({'custom_gelu': Activation(custom_gelu)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mish(Activation):\n",
    "    '''\n",
    "    Mish Activation Function.\n",
    "    .. math::\n",
    "        mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + e^{x}))\n",
    "    Shape:\n",
    "        - Input: Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "        - Output: Same shape as the input.\n",
    "    Examples:\n",
    "        >>> X = Activation('Mish', name=\"conv1_act\")(X_input)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(Mish, self).__init__(activation, **kwargs)\n",
    "        self.__name__ = 'Mish'\n",
    "\n",
    "\n",
    "def mish(inputs):\n",
    "    return inputs * tf.math.tanh(tf.math.softplus(inputs))\n",
    "\n",
    "\n",
    "get_custom_objects().update({'Mish': Mish(mish)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmUpLearningRateScheduler(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Warmup learning rate scheduler\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, warmup_batches, init_lr, verbose=0):\n",
    "        \"\"\"Constructor for warmup learning rate scheduler\n",
    "\n",
    "        Arguments:\n",
    "            warmup_batches {int} -- Number of batch for warmup.\n",
    "            init_lr {float} -- Learning rate after warmup.\n",
    "\n",
    "        Keyword Arguments:\n",
    "            verbose {int} -- 0: quiet, 1: update messages. (default: {0})\n",
    "        \"\"\"\n",
    "\n",
    "        super(WarmUpLearningRateScheduler, self).__init__()\n",
    "        self.warmup_batches = warmup_batches\n",
    "        self.init_lr = init_lr\n",
    "        self.verbose = verbose\n",
    "        self.batch_count = 0\n",
    "        self.learning_rates = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.batch_count = self.batch_count + 1\n",
    "        lr = K.get_value(self.model.optimizer.lr)\n",
    "        self.learning_rates.append(lr)\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        if self.batch_count <= self.warmup_batches:\n",
    "            lr = self.batch_count*self.init_lr/self.warmup_batches\n",
    "            K.set_value(self.model.optimizer.lr, lr)\n",
    "            if self.verbose > 0:\n",
    "                print('\\nBatch %05d: WarmUpLearningRateScheduler setting learning '\n",
    "                      'rate to %s.' % (self.batch_count + 1, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicLR(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
    "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn == None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1 / (2. ** (x - 1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma ** (x)\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        \"\"\"Resets cycle iterations.\n",
    "        Optional boundary/step size adjustment.\n",
    "        \"\"\"\n",
    "        if new_base_lr != None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size != None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "\n",
    "    def clr(self):\n",
    "        cycle = np.floor(1 + self.clr_iterations / (2 * self.step_size))\n",
    "        x = np.abs(self.clr_iterations / self.step_size - 2 * cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr - self.base_lr) * np.maximum(0, (1 - x)) * self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr - self.base_lr) * np.maximum(0, (1 - x)) * self.scale_fn(\n",
    "                self.clr_iterations)\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())\n",
    "\n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "\n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        K.set_value(self.model.optimizer.lr, self.clr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['target']\n",
    "N_Splits = 50\n",
    "Verbose = 0\n",
    "Epochs = 10\n",
    "SEED = 2020\n",
    "Batch_S_T = 128\n",
    "Batch_S_P = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation AUC fold 1 : 0.78923\n",
      "validation AUC fold 2 : 0.78359\n",
      "validation AUC fold 3 : 0.791\n",
      "validation AUC fold 4 : 0.77893\n",
      "validation AUC fold 5 : 0.78788\n",
      "validation AUC fold 6 : 0.78469\n",
      "validation AUC fold 7 : 0.78831\n",
      "validation AUC fold 8 : 0.7889\n",
      "validation AUC fold 9 : 0.7901\n",
      "validation AUC fold 10 : 0.78576\n",
      "validation AUC fold 11 : 0.78421\n",
      "validation AUC fold 12 : 0.78372\n",
      "validation AUC fold 13 : 0.78315\n",
      "validation AUC fold 14 : 0.79126\n",
      "validation AUC fold 15 : 0.78812\n",
      "validation AUC fold 16 : 0.79901\n",
      "validation AUC fold 17 : 0.79302\n",
      "validation AUC fold 18 : 0.78051\n",
      "validation AUC fold 19 : 0.78034\n",
      "validation AUC fold 20 : 0.79016\n",
      "validation AUC fold 21 : 0.78936\n",
      "validation AUC fold 22 : 0.78438\n",
      "validation AUC fold 23 : 0.78878\n",
      "validation AUC fold 24 : 0.7966\n",
      "validation AUC fold 25 : 0.79333\n",
      "validation AUC fold 26 : 0.78537\n",
      "validation AUC fold 27 : 0.77828\n",
      "validation AUC fold 28 : 0.78252\n",
      "validation AUC fold 29 : 0.78525\n",
      "validation AUC fold 30 : 0.7921\n",
      "validation AUC fold 31 : 0.7929\n",
      "validation AUC fold 32 : 0.79468\n",
      "validation AUC fold 33 : 0.78231\n",
      "validation AUC fold 34 : 0.79054\n",
      "validation AUC fold 35 : 0.7866\n",
      "validation AUC fold 36 : 0.79094\n",
      "validation AUC fold 37 : 0.79587\n",
      "validation AUC fold 38 : 0.7834\n",
      "validation AUC fold 39 : 0.78751\n",
      "validation AUC fold 40 : 0.79231\n",
      "validation AUC fold 41 : 0.78907\n",
      "validation AUC fold 42 : 0.79253\n",
      "validation AUC fold 43 : 0.79038\n",
      "validation AUC fold 44 : 0.78278\n",
      "validation AUC fold 45 : 0.78531\n",
      "validation AUC fold 46 : 0.79419\n",
      "validation AUC fold 47 : 0.79002\n",
      "validation AUC fold 48 : 0.78909\n",
      "validation AUC fold 49 : 0.79649\n",
      "validation AUC fold 50 : 0.79115\n"
     ]
    }
   ],
   "source": [
    "oof_pred_deepfm = np.zeros((len(train), ))\n",
    "y_pred_deepfm = np.zeros((len(test), ))\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_Splits, shuffle=True, random_state=SEED)\n",
    "for fold, (tr_ind, val_ind) in enumerate(skf.split(train, train[target])):\n",
    "    X_train, X_val = train[sparse_features].iloc[tr_ind], train[sparse_features].iloc[val_ind]\n",
    "    y_train, y_val = train[target].iloc[tr_ind], train[target].iloc[val_ind]\n",
    "    train_model_input = {name:X_train[name] for name in feature_names}\n",
    "    val_model_input = {name:X_val[name] for name in feature_names}\n",
    "    test_model_input = {name:test[name] for name in feature_names}\n",
    "    model = DeepFM(linear_feature_columns, dnn_feature_columns, dnn_hidden_units=(256, 256), dnn_dropout=0.0, dnn_activation='Mish', dnn_use_bn=False, task='binary')\n",
    "    model.compile('adam', loss = 'binary_crossentropy', metrics=[auc], )\n",
    "    es = callbacks.EarlyStopping(monitor='val_auc', min_delta=0.001, patience=3, verbose=Verbose, mode='max', baseline=None, restore_best_weights=True)\n",
    "    sb = callbacks.ModelCheckpoint('./nn_model.w8', save_weights_only=True, save_best_only=True, verbose=Verbose)\n",
    "    clr = CyclicLR(base_lr=1e-7, max_lr = 1e-4, step_size= int(1.0*(test.shape[0])/(Batch_S_T*4)) , mode='exp_range', gamma=1.0, scale_fn=None, scale_mode='cycle')\n",
    "    history = model.fit(train_model_input, y_train,\n",
    "                        validation_data=(val_model_input, y_val),\n",
    "                        batch_size=Batch_S_T, epochs=Epochs, verbose=Verbose,\n",
    "                        callbacks=[es, sb, clr],)\n",
    "    model.load_weights('./nn_model.w8')\n",
    "    val_pred = model.predict(val_model_input, batch_size=Batch_S_P)\n",
    "    print(f'validation AUC fold {fold+1} : {round(roc_auc_score(y_val, val_pred), 5)}')\n",
    "    oof_pred_deepfm[val_ind] = val_pred.ravel()\n",
    "    y_pred_deepfm += model.predict(test_model_input, batch_size=Batch_S_P).ravel() / (N_Splits)\n",
    "    K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF AUC : 0.78827\n"
     ]
    }
   ],
   "source": [
    "print(f'OOF AUC : {round(roc_auc_score(train.target.values, oof_pred_deepfm), 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved!\n"
     ]
    }
   ],
   "source": [
    "test_idx = test.id.values\n",
    "submission = pd.DataFrame.from_dict({\n",
    "    'id': test_idx,\n",
    "    'target': y_pred_deepfm\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('Submission file saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('oof_pred_deepfm.npy',oof_pred_deepfm)\n",
    "np.save('y_pred_deepfm.npy',    y_pred_deepfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
