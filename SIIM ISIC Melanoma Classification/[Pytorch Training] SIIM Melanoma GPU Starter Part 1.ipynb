{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install various pretrained models packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: Turn on Internet on kaggle kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid requirement: '#'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\requirements.py\", line 93, in __init__\n",
      "    req = REQUIREMENT.parseString(requirement_string)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1632, in parseString\n",
      "    raise exc\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1622, in parseString\n",
      "    loc, tokens = self._parse( instring, 0 )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1379, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 3395, in parseImpl\n",
      "    loc, exprtokens = e._parse( instring, loc, doActions )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1379, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 3717, in parseImpl\n",
      "    return self.expr._parse( instring, loc, doActions, callPreParse=False )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1379, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 3378, in parseImpl\n",
      "    loc, resultlist = self.exprs[0]._parse( instring, loc, doActions, callPreParse=False )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1383, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 2689, in parseImpl\n",
      "    raise ParseException(instring, loc, self.errmsg, self)\n",
      "pip._vendor.pyparsing.ParseException: Expected W:(abcd...) (at char 0), (line:1, col:1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_internal\\req\\req_install.py\", line 252, in from_line\n",
      "    req = Requirement(req)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\requirements.py\", line 97, in __init__\n",
      "    requirement_string[e.loc:e.loc + 8]))\n",
      "pip._vendor.packaging.requirements.InvalidRequirement: Invalid requirement, parse error at \"'#'\"\n",
      "\n",
      "You are using pip version 10.0.1, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n",
      "Invalid requirement: '#'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\requirements.py\", line 93, in __init__\n",
      "    req = REQUIREMENT.parseString(requirement_string)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1632, in parseString\n",
      "    raise exc\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1622, in parseString\n",
      "    loc, tokens = self._parse( instring, 0 )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1379, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 3395, in parseImpl\n",
      "    loc, exprtokens = e._parse( instring, loc, doActions )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1379, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 3717, in parseImpl\n",
      "    return self.expr._parse( instring, loc, doActions, callPreParse=False )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1379, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 3378, in parseImpl\n",
      "    loc, resultlist = self.exprs[0]._parse( instring, loc, doActions, callPreParse=False )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1383, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 2689, in parseImpl\n",
      "    raise ParseException(instring, loc, self.errmsg, self)\n",
      "pip._vendor.pyparsing.ParseException: Expected W:(abcd...) (at char 0), (line:1, col:1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_internal\\req\\req_install.py\", line 252, in from_line\n",
      "    req = Requirement(req)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\requirements.py\", line 97, in __init__\n",
      "    requirement_string[e.loc:e.loc + 8]))\n",
      "pip._vendor.packaging.requirements.InvalidRequirement: Invalid requirement, parse error at \"'#'\"\n",
      "\n",
      "You are using pip version 10.0.1, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n",
      "Invalid requirement: '#'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\requirements.py\", line 93, in __init__\n",
      "    req = REQUIREMENT.parseString(requirement_string)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1632, in parseString\n",
      "    raise exc\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1622, in parseString\n",
      "    loc, tokens = self._parse( instring, 0 )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1379, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 3395, in parseImpl\n",
      "    loc, exprtokens = e._parse( instring, loc, doActions )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1379, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 3717, in parseImpl\n",
      "    return self.expr._parse( instring, loc, doActions, callPreParse=False )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1379, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 3378, in parseImpl\n",
      "    loc, resultlist = self.exprs[0]._parse( instring, loc, doActions, callPreParse=False )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1383, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 2689, in parseImpl\n",
      "    raise ParseException(instring, loc, self.errmsg, self)\n",
      "pip._vendor.pyparsing.ParseException: Expected W:(abcd...) (at char 0), (line:1, col:1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_internal\\req\\req_install.py\", line 252, in from_line\n",
      "    req = Requirement(req)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\requirements.py\", line 97, in __init__\n",
      "    requirement_string[e.loc:e.loc + 8]))\n",
      "pip._vendor.packaging.requirements.InvalidRequirement: Invalid requirement, parse error at \"'#'\"\n",
      "\n",
      "You are using pip version 10.0.1, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install timm                   # - https://github.com/rwightman/pytorch-image-models\n",
    "!pip install efficientnet_pytorch   # - https://github.com/lukemelas/EfficientNet-PyTorch\n",
    "!pip install pretrainedmodels       # - https://github.com/Cadene/pretrained-models.pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "gc.enable()\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import timm\n",
    "import pretrainedmodels\n",
    "import efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CSV Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/siim-isic-melanoma-classification/train.csv')\n",
    "test_df = pd.read_csv('../input/siim-isic-melanoma-classification/test.csv')\n",
    "sample = pd.read_csv('../input/siim-isic-melanoma-classification/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This one is working but the model is too big to download in kaggle\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.arch = pretrainedmodels.__dict__[\"se_resnext50_32x4d\"](pretrained=\"imagenet\")\n",
    "        self.arch.load_state_dict(torch.load(\"C:/Users/tushar.sharma/Desktop/SIIM-Kaggle/se_resnext50_32x4d-a260b3a4.pth\"))\n",
    "        self.arch.last_linear = nn.Linear(512, 1)\n",
    "    \n",
    "    def forward(self, image):\n",
    "        x = self.arch(image)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#Issue is in this model\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.arch = pretrainedmodels.__dict__[\"resnet18\"](pretrained=\"imagenet\")\n",
    "        self.arch.load_state_dict(torch.load(\"C:/Users/tushar.sharma/Desktop/SIIM-Kaggle/resnet18-5c106cde.pth\"))\n",
    "        self.arch.last_linear = nn.Linear(512, 1)\n",
    "    \n",
    "    def forward(self, image):\n",
    "        x = self.arch(image)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelanomaDataset(Dataset):\n",
    "    def __init__(self, dataframe:pd.DataFrame, imfolder:str, train=bool, transforms=None):\n",
    "        self.df = dataframe\n",
    "        self.imfolder = imfolder\n",
    "        self.train = train\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.__len__()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = os.path.join(self.imfolder, self.df.iloc[index]['image_name'] + '.jpg')\n",
    "        image = cv2.imread(image_path)\n",
    "        image = transforms.ToPILImage()(image)\n",
    "\n",
    "        if self.transforms:\n",
    "            image= self.transforms(image)\n",
    "        \n",
    "        if self.train:\n",
    "            label = self.df.iloc[index]['target']\n",
    "            return image, label\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=256, scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=32. / 255.,saturation=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Meter Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "epochs = 5\n",
    "train_bs = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"last_linear.weight\", \"last_linear.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-2848cb1b3e11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResNet18\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-32-ed3225559c1d>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mResNet18\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0march\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpretrainedmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"resnet18\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"imagenet\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0march\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/tushar.sharma/Desktop/SIIM-Kaggle/resnet18-5c106cde.pth\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0march\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_linear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m    845\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m--> 847\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m    848\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"last_linear.weight\", \"last_linear.bias\". "
     ]
    }
   ],
   "source": [
    "model = ResNet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df3def269a1a42148d53a2842692fa10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 16/130 [13:59<1:24:37, 44.54s/it, loss=0.609]"
     ]
    }
   ],
   "source": [
    "train = MelanomaDataset(train_df, \n",
    "                        imfolder='/kaggle/input/siim-isic-melanoma-classification/jpeg/train/', \n",
    "                        train=True, \n",
    "                        transforms=train_transform)\n",
    "train_loader = DataLoader(dataset=train, batch_size=train_bs, shuffle=True, num_workers=2)\n",
    "\n",
    "model = ResNet18()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=3,threshold=0.001, mode=\"max\")\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()    \n",
    "    losses = AverageMeter()\n",
    "    epoch_loss = 0.\n",
    "    correct = 0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    tk = tqdm(train_loader, total=len(train_loader), position=0, leave=True)\n",
    "    for idx, (imgs, labels) in enumerate(tk):\n",
    "        imgs_train = torch.tensor(imgs, device=device, dtype=torch.float32)\n",
    "        labels_train = torch.tensor(labels, device=device, dtype=torch.float32)\n",
    "        \n",
    "        optimizer.zero_grad() \n",
    "        output_train = model(imgs_train)\n",
    "        loss = criterion(output_train.squeeze(), labels_train)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        \n",
    "        pred = torch.round(torch.sigmoid(output_train))  \n",
    "        correct += (pred.cpu() == labels_train.cpu().unsqueeze(1)).sum().item()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        losses.update(loss.item(), imgs.size(0))\n",
    "        tk.set_postfix(loss=losses.avg)\n",
    "        \n",
    "    train_acc = correct / len(train_idx)\n",
    "    print('Epoch {:03}: | Loss: {:.3f} | Train acc: {:.3f} | Training time: {}'.format(\n",
    "            epoch + 1, \n",
    "            epoch_loss, \n",
    "            train_acc,  \n",
    "            str(datetime.timedelta(seconds=time.time() - start_time))[:7]))\n",
    "    scheduler.step(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
