{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"scrolled":false},"cell_type":"code","source":"!pip install pretrainedmodels\n!pip install torchtoolbox","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"scrolled":false},"cell_type":"code","source":"import time\ntime1 = time.time()\nimport os\nimport gc\ngc.enable()\nimport glob\nimport datetime\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import BatchSampler, DataLoader, Dataset, SequentialSampler\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nfrom tqdm import tqdm\nfrom pathlib import Path\n\nimport torchtoolbox\nfrom torchtoolbox.tools import summary\n\nimport pretrainedmodels\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom catalyst.data.sampler import BalanceClassSampler\n\nimport sklearn\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold\n\nimport warnings\nwarnings.simplefilter(\"ignore\")\nwarnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n\ndef seed_everything(seed=2020):\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    print(\"Seeding completed..\")\nseed_everything()\ntime2 = time.time()\nprint(\"Importing libraries done.! Total time taken {:.2f}sec.\".format(time2-time1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"DATA_PATH = '../input/melanoma-merged-external-data-512x512-jpeg'\ndf_folds = pd.read_csv(f'{DATA_PATH}/folds.csv', low_memory=False)\nTRAIN_PATH = f'{DATA_PATH}/512x512-dataset-melanoma/512x512-dataset-melanoma/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"def get_train_transforms():\n    return A.Compose([\n            A.RandomSizedCrop(min_max_height=(400, 400), height=512, width=512, p=0.5),\n            A.RandomRotate90(p=0.5),\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.5),\n            A.Resize(height=512, width=512, p=1),\n            A.Cutout(num_holes=8, max_h_size=64, max_w_size=64, fill_value=0, p=0.5),\n            ToTensorV2(p=1.0),                  \n        ], p=1.0)\n\ndef get_valid_transforms():\n    return A.Compose([\n            A.Resize(height=512, width=512, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"def onehot(size, target):\n    vec = torch.zeros(size, dtype=torch.float32)\n    vec[target] = 1.\n    return vec\n\nclass DatasetRetriever(Dataset):\n\n    def __init__(self, image_ids, labels, transforms=None):\n        super().__init__()\n        self.image_ids = image_ids\n        self.labels = labels\n        self.transforms = transforms\n\n    def __getitem__(self, idx: int):\n        image_id = self.image_ids[idx]\n        image = cv2.imread(f'{TRAIN_PATH}/{image_id}.jpg', cv2.IMREAD_COLOR)\n        image = image.astype(np.float32) / 255.0\n\n        label = self.labels[idx]\n\n        if self.transforms:\n            sample = {'image': image}\n            sample = self.transforms(**sample)\n            image = sample['image']\n\n        target = onehot(2, label)\n        return image, target\n\n    def __len__(self) -> int:\n        return self.image_ids.shape[0]\n\n    def get_labels(self):\n        return list(self.labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Metrics","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"from sklearn import metrics\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"class RocAucMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.y_true = np.array([0,1])\n        self.y_pred = np.array([0.5,0.5])\n        self.score = 0\n\n    def update(self, y_true, y_pred):\n        y_true = y_true.cpu().numpy().argmax(axis=1).clip(min=0, max=1).astype(int)\n        # y_pred = 1 - nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,0]\n        y_pred = nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,1]\n        self.y_true = np.hstack((self.y_true, y_true))\n        self.y_pred = np.hstack((self.y_pred, y_pred))\n        self.score = sklearn.metrics.roc_auc_score(self.y_true, self.y_pred)\n\n    @property\n    def avg(self):\n        return self.score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"class APScoreMeter(RocAucMeter):\n    def __init__(self):\n        super(APScoreMeter, self).__init__()\n\n    def update(self, y_true, y_pred):\n        y_true = y_true.cpu().numpy().argmax(axis=1).clip(min=0, max=1).astype(int)\n        y_pred = nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,1]\n        self.y_true = np.hstack((self.y_true, y_true))\n        self.y_pred = np.hstack((self.y_pred, y_pred))\n        self.score = sklearn.metrics.average_precision_score(self.y_true, self.y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loss and Label Smoothing","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, alpha=1, gamma=2, logits=False, reduce=True):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.logits = logits\n        self.reduce = reduce\n        \n    def forward(self, inputs, targets):\n        if self.logits:\n            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets)\n        else:\n            BCE_loss = F.binary_cross_entropy(inputs, targets)\n        pt = torch.exp(-BCE_loss)\n        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n        if self.reduce:\n            return torch.mean(F_loss)\n        else:\n            return F_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"class LabelSmoothing(nn.Module):\n    def __init__(self, smoothing=0.1):\n        super(LabelSmoothing, self).__init__()\n        self.confidence = 1.0 - smoothing\n        self.smoothing = smoothing\n        \n    def forward(self, x, target):\n        if self.training:\n            x = x.float()\n            target = target.float()\n            logprobs = F.log_softmax(x, dim=-1)\n            \n            nll_loss = -logprobs * target\n            nll_loss = nll_loss.sum(-1)\n            smooth_loss = -logprobs.mean(dim=1)\n            \n            loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n            return loss.mean()\n        else:\n            return F.cross_entropy(x, target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"def gem(x, p=3, eps=1e-6):\n    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n\nclass GeM(nn.Module):\n    'Gemeralized Mean Pooling'\n    def __init__(self, p=3, eps=1e-6):\n        super(GeM,self).__init__()\n        self.p = Parameter(torch.ones(1)*p)\n        self.eps = eps\n    def forward(self, x):\n        return gem(x, p=self.p, eps=self.eps)       \n    def __repr__(self):\n        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n    \nclass Conv2d_ws(nn.Conv2d):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1,padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros'):\n        super(nn.Conv2d, self).__init__(in_channels, out_channels, kernel_size, stride,padding, dilation, bias=True ,padding_mode='zeros',\n                                       groups=1, output_padding='zeros', transposed=False)\n    def forward(self, x):\n        weight = self.weight\n        weight_mean = weight.mean(dim=1, keepdim=True).mean(dim=2,\n                                  keepdim=True).mean(dim=3, keepdim=True)\n        weight = weight - weight_mean\n        std = weight.view(weight.size(0), -1).std(dim=1).view(-1, 1, 1, 1) + 1e-5\n        weight = weight / std.expand_as(weight)\n        return F.conv2d(x, weight, self.bias, self.stride,\n                        self.padding, self.dilation, self.groups)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"def convert_to_conv2d(model):\n    'conv2d with weight standardization'\n    for child_name, child in model.named_children():\n        if child_name not in ['fc1','fc2']:\n            if isinstance(child, nn.Conv2d):\n                in_feat = child.in_channels\n                out_feat = child.out_channels\n                ker_size = child.kernel_size\n                stride = child.stride\n                padding = child.padding\n                dilation = child.dilation\n                groups = child.groups\n                setattr(model, child_name, Conv2d_ws(in_channels=in_feat, out_channels=out_feat, kernel_size=ker_size, stride=stride,padding = padding, dilation=dilation, groups=groups))\n            else:\n                convert_to_conv2d(child)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"class SEResNext50_32x4d(nn.Module):\n    def __init__(self, weight_standardization=False, generalized_mean_pooling=False, pretrained=False, dropout_num=0, dropout_p=0.5, classes=2):\n        '''\n        params:\n        weight_standardization: implement conv2d weight standardization\n        generalized_mean_pooling: implement generalized mean pooling\n        pretrained: pretrained weights\n        drop_num: number of dropout layers for multi-sample dropout\n        dropout_p: dropout probability for multi-sample dropout\n        classes: number of target classes\n        '''\n        \n        super(SEResNext50_32x4d, self).__init__()\n        self.model = pretrainedmodels.__dict__['se_resnext50_32x4d'](pretrained=None)\n        if pretrained:\n            self.model.load_state_dict(torch.load(\n                '../input/pretrained-model-weights-pytorch/se_resnext50_32x4d-a260b3a4.pth'\n            ))\n        if weight_standardization:\n            convert_to_conv2d(self.model)\n        if generalized_mean_pooling:\n            self.model.avg_pool = GeM()\n        else:\n            self.model.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.model.last_linear = nn.Linear(in_features=self.model.last_linear.in_features, out_features=classes)\n        self.fc = nn.Linear(in_features=2048, out_features=classes)\n        self.dropouts = nn.ModuleList([nn.Dropout(dropout_p) for _ in range(dropout_num)])\n        \n    def forward(self, inputs):\n        features = self.model(inputs)\n        if len(self.dropouts) == 0:\n            return features\n            # outputs = self.fc(features)\n            # return outputs\n        else:\n            for i, dropout in enumerate(self.dropouts):\n                if i==0:\n                    outputs = dropout(features)\n                    outputs = outputs.view(outputs.size(0),-1)\n                    outputs = self.fc(outputs)\n                else:\n                    temp_out = dropout(features)\n                    temp_out = temp_out.view(temp_out.size(0),-1)\n                    outputs = outputs + self.fc(temp_out)\n            return outputs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fitter / Trainer","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"def is_lastLinear(name):\n    return \"last_linear\" in name\n\nclass Fitter(object):\n    def __init__(self, model, device, config, folder):\n        self.config = config\n        self.epoch = 0\n        \n        self.base_dir = f'./{folder}'\n        if not os.path.exists(self.base_dir):\n            os.makedirs(self.base_dir)\n        self.log_path = f'{self.base_dir}/log.txt'\n        \n        self.best_score = 0\n        self.best_loss = 10**5\n        self.best_ap = 0\n        \n        self.model = model\n        self.device = device\n        self.model.to(self.device)\n        self.model = nn.DataParallel(self.model)\n        \n        # differential learning rate and weight decay\n        param_optimizer = list(self.model.named_parameters())\n        no_decay_layers = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n        optimizer_grouped_parameters = [\n            {\n                \"params\": [param for name, param in param_optimizer if not is_lastLinear(name) and \\\n                           not any(layer in name for layer in no_decay_layers)], \n                \"lr\": self.config.learning_rate,\n                'weight_decay': 0.001\n            },\n            {\n                \"params\": [param for name, param in param_optimizer if not is_lastLinear(name) and \\\n                           any(layer in name for layer in no_decay_layers)], \n                \"lr\": self.config.learning_rate,\n                'weight_decay': 0.0\n            },\n            {\n                \"params\": [param for name, param in param_optimizer if is_lastLinear(name)],\n                \"lr\": self.config.learning_rate * 10,\n            },\n        ]\n        self.optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=self.config.learning_rate, weight_decay=0.0)\n        self.scheduler = self.config.Scheduler(self.optimizer, **self.config.scheduler_params)\n        \n        #self.criterion = FocalLoss(logits=True).to(self.device)\n        self.criterion = LabelSmoothing().to(self.device)\n        \n        if self.config.verbose:\n            self.log(f'Fitter initialized. Device is {self.device}.')\n    \n    def fit(self, train_loader, validation_loader):\n        \n        for epoch in range(self.config.n_epochs):\n            if self.config.verbose:\n                learning_rate_1 = self.optimizer.param_groups[0]['lr']\n                learning_rate_2 = self.optimizer.param_groups[-1]['lr']\n                timestamp = datetime.datetime.utcnow().isoformat()\n                self.log(f\"\\n{timestamp}\\nLR: {learning_rate_1}, {learning_rate_2}\")\n            \n            time1 = time.time()\n            summary_loss, roc_auc_scores, ap_scores = self.train_one_epoch(train_loader)\n            if self.config.verbose:\n                self.log(f\"[TRAIN RESULT]: Epoch: {self.epoch}, Summary Loss: {summary_loss.avg:.3f}, Roc Auc: {roc_auc_scores.avg:.3f}, Average Precision: {ap_scores.avg:.3f}, Time: {(time.time()-time1):.2f}secs.\")\n            \n            if self.config.train_scheduler:\n                self.scheduler.step(metrics=summary_loss.avg)\n            \n            time2 = time.time()\n            summary_loss, roc_auc_scores, ap_scores = self.validation(validation_loader)\n            if self.config.verbose:\n                self.log(f\"[VALIDATION RESULT]: Epoch: {self.epoch}, Summary Loss: {summary_loss.avg:.3f}, Roc Auc: {roc_auc_scores.avg:.3f}, Average Precision: {ap_scores.avg:.3f}, Time: {(time.time()-time2):.2f}secs.\")\n            if self.config.validation_scheduler:\n                self.scheduler.step(metrics=summary_loss.avg)\n            \n            if summary_loss.avg < self.best_loss:\n                self.best_loss = summary_loss.avg\n                self.save_model(f'{self.base_dir}/best_loss_checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n                for path in sorted(glob.glob(f'{self.base_dir}/best-loss-checkpoint-*epoch.bin'))[:-2]:\n                    os.remove(path)\n            if roc_auc_scores.avg > self.best_score:\n                self.best_score = roc_auc_scores.avg\n                self.save_model(f'{self.base_dir}/best-score-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n                for path in sorted(glob.glob(f'{self.base_dir}/best-score-checkpoint-*epoch.bin'))[:-2]:\n                    os.remove(path)\n            if ap_scores.avg > self.best_ap:\n                self.best_ap = ap_scores.avg\n                self.save_model(f'{self.base_dir}/best-ap-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n                for path in sorted(glob.glob(f'{self.base_dir}/best-ap-checkpoint-*epoch.bin'))[:-2]:\n                    os.remove(path)\n            \n            \n            self.epoch +=1\n    \n    def train_one_epoch(self, train_loader):\n        self.model.train()\n        time1 = time.time()\n        \n        summary_loss = AverageMeter()\n        roc_auc_scores = RocAucMeter()\n        ap_scores = APScoreMeter()\n        \n        for step, (images, targets) in enumerate(train_loader):\n            if self.config.verbose:\n                if step % self.config.verbose_step == 0:\n                    print(\n                        f'Train Step {step}/{len(train_loader)}, ' + \\\n                        f'Summary Loss: {summary_loss.avg:.3f}, ROC AUC: {roc_auc_scores.avg:.3f}, AP: {ap_scores.avg:.3f} ' + \\\n                        f'Time: {(time.time() - time1):.2f}', end='\\r'\n                    )\n            \n            images = torch.tensor(images, device=self.device, dtype=torch.float32)\n            targets = torch.tensor(targets, device=self.device, dtype=torch.float32)\n            batch_size = images.shape[0]\n            \n            self.optimizer.zero_grad()\n            outputs = self.model(images)\n            loss = self.criterion(outputs, targets)\n            loss.backward()\n            self.optimizer.step()\n            \n            summary_loss.update(loss.detach().item(), batch_size)\n            roc_auc_scores.update(targets, outputs)\n            ap_scores.update(targets, outputs)\n            \n        return summary_loss, roc_auc_scores, ap_scores\n    \n    def validation(self, val_loader):\n        self.model.eval()\n        time1 = time.time()\n        \n        summary_loss = AverageMeter()\n        roc_auc_scores = RocAucMeter()\n        ap_scores = APScoreMeter()\n        \n        for step, (images, targets) in enumerate(val_loader):\n            if self.config.verbose:\n                if step % self.config.verbose_step == 0:\n                    print(\n                        f'Val Step {step}/{len(val_loader)}, ' + \\\n                        f'summary Loss: {summary_loss.avg:.3f}, ROC AUC: {roc_auc_scores.avg:.3f}, AP: {ap_scores.avg:.3f} ' + \\\n                        f'Time: {(time.time() - time1):.2f}', end='\\r'\n                    )\n            with torch.no_grad():\n                images = torch.tensor(images, device=self.device, dtype=torch.float32)\n                targets = torch.tensor(targets, device=self.device, dtype=torch.float32)\n                batch_size = images.shape[0]\n                \n                outputs = self.model(images)\n                loss = self.criterion(outputs, targets)\n                \n                roc_auc_scores.update(targets, outputs)\n                ap_scores.update(targets, outputs)\n                summary_loss.update(loss.detach().item(), batch_size)\n        \n        return summary_loss, roc_auc_scores, ap_scores\n    \n    def save_model(self, path):\n        self.model.eval()\n        torch.save(self.model.state_dict(), path)\n    \n    def save(self, path):\n        self.model.eval()\n        torch.save({\n            'model_state_dict': self.model.state_dict(),\n            'optimizer_state_dict': self.optimizer.state_dict(),\n            'scheduler_state_dict': self.scheduler.state_dict(),\n            'best_score': self.best_score,\n            'best_ap': self.best_ap,\n            'best_loss': self.best_loss,\n            'epoch': self.epoch,\n        }, path)\n    \n    def load(self, path):\n        checkpoint = torch.load(path)\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n        self.best_score = checkpoint['best_score']\n        self.best_ap = checkpoint['best_ap']\n        self.best_loss = checkpoint['best_loss']\n        self.epoch = checkpoint['epoch']\n        \n    def log(self, message):\n        if self.config.verbose:\n            print(message)\n        with open(self.log_path, 'a+') as logger:\n            logger.write(f'{message}\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"class TrainGlobalConfig:\n    num_workers = 2\n    \n    batch_size = 16\n    n_epochs = 15\n    learning_rate = 1e-4\n    \n    verbose = True\n    verbose_step = 1\n    \n    train_scheduler = True\n    validation_scheduler = True\n    \n    Scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau\n    scheduler_params = dict(\n        mode = 'min',\n        factor = 0.8,\n        patience = 1,\n        verbose = False, \n        threshold = 0.0001,\n        threshold_mode = 'abs',\n        cooldown = 0,\n        min_lr = 1e-8,\n        eps = 1e-08\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"model = SEResNext50_32x4d(pretrained=True, generalized_mean_pooling=False, weight_standardization=False, dropout_num=0, dropout_p=0.5)\nfitter = Fitter(model=model, device = torch.device(\"cuda\"), config=TrainGlobalConfig, folder='base_state')\nBASE_STATE_PATH = f'{fitter.base_dir}/base_state.bin'\nfitter.save(BASE_STATE_PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"def train_fold(fold_number):\n    train_dataset = DatasetRetriever(image_ids=df_folds[df_folds['fold']!=fold_number].image_id.values,\n                                   labels=df_folds[df_folds['fold']!=fold_number].target.values,\n                                   transforms=get_train_transforms())\n    \n    df_val = df_folds[(df_folds['fold']==fold_number)&(df_folds['source']=='ISIC20')]\n    validation_dataset = DatasetRetriever(image_ids=df_val.image_id.values,\n                                   labels=df_val.target.values,\n                                   transforms=get_valid_transforms())\n    \n    train_loader = DataLoader(train_dataset,\n                              sampler= BalanceClassSampler(labels=train_dataset.get_labels(), \n                                                         mode='downsampling'),\n                              batch_size= TrainGlobalConfig.batch_size,\n                              pin_memory= False,\n                              drop_last=True,\n                              num_workers=TrainGlobalConfig.num_workers\n                             )\n    val_loader = DataLoader(validation_dataset,\n                            sampler= SequentialSampler(validation_dataset),\n                            batch_size= TrainGlobalConfig.batch_size,\n                            pin_memory= False,\n                            shuffle=False,\n                            drop_last=False,\n                            num_workers=TrainGlobalConfig.num_workers\n                           )\n    \n    fitter = Fitter(model=model, device=torch.device(\"cuda\"), config=TrainGlobalConfig, folder=f'fold{fold_number}')\n    fitter.load(BASE_STATE_PATH)\n    fitter.fit(train_loader=train_loader, validation_loader=val_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"for fold_number in range(5):\n    train_fold(fold_number=fold_number)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}