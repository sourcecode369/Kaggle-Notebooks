{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Install various pretrained models packages"},{"metadata":{},"cell_type":"markdown","source":"##### Note: Turn on Internet on kaggle kernel"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install timm                   # - https://github.com/rwightman/pytorch-image-models\n!pip install efficientnet_pytorch   # - https://github.com/lukemelas/EfficientNet-PyTorch\n!pip install pretrainedmodels       # - https://github.com/Cadene/pretrained-models.pytorch","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting timm\n  Downloading timm-0.1.30-py3-none-any.whl (207 kB)\n\u001b[K     |████████████████████████████████| 207 kB 4.4 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: torch>=1.0 in /opt/conda/lib/python3.7/site-packages (from timm) (1.5.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.6.0a0+82fd1c8)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.0->timm) (0.18.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.0->timm) (1.18.1)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (5.4.1)\nInstalling collected packages: timm\nSuccessfully installed timm-0.1.30\nCollecting efficientnet_pytorch\n  Downloading efficientnet_pytorch-0.6.3.tar.gz (16 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet_pytorch) (1.5.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet_pytorch) (0.18.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet_pytorch) (1.18.1)\nBuilding wheels for collected packages: efficientnet-pytorch\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-py3-none-any.whl size=12419 sha256=f49024e1f73075fb5a81da8fe5490509e48eb6b0345c0df5eb05b2cbf950bb8f\n  Stored in directory: /root/.cache/pip/wheels/90/6b/0c/f0ad36d00310e65390b0d4c9218ae6250ac579c92540c9097a\nSuccessfully built efficientnet-pytorch\nInstalling collected packages: efficientnet-pytorch\nSuccessfully installed efficientnet-pytorch-0.6.3\nCollecting pretrainedmodels\n  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n\u001b[K     |████████████████████████████████| 58 kB 2.3 MB/s eta 0:00:011\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (1.5.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (0.6.0a0+82fd1c8)\nRequirement already satisfied: munch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (2.5.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (4.45.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels) (0.18.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels) (1.18.1)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->pretrainedmodels) (5.4.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from munch->pretrainedmodels) (1.14.0)\nBuilding wheels for collected packages: pretrainedmodels\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60962 sha256=0ed2e750c527de12274eadc7695be67ef35939884209d881a58e8c18bd0b795d\n  Stored in directory: /root/.cache/pip/wheels/ed/27/e8/9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\nSuccessfully built pretrainedmodels\nInstalling collected packages: pretrainedmodels\nSuccessfully installed pretrainedmodels-0.7.4\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Dependencies"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport gc\ngc.enable()\nimport time\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\n\nfrom sklearn.metrics import roc_auc_score\n\nimport timm\nimport pretrainedmodels\nimport efficientnet_pytorch","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.simplefilter(\"ignore\")","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load CSV Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/siim-isic-melanoma-classification/train.csv')\ntest_df = pd.read_csv('../input/siim-isic-melanoma-classification/test.csv')\nsample = pd.read_csv('../input/siim-isic-melanoma-classification/sample_submission.csv')","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class ResNet18(nn.Module):\n    def __init__(self):\n        super(ResNet18, self).__init__()\n        self.arch = pretrainedmodels.__dict__[\"resnet18\"](pretrained=\"imagenet\")\n        #self.arch.load_state_dict(torch.load(\"../input/pretrained-model-weights-pytorch/resnet18-5c106cde.pth\"))\n        self.arch.last_linear = nn.Linear(512, 1)\n    \n    def forward(self, image):\n        x = self.arch(image)\n        return x","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Image DataLoader"},{"metadata":{"trusted":true},"cell_type":"code","source":"class MelanomaDataset(Dataset):\n    def __init__(self, dataframe:pd.DataFrame, imfolder:str, train=bool, transforms=None):\n        self.df = dataframe\n        self.imfolder = imfolder\n        self.train = train\n        self.transforms = transforms\n        \n    def __len__(self):\n        return self.df.__len__()\n    \n    def __getitem__(self, index):\n        image_path = os.path.join(self.imfolder, self.df.iloc[index]['image_name'] + '.jpg')\n        image = cv2.imread(image_path)\n        image = transforms.ToPILImage()(image)\n\n        if self.transforms:\n            image= self.transforms(image)\n        \n        if self.train:\n            label = self.df.iloc[index]['target']\n            return image, label\n        else:\n            return image","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Simple Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.RandomResizedCrop(size=256, scale=(0.7, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.ColorJitter(brightness=32. / 255.,saturation=0.5),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n])\n\ntest_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n])","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Average Meter Metric"},{"metadata":{"trusted":true},"cell_type":"code","source":"class AverageMeter:\n    \"\"\"\n    Computes and stores the average and current value\n    \"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"device = \"cuda\"\nepochs = 5\ntrain_bs = 256","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = MelanomaDataset(train_df, \n                        imfolder='/kaggle/input/siim-isic-melanoma-classification/jpeg/train/', \n                        train=True, \n                        transforms=train_transform)\ntrain_loader = DataLoader(dataset=train, batch_size=train_bs, shuffle=True, num_workers=2)\n\nmodel = ResNet18()\nmodel.to(device)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=3,threshold=0.001, mode=\"max\")\ncriterion = nn.BCEWithLogitsLoss()\n\nfor epoch in range(epochs):\n    start_time = time.time()\n    model.train()    \n    losses = AverageMeter()\n    epoch_loss = 0.\n    correct = 0\n    optimizer.zero_grad()\n    \n    tk = tqdm(train_loader, total=len(train_loader), position=0, leave=True)\n    for idx, (imgs, labels) in enumerate(tk):\n        imgs_train = torch.tensor(imgs, device=device, dtype=torch.float32)\n        labels_train = torch.tensor(labels, device=device, dtype=torch.float32)\n        \n        optimizer.zero_grad() \n        output_train = model(imgs_train)\n        loss = criterion(output_train.squeeze(), labels_train)\n        loss.backward()\n        optimizer.step() \n        \n        pred = torch.round(torch.sigmoid(output_train))  \n        correct += (pred.cpu() == labels_train.cpu().unsqueeze(1)).sum().item()\n        epoch_loss += loss.item()\n        \n        losses.update(loss.item(), imgs.size(0))\n        tk.set_postfix(loss=losses.avg)\n        \n    train_acc = correct / len(train_idx)\n    print('Epoch {:03}: | Loss: {:.3f} | Train acc: {:.3f} | Training time: {}'.format(\n            epoch + 1, \n            epoch_loss, \n            train_acc,  \n            str(datetime.timedelta(seconds=time.time() - start_time))[:7]))\n    scheduler.step(auc)","execution_count":null,"outputs":[{"output_type":"stream","text":"Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df3def269a1a42148d53a2842692fa10"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"stream","text":" 12%|█▏        | 16/130 [13:59<1:24:37, 44.54s/it, loss=0.609]","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}