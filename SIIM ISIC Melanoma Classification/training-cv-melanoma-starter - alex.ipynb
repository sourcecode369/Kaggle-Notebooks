{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Melanoma starter pipeline by [@shonenkov](https://www.kaggle.com/shonenkov)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Main ideas\n",
    "\n",
    "\n",
    "- Using External Data\n",
    "- StratifyGroupKFold\n",
    "- Focal Loss / Label Smoothing\n",
    "- BalanceClassSampler\n",
    "- SimpleAugs\n",
    "- 512x512 image size\n",
    "- EfficientNet"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q efficientnet_pytorch > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import cv2\n",
    "from skimage import io\n",
    "import albumentations as A\n",
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.nn import functional as F\n",
    "from glob import glob\n",
    "import sklearn\n",
    "from torch import nn\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# External data\n",
    "\n",
    "I have prepared kernel with merging data. Don't forget to read [this kernel](https://www.kaggle.com/shonenkov/merge-external-data) ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../input/melanoma-merged-external-data-512x512-jpeg'"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# StratifyGroupKFold\n",
    "\n",
    "I think group by patient_id is very important. Also I think that stratify by sex, target, source, anatom_site_general_challenge also useful.\n",
    "Code with getting folds you can find [here](https://www.kaggle.com/shonenkov/merge-external-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_folds = pd.read_csv(f'{DATA_PATH}/folds.csv', index_col='image_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_folds[df_folds['fold'] == 0]['patient_id'].values).intersection(df_folds[df_folds['fold'] == 1]['patient_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_folds[df_folds['fold'] == 0]['target'].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_folds[df_folds['fold'] == 1]['target'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return A.Compose([\n",
    "            A.RandomSizedCrop(min_max_height=(400, 400), height=512, width=512, p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.Resize(height=512, width=512, p=1),\n",
    "            A.Cutout(num_holes=8, max_h_size=64, max_w_size=64, fill_value=0, p=0.5),\n",
    "            ToTensorV2(p=1.0),                  \n",
    "        ], p=1.0)\n",
    "\n",
    "def get_valid_transforms():\n",
    "    return A.Compose([\n",
    "            A.Resize(height=512, width=512, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_ROOT_PATH = f'{DATA_PATH}/512x512-dataset-melanoma/512x512-dataset-melanoma'\n",
    "\n",
    "def onehot(size, target):\n",
    "    vec = torch.zeros(size, dtype=torch.float32)\n",
    "    vec[target] = 1.\n",
    "    return vec\n",
    "\n",
    "class DatasetRetriever(Dataset):\n",
    "\n",
    "    def __init__(self, image_ids, labels, transforms=None):\n",
    "        super().__init__()\n",
    "        self.image_ids = image_ids\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image = cv2.imread(f'{TRAIN_ROOT_PATH}/{image_id}.jpg', cv2.IMREAD_COLOR)\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = {'image': image}\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample['image']\n",
    "\n",
    "        target = onehot(2, label)\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]\n",
    "\n",
    "    def get_labels(self):\n",
    "        return list(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class RocAucMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.y_true = np.array([0,1])\n",
    "        self.y_pred = np.array([0.5,0.5])\n",
    "        self.score = 0\n",
    "\n",
    "    def update(self, y_true, y_pred):\n",
    "        y_true = y_true.cpu().numpy().argmax(axis=1).clip(min=0, max=1).astype(int)\n",
    "        # y_pred = 1 - nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,0]\n",
    "        y_pred = nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,1]\n",
    "        self.y_true = np.hstack((self.y_true, y_true))\n",
    "        self.y_pred = np.hstack((self.y_pred, y_pred))\n",
    "        self.score = sklearn.metrics.roc_auc_score(self.y_true, self.y_pred)\n",
    "\n",
    "    @property\n",
    "    def avg(self):\n",
    "        return self.score\n",
    "\n",
    "    \n",
    "class APScoreMeter(RocAucMeter):\n",
    "    def __init__(self):\n",
    "        super(APScoreMeter, self).__init__()\n",
    "\n",
    "    def update(self, y_true, y_pred):\n",
    "        y_true = y_true.cpu().numpy().argmax(axis=1).clip(min=0, max=1).astype(int)\n",
    "        y_pred = nn.functional.softmax(y_pred, dim=1).data.cpu().numpy()[:,1]\n",
    "        self.y_true = np.hstack((self.y_true, y_true))\n",
    "        self.y_pred = np.hstack((self.y_pred, y_pred))\n",
    "        self.score = sklearn.metrics.average_precision_score(self.y_true, self.y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, logits=False, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets)\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets)\n",
    "\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "        \n",
    "class LabelSmoothing(nn.Module):\n",
    "    def __init__(self, smoothing = 0.1):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        if self.training:\n",
    "            x = x.float()\n",
    "            target = target.float()\n",
    "            logprobs = torch.nn.functional.log_softmax(x, dim = -1)\n",
    "\n",
    "            nll_loss = -logprobs * target\n",
    "            nll_loss = nll_loss.sum(-1)\n",
    "    \n",
    "            smooth_loss = -logprobs.mean(dim=-1)\n",
    "\n",
    "            loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
    "\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return torch.nn.functional.cross_entropy(x, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b5-b6417697.pth\" to /root/.cache/torch/checkpoints/efficientnet-b5-b6417697.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9180054f73f146bba2a972af40548075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=122410125.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "def get_net():\n",
    "    net = EfficientNet.from_pretrained('efficientnet-b5')\n",
    "    net._fc = nn.Linear(in_features=2048, out_features=2, bias=True)\n",
    "    return net\n",
    "\n",
    "net = get_net().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fitter:\n",
    "    \n",
    "    def __init__(self, model, device, config, folder):\n",
    "        self.config = config\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.base_dir = f'./{folder}'\n",
    "        if not os.path.exists(self.base_dir):\n",
    "            os.makedirs(self.base_dir)\n",
    "\n",
    "        self.log_path = f'{self.base_dir}/log.txt'\n",
    "        self.best_score = 0\n",
    "        self.best_loss = 10**5\n",
    "        self.best_ap = 0\n",
    "        \n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "        param_optimizer = list(self.model.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ] \n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=config.lr)\n",
    "        self.scheduler = config.SchedulerClass(self.optimizer, **config.scheduler_params)\n",
    "\n",
    "#         self.criterion = FocalLoss(logits=True).to(self.device)\n",
    "        self.criterion = LabelSmoothing().to(self.device)\n",
    "        self.log(f'Fitter prepared. Device is {self.device}')\n",
    "\n",
    "    def fit(self, train_loader, validation_loader):\n",
    "        for e in range(self.config.n_epochs):\n",
    "            if self.config.verbose:\n",
    "                lr = self.optimizer.param_groups[0]['lr']\n",
    "                timestamp = datetime.utcnow().isoformat()\n",
    "                self.log(f'\\n{timestamp}\\nLR: {lr}')\n",
    "\n",
    "            t = time.time()\n",
    "            summary_loss, roc_auc_scores, ap_scores = self.train_one_epoch(train_loader)\n",
    "            self.log(f'[RESULT]: Train. Epoch: {self.epoch}, summary_loss: {summary_loss.avg:.5f}, roc_auc: {roc_auc_scores.avg:.5f}, ap: {ap_scores.avg:.5f}, time: {(time.time() - t):.5f}')\n",
    "\n",
    "            t = time.time()\n",
    "            summary_loss, roc_auc_scores, ap_scores = self.validation(validation_loader)\n",
    "\n",
    "            self.log(f'[RESULT]: Val. Epoch: {self.epoch}, summary_loss: {summary_loss.avg:.5f}, roc_auc: {roc_auc_scores.avg:.5f}, ap: {ap_scores.avg:.5f}, time: {(time.time() - t):.5f}')\n",
    "            if summary_loss.avg < self.best_loss:\n",
    "                self.best_loss = summary_loss.avg\n",
    "                self.save_model(f'{self.base_dir}/best-loss-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n",
    "                for path in sorted(glob(f'{self.base_dir}/best-loss-checkpoint-*epoch.bin'))[:-2]:\n",
    "                    os.remove(path)\n",
    "                    \n",
    "            if roc_auc_scores.avg > self.best_score:\n",
    "                self.best_score = roc_auc_scores.avg\n",
    "                self.save_model(f'{self.base_dir}/best-score-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n",
    "                for path in sorted(glob(f'{self.base_dir}/best-score-checkpoint-*epoch.bin'))[:-2]:\n",
    "                    os.remove(path)\n",
    "                    \n",
    "            if ap_scores.avg > self.best_ap:\n",
    "                self.best_ap = ap_scores.avg\n",
    "                self.save_model(f'{self.base_dir}/best-ap-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n",
    "                for path in sorted(glob(f'{self.base_dir}/best-ap-checkpoint-*epoch.bin'))[:-2]:\n",
    "                    os.remove(path)\n",
    "\n",
    "            if self.config.validation_scheduler:\n",
    "                self.scheduler.step(metrics=summary_loss.avg)\n",
    "\n",
    "            self.epoch += 1\n",
    "\n",
    "    def validation(self, val_loader):\n",
    "        self.model.eval()\n",
    "        summary_loss = AverageMeter()\n",
    "        roc_auc_scores = RocAucMeter()\n",
    "        ap_scores = APScoreMeter()\n",
    "        t = time.time()\n",
    "        for step, (images, targets) in enumerate(val_loader):\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    print(\n",
    "                        f'Val Step {step}/{len(val_loader)}, ' + \\\n",
    "                        f'summary_loss: {summary_loss.avg:.5f}, roc_auc: {roc_auc_scores.avg:.5f}, ap: {ap_scores.avg:.5f} ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}', end='\\r'\n",
    "                    )\n",
    "            with torch.no_grad():\n",
    "                targets = targets.to(self.device).float()\n",
    "                batch_size = images.shape[0]\n",
    "                images = images.to(self.device).float()\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                roc_auc_scores.update(targets, outputs)\n",
    "                ap_scores.update(targets, outputs)\n",
    "                summary_loss.update(loss.detach().item(), batch_size)\n",
    "\n",
    "        return summary_loss, roc_auc_scores, ap_scores\n",
    "\n",
    "    def train_one_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        summary_loss = AverageMeter()\n",
    "        roc_auc_scores = RocAucMeter()\n",
    "        ap_scores = APScoreMeter()\n",
    "        t = time.time()\n",
    "        for step, (images, targets) in enumerate(train_loader):\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    print(\n",
    "                        f'Train Step {step}/{len(train_loader)}, ' + \\\n",
    "                        f'summary_loss: {summary_loss.avg:.5f}, roc_auc: {roc_auc_scores.avg:.5f}, ap: {ap_scores.avg:.5f} ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}', end='\\r'\n",
    "                    )\n",
    "            \n",
    "            targets = targets.to(self.device).float()\n",
    "            images = images.to(self.device).float()\n",
    "            batch_size = images.shape[0]\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(images)\n",
    "            loss = self.criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            \n",
    "            roc_auc_scores.update(targets, outputs)\n",
    "            ap_scores.update(targets, outputs)\n",
    "            summary_loss.update(loss.detach().item(), batch_size)\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if self.config.step_scheduler:\n",
    "                self.scheduler.step()\n",
    "\n",
    "        return summary_loss, roc_auc_scores, ap_scores\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        self.model.eval()\n",
    "        torch.save(self.model.state_dict(),path)\n",
    "\n",
    "    def save(self, path):\n",
    "        self.model.eval()\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'best_score': self.best_score,\n",
    "            'best_ap': self.best_ap,\n",
    "            'best_loss': self.best_loss,\n",
    "            'epoch': self.epoch,\n",
    "        }, path)\n",
    "\n",
    "    def load(self, path):\n",
    "        checkpoint = torch.load(path)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        self.best_score = checkpoint['best_score']\n",
    "        self.best_ap = checkpoint['best_ap']\n",
    "        self.best_loss = checkpoint['best_loss']\n",
    "        self.epoch = checkpoint['epoch']\n",
    "        \n",
    "    def log(self, message):\n",
    "        if self.config.verbose:\n",
    "            print(message)\n",
    "        with open(self.log_path, 'a+') as logger:\n",
    "            logger.write(f'{message}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainGlobalConfig:\n",
    "    num_workers = 2\n",
    "    batch_size = 8 \n",
    "    n_epochs = 20\n",
    "    lr = 0.00003\n",
    "\n",
    "    # -------------------\n",
    "    verbose = True\n",
    "    verbose_step = 1\n",
    "    # -------------------\n",
    "\n",
    "    # --------------------\n",
    "    step_scheduler = False  # do scheduler.step after optimizer.step\n",
    "    validation_scheduler = True  # do scheduler.step after validation stage loss\n",
    "\n",
    "#     SchedulerClass = torch.optim.lr_scheduler.OneCycleLR\n",
    "#     scheduler_params = dict(\n",
    "#         max_lr=0.001,\n",
    "#         epochs=n_epochs,\n",
    "#         steps_per_epoch=int(len(train_dataset) / batch_size),\n",
    "#         pct_start=0.1,\n",
    "#         anneal_strategy='cos', \n",
    "#         final_div_factor=10**5\n",
    "#     )\n",
    "    \n",
    "    SchedulerClass = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "    scheduler_params = dict(\n",
    "        mode='min',\n",
    "        factor=0.8,\n",
    "        patience=1,\n",
    "        verbose=False, \n",
    "        threshold=0.0001,\n",
    "        threshold_mode='abs',\n",
    "        cooldown=0, \n",
    "        min_lr=1e-8,\n",
    "        eps=1e-08\n",
    "    )\n",
    "    # --------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save all states for \"honest\" training of folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitter prepared. Device is cuda:0\n"
     ]
    }
   ],
   "source": [
    "fitter = Fitter(model=net, device=torch.device('cuda:0'), config=TrainGlobalConfig, folder='base_state')\n",
    "BASE_STATE_PATH = f'{fitter.base_dir}/base_state.bin'\n",
    "fitter.save(BASE_STATE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst.data.sampler import BalanceClassSampler\n",
    "\n",
    "def train_fold(fold_number):\n",
    "\n",
    "    train_dataset = DatasetRetriever(\n",
    "        image_ids=df_folds[df_folds['fold'] != fold_number].index.values,\n",
    "        labels=df_folds[df_folds['fold'] != fold_number].target.values,\n",
    "        transforms=get_train_transforms(),\n",
    "    )\n",
    "\n",
    "    df_val = df_folds[(df_folds['fold'] == fold_number) & (df_folds['source'] == 'ISIC20')]\n",
    "\n",
    "    validation_dataset = DatasetRetriever(\n",
    "        image_ids=df_val.index.values,\n",
    "        labels=df_val.target.values,\n",
    "        transforms=get_valid_transforms(),\n",
    "    )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        sampler=BalanceClassSampler(labels=train_dataset.get_labels(), mode=\"downsampling\"),\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        pin_memory=False,\n",
    "        drop_last=True,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        validation_dataset, \n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "        shuffle=False,\n",
    "        sampler=SequentialSampler(validation_dataset),\n",
    "        pin_memory=False,\n",
    "    )\n",
    "\n",
    "    fitter = Fitter(model=net, device=torch.device('cuda:0'), config=TrainGlobalConfig, folder=f'fold{fold_number}')\n",
    "    fitter.load(BASE_STATE_PATH)\n",
    "    fitter.fit(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitter prepared. Device is cuda:0\n",
      "\n",
      "2020-06-05T05:06:54.833729\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 0, summary_loss: 0.52805, roc_auc: 0.85103, ap: 0.84112, time: 797.09923\n",
      "[RESULT]: Val. Epoch: 0, summary_loss: 0.31345, roc_auc: 0.89614, ap: 0.21135, time: 147.94666\n",
      "\n",
      "2020-06-05T05:22:40.383111\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 1, summary_loss: 0.48091, roc_auc: 0.89080, ap: 0.88059, time: 794.29858\n",
      "[RESULT]: Val. Epoch: 1, summary_loss: 0.29728, roc_auc: 0.92565, ap: 0.27764, time: 147.87266\n",
      "\n",
      "2020-06-05T05:38:23.143641\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 2, summary_loss: 0.46159, roc_auc: 0.90506, ap: 0.89870, time: 795.10489\n",
      "[RESULT]: Val. Epoch: 2, summary_loss: 0.26277, roc_auc: 0.92242, ap: 0.29737, time: 147.70316\n",
      "\n",
      "2020-06-05T05:54:06.319534\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 3, summary_loss: 0.45305, roc_auc: 0.91111, ap: 0.90125, time: 792.95324\n",
      "[RESULT]: Val. Epoch: 3, summary_loss: 0.26828, roc_auc: 0.93312, ap: 0.31940, time: 147.96768\n",
      "\n",
      "2020-06-05T06:09:47.596597\n",
      "LR: 3e-05\n",
      "[RESULT]: Train. Epoch: 4, summary_loss: 0.43363, roc_auc: 0.92394, ap: 0.91717, time: 794.24562\n",
      "[RESULT]: Val. Epoch: 4, summary_loss: 0.26510, roc_auc: 0.93601, ap: 0.31532, time: 147.67352\n",
      "\n",
      "2020-06-05T06:25:29.704667\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 5, summary_loss: 0.41628, roc_auc: 0.93446, ap: 0.92922, time: 795.17649\n",
      "[RESULT]: Val. Epoch: 5, summary_loss: 0.25994, roc_auc: 0.93295, ap: 0.31147, time: 148.69532\n",
      "\n",
      "2020-06-05T06:41:13.763857\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 6, summary_loss: 0.40432, roc_auc: 0.94085, ap: 0.93506, time: 797.24703\n",
      "[RESULT]: Val. Epoch: 6, summary_loss: 0.26895, roc_auc: 0.93694, ap: 0.33459, time: 148.54233\n",
      "\n",
      "2020-06-05T06:56:59.971115\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 7, summary_loss: 0.39235, roc_auc: 0.94711, ap: 0.94114, time: 796.85773\n",
      "[RESULT]: Val. Epoch: 7, summary_loss: 0.25897, roc_auc: 0.93723, ap: 0.36816, time: 148.02976\n",
      "\n",
      "2020-06-05T07:12:45.443739\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 8, summary_loss: 0.38735, roc_auc: 0.94998, ap: 0.94516, time: 797.46006\n",
      "[RESULT]: Val. Epoch: 8, summary_loss: 0.26677, roc_auc: 0.94105, ap: 0.35882, time: 161.11227\n",
      "\n",
      "2020-06-05T07:28:44.231278\n",
      "LR: 2.4e-05\n",
      "[RESULT]: Train. Epoch: 9, summary_loss: 0.38149, roc_auc: 0.95266, ap: 0.94676, time: 799.57385\n",
      "[RESULT]: Val. Epoch: 9, summary_loss: 0.26856, roc_auc: 0.94306, ap: 0.33111, time: 170.06102\n",
      "\n",
      "2020-06-05T07:44:54.106335\n",
      "LR: 1.9200000000000003e-05\n",
      "[RESULT]: Train. Epoch: 10, summary_loss: 0.37175, roc_auc: 0.95776, ap: 0.95388, time: 800.67355\n",
      "[RESULT]: Val. Epoch: 10, summary_loss: 0.25801, roc_auc: 0.93818, ap: 0.38092, time: 149.15346\n",
      "\n",
      "2020-06-05T08:00:44.328658\n",
      "LR: 1.9200000000000003e-05\n",
      "[RESULT]: Train. Epoch: 11, summary_loss: 0.35853, roc_auc: 0.96347, ap: 0.95957, time: 799.41758\n",
      "[RESULT]: Val. Epoch: 11, summary_loss: 0.26780, roc_auc: 0.94272, ap: 0.36878, time: 148.22867\n",
      "\n",
      "2020-06-05T08:16:31.977616\n",
      "LR: 1.9200000000000003e-05\n",
      "[RESULT]: Train. Epoch: 12, summary_loss: 0.36137, roc_auc: 0.96237, ap: 0.95788, time: 798.17402\n",
      "[RESULT]: Val. Epoch: 12, summary_loss: 0.26323, roc_auc: 0.93994, ap: 0.38576, time: 149.07333\n",
      "\n",
      "2020-06-05T08:32:19.415092\n",
      "LR: 1.5360000000000002e-05\n",
      "[RESULT]: Train. Epoch: 13, summary_loss: 0.35227, roc_auc: 0.96536, ap: 0.96027, time: 797.09600\n",
      "[RESULT]: Val. Epoch: 13, summary_loss: 0.26693, roc_auc: 0.94153, ap: 0.35326, time: 148.71052\n",
      "\n",
      "2020-06-05T08:48:05.224288\n",
      "LR: 1.5360000000000002e-05\n",
      "[RESULT]: Train. Epoch: 14, summary_loss: 0.34956, roc_auc: 0.96748, ap: 0.96403, time: 797.72656\n",
      "[RESULT]: Val. Epoch: 14, summary_loss: 0.27423, roc_auc: 0.94300, ap: 0.37154, time: 147.99482\n",
      "\n",
      "2020-06-05T09:03:50.948536\n",
      "LR: 1.2288000000000002e-05\n",
      "[RESULT]: Train. Epoch: 15, summary_loss: 0.33852, roc_auc: 0.97183, ap: 0.96803, time: 798.02887\n",
      "[RESULT]: Val. Epoch: 15, summary_loss: 0.25633, roc_auc: 0.93546, ap: 0.36384, time: 148.07785\n",
      "\n",
      "2020-06-05T09:19:37.250235\n",
      "LR: 1.2288000000000002e-05\n",
      "[RESULT]: Train. Epoch: 16, summary_loss: 0.33604, roc_auc: 0.97249, ap: 0.96840, time: 798.09547\n",
      "[RESULT]: Val. Epoch: 16, summary_loss: 0.26115, roc_auc: 0.94363, ap: 0.36320, time: 170.97372\n",
      "\n",
      "2020-06-05T09:35:46.511084\n",
      "LR: 1.2288000000000002e-05\n",
      "[RESULT]: Train. Epoch: 17, summary_loss: 0.34403, roc_auc: 0.96902, ap: 0.96482, time: 806.47045\n",
      "[RESULT]: Val. Epoch: 17, summary_loss: 0.26363, roc_auc: 0.94441, ap: 0.36227, time: 148.36277\n",
      "\n",
      "2020-06-05T09:51:41.530744\n",
      "LR: 9.830400000000002e-06\n",
      "[RESULT]: Train. Epoch: 18, summary_loss: 0.32816, roc_auc: 0.97491, ap: 0.96916, time: 796.29051\n",
      "[RESULT]: Val. Epoch: 18, summary_loss: 0.25374, roc_auc: 0.92774, ap: 0.33635, time: 148.09658\n",
      "\n",
      "2020-06-05T10:07:26.106473\n",
      "LR: 9.830400000000002e-06\n",
      "[RESULT]: Train. Epoch: 19, summary_loss: 0.32172, roc_auc: 0.97784, ap: 0.97552, time: 794.90660\n",
      "[RESULT]: Val. Epoch: 19, summary_loss: 0.25458, roc_auc: 0.93117, ap: 0.35572, time: 148.32973\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "for fold_number in range(1): # range(5)\n",
    "    train_fold(fold_number=fold_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Thank you for reading my kernel!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0c0da6aad3834b869c238c21643ad5f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "2e70289fdc9443ba96a90eb0ac78b522": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a6a1444972374dbbaf12b30c1dfd0db5",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_f011f5a34b7f469297152a8e019100ba",
       "value": " 117M/117M [00:08&lt;00:00, 14.2MB/s]"
      }
     },
     "413569cc291e40bcbfc560be28e405ee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4e6620b1ba79497bad25a2f95f5bde7a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "690fb41c2e864affb2f696ce44f4fd95": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4e6620b1ba79497bad25a2f95f5bde7a",
       "max": 122410125.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0c0da6aad3834b869c238c21643ad5f8",
       "value": 122410125.0
      }
     },
     "9180054f73f146bba2a972af40548075": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_690fb41c2e864affb2f696ce44f4fd95",
        "IPY_MODEL_2e70289fdc9443ba96a90eb0ac78b522"
       ],
       "layout": "IPY_MODEL_413569cc291e40bcbfc560be28e405ee"
      }
     },
     "a6a1444972374dbbaf12b30c1dfd0db5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f011f5a34b7f469297152a8e019100ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
