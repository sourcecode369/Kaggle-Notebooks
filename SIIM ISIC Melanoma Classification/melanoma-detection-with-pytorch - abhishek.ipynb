{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wtfml\r\n",
      "  Downloading wtfml-0.0.2-py3-none-any.whl (8.1 kB)\r\n",
      "Requirement already satisfied: scikit-learn>=0.22.1 in /opt/conda/lib/python3.7/site-packages (from wtfml) (0.22.2.post1)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.1->wtfml) (0.14.1)\r\n",
      "Requirement already satisfied: numpy>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.1->wtfml) (1.18.1)\r\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.1->wtfml) (1.4.1)\r\n",
      "Installing collected packages: wtfml\r\n",
      "Successfully installed wtfml-0.0.2\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Collecting pretrainedmodels\r\n",
      "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 58 kB 1.9 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (1.5.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (0.6.0a0+82fd1c8)\r\n",
      "Requirement already satisfied: munch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (2.5.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (4.45.0)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels) (0.18.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels) (1.18.1)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->pretrainedmodels) (5.4.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from munch->pretrainedmodels) (1.14.0)\r\n",
      "Building wheels for collected packages: pretrainedmodels\r\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60962 sha256=e380a7b8cfe5abeb8defa0271e4ba0a643da21f521e2c18af97d7f4e82a94dd7\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/ed/27/e8/9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\r\n",
      "Successfully built pretrainedmodels\r\n",
      "Installing collected packages: pretrainedmodels\r\n",
      "Successfully installed pretrainedmodels-0.7.4\r\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install wtfml\n",
    "!pip install pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import albumentations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from wtfml.utils import EarlyStopping\n",
    "from wtfml.engine import Engine\n",
    "from wtfml.data_loaders.image import ClassificationLoader\n",
    "\n",
    "import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEResnext50_32x4d(nn.Module):\n",
    "    def __init__(self, pretrained='imagenet'):\n",
    "        super(SEResnext50_32x4d, self).__init__()\n",
    "        \n",
    "        self.base_model = pretrainedmodels.__dict__[\n",
    "            \"se_resnext50_32x4d\"\n",
    "        ](pretrained=None)\n",
    "        if pretrained is not None:\n",
    "            self.base_model.load_state_dict(\n",
    "                torch.load(\n",
    "                    \"../input/pretrained-model-weights-pytorch/se_resnext50_32x4d-a260b3a4.pth\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.l0 = nn.Linear(2048, 1)\n",
    "    \n",
    "    def forward(self, image, targets):\n",
    "        batch_size, _, _, _ = image.shape\n",
    "        \n",
    "        x = self.base_model.features(image)\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n",
    "        \n",
    "        out = self.l0(x)\n",
    "        loss = nn.BCEWithLogitsLoss()(out, targets.view(-1, 1).type_as(x))\n",
    "\n",
    "        return out, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folds\n",
    "df = pd.read_csv(\"../input/siim-isic-melanoma-classification/train.csv\")\n",
    "df[\"kfold\"] = -1    \n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "y = df.target.values\n",
    "kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "\n",
    "for f, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n",
    "    df.loc[v_, 'kfold'] = f\n",
    "\n",
    "df.to_csv(\"train_folds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(fold):\n",
    "    training_data_path = \"../input/siic-isic-224x224-images/train/\"\n",
    "    df = pd.read_csv(\"/kaggle/working/train_folds.csv\")\n",
    "    device = \"cuda\"\n",
    "    epochs = 50\n",
    "    train_bs = 32\n",
    "    valid_bs = 16\n",
    "\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "    model = SEResnext50_32x4d(pretrained=\"imagenet\")\n",
    "    model.to(device)\n",
    "\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    train_aug = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True),\n",
    "            albumentations.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15),\n",
    "            albumentations.Flip(p=0.5)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    valid_aug = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train_images = df_train.image_name.values.tolist()\n",
    "    train_images = [os.path.join(training_data_path, i + \".png\") for i in train_images]\n",
    "    train_targets = df_train.target.values\n",
    "\n",
    "    valid_images = df_valid.image_name.values.tolist()\n",
    "    valid_images = [os.path.join(training_data_path, i + \".png\") for i in valid_images]\n",
    "    valid_targets = df_valid.target.values\n",
    "\n",
    "    train_dataset = ClassificationLoader(\n",
    "        image_paths=train_images,\n",
    "        targets=train_targets,\n",
    "        resize=None,\n",
    "        augmentations=train_aug,\n",
    "    )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=train_bs, shuffle=True, num_workers=4\n",
    "    )\n",
    "\n",
    "    valid_dataset = ClassificationLoader(\n",
    "        image_paths=valid_images,\n",
    "        targets=valid_targets,\n",
    "        resize=None,\n",
    "        augmentations=valid_aug,\n",
    "    )\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=valid_bs, shuffle=False, num_workers=4\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        patience=3,\n",
    "        threshold=0.001,\n",
    "        mode=\"max\"\n",
    "    )\n",
    "\n",
    "    es = EarlyStopping(patience=5, mode=\"max\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = Engine.train(train_loader, model, optimizer, device=device)\n",
    "        predictions, valid_loss = Engine.evaluate(\n",
    "            valid_loader, model, device=device\n",
    "        )\n",
    "        predictions = np.vstack((predictions)).ravel()\n",
    "        auc = metrics.roc_auc_score(valid_targets, predictions)\n",
    "        print(f\"Epoch = {epoch}, AUC = {auc}\")\n",
    "        scheduler.step(auc)\n",
    "\n",
    "        es(auc, model, model_path=f\"model_fold_{fold}.bin\")\n",
    "        if es.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(fold):\n",
    "    test_data_path = \"../input/siic-isic-224x224-images/test/\"\n",
    "    df = pd.read_csv(\"../input/siim-isic-melanoma-classification/test.csv\")\n",
    "    device = \"cuda\"\n",
    "    model_path=f\"model_fold_{fold}.bin\"\n",
    "\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    aug = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    images = df.image_name.values.tolist()\n",
    "    images = [os.path.join(test_data_path, i + \".png\") for i in images]\n",
    "    targets = np.zeros(len(images))\n",
    "\n",
    "    test_dataset = ClassificationLoader(\n",
    "        image_paths=images,\n",
    "        targets=targets,\n",
    "        resize=None,\n",
    "        augmentations=aug,\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=16, shuffle=False, num_workers=4\n",
    "    )\n",
    "\n",
    "    model = SEResnext50_32x4d(pretrained=None)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "\n",
    "    predictions = Engine.predict(test_loader, model, device=device)\n",
    "    predictions = np.vstack((predictions)).ravel()\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:55<00:00,  2.33it/s, loss=0.0818]\n",
      "100%|██████████| 415/415 [00:34<00:00, 12.03it/s, loss=0.0805]\n",
      "  0%|          | 0/829 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, AUC = 0.8667945632149042\n",
      "Validation score improved (-inf --> 0.8667945632149042). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:54<00:00,  2.34it/s, loss=0.0664]\n",
      "100%|██████████| 415/415 [00:34<00:00, 12.09it/s, loss=0.0777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, AUC = 0.8743764386720293\n",
      "Validation score improved (0.8667945632149042 --> 0.8743764386720293). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:54<00:00,  2.34it/s, loss=0.0617]\n",
      "100%|██████████| 415/415 [00:32<00:00, 12.76it/s, loss=0.0703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2, AUC = 0.8964024828212875\n",
      "Validation score improved (0.8743764386720293 --> 0.8964024828212875). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:53<00:00,  2.34it/s, loss=0.0576]\n",
      "100%|██████████| 415/415 [00:33<00:00, 12.41it/s, loss=0.0732]\n",
      "  0%|          | 0/829 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 3, AUC = 0.8932405229839552\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:53<00:00,  2.35it/s, loss=0.0518]\n",
      "100%|██████████| 415/415 [00:32<00:00, 12.86it/s, loss=0.0786]\n",
      "  0%|          | 0/829 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, AUC = 0.8729648494589345\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:53<00:00,  2.34it/s, loss=0.0483]\n",
      "100%|██████████| 415/415 [00:33<00:00, 12.29it/s, loss=0.076]\n",
      "  0%|          | 0/829 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5, AUC = 0.8866776179727478\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:54<00:00,  2.34it/s, loss=0.0423]\n",
      "100%|██████████| 415/415 [00:32<00:00, 12.73it/s, loss=0.089]\n",
      "  0%|          | 0/829 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 6, AUC = 0.8618113250161185\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:53<00:00,  2.34it/s, loss=0.0524]\n",
      "100%|██████████| 415/415 [00:34<00:00, 12.18it/s, loss=0.068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, AUC = 0.9042333956696563\n",
      "Validation score improved (0.9018030737281536 --> 0.9042333956696563). Saving model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:53<00:00,  2.34it/s, loss=0.0469]\n",
      "100%|██████████| 829/829 [05:54<00:00,  2.34it/s, loss=0.00773]\n",
      "100%|██████████| 829/829 [05:54<00:00,  2.34it/s, loss=0.00529]\n",
      "100%|██████████| 415/415 [00:33<00:00, 12.47it/s, loss=0.133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 16, AUC = 0.9039406974957751\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:54<00:00,  2.34it/s, loss=0.037]\n",
      "100%|██████████| 415/415 [00:32<00:00, 12.61it/s, loss=0.109]\n",
      "  0%|          | 0/829 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 7, AUC = 0.8841071344144485\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:53<00:00,  2.35it/s, loss=0.00793]\n",
      "100%|██████████| 415/415 [00:32<00:00, 12.69it/s, loss=0.144]\n",
      "  0%|          | 0/829 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 14, AUC = 0.8788854217557353\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:53<00:00,  2.35it/s, loss=0.0616]\n",
      "100%|██████████| 829/829 [05:52<00:00,  2.35it/s, loss=0.0518]\n",
      "100%|██████████| 415/415 [00:31<00:00, 13.14it/s, loss=0.0678]\n",
      "  0%|          | 0/829 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4, AUC = 0.8964561696583822\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:53<00:00,  2.35it/s, loss=0.0501]\n",
      "100%|██████████| 829/829 [06:06<00:00,  2.26it/s, loss=0.0298]\n",
      "100%|██████████| 415/415 [00:34<00:00, 12.19it/s, loss=0.0826]\n",
      "  0%|          | 0/829 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 8, AUC = 0.9025000131330801\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 829/829 [05:52<00:00,  2.35it/s, loss=0.0174]\n",
      "100%|██████████| 829/829 [05:53<00:00,  2.35it/s, loss=0.0069]\n",
      "100%|██████████| 415/415 [00:33<00:00, 12.41it/s, loss=0.105]\n",
      "  0%|          | 0/829 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 15, AUC = 0.9006206693668279\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 42/829 [00:18<05:33,  2.36it/s, loss=0.00417]"
     ]
    }
   ],
   "source": [
    "train(0)\n",
    "train(1)\n",
    "train(2)\n",
    "train(3)\n",
    "train(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [00:55<00:00, 12.36it/s]\n",
      "100%|██████████| 687/687 [00:53<00:00, 12.89it/s]\n",
      "100%|██████████| 687/687 [00:53<00:00, 12.90it/s]\n",
      "100%|██████████| 687/687 [00:53<00:00, 12.72it/s]\n",
      "100%|██████████| 687/687 [00:54<00:00, 12.72it/s]\n"
     ]
    }
   ],
   "source": [
    "p1 = predict(0)\n",
    "p2 = predict(1)\n",
    "p3 = predict(2)\n",
    "p4 = predict(3)\n",
    "p5 = predict(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (p1 + p2 + p3 + p4 + p5) / 5\n",
    "sample = pd.read_csv(\"../input/siim-isic-melanoma-classification/sample_submission.csv\")\n",
    "sample.loc[:, \"target\"] = predictions\n",
    "sample.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
