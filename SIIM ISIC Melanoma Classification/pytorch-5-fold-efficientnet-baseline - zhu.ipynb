{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-output": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\r\n",
      "  Downloading timm-0.1.26-py3-none-any.whl (179 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 179 kB 2.9 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.0 in /opt/conda/lib/python3.6/site-packages (from timm) (1.4.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.6/site-packages (from timm) (0.5.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torchvision->timm) (1.18.2)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from torchvision->timm) (1.14.0)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.6/site-packages (from torchvision->timm) (5.4.1)\r\n",
      "Installing collected packages: timm\r\n",
      "Successfully installed timm-0.1.26\r\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import cv2\n",
    "import torch.nn.init as init\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image, ImageFilter\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.optim import Adam, SGD, RMSprop\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "import torch.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "import urllib\n",
    "import pickle\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import seaborn as sns\n",
    "import random\n",
    "import timm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sys\n",
    "sys.path.append('../input/autoaug')\n",
    "from auto_augment import AutoAugment, Cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(2020)\n",
    "num_classes = 2\n",
    "bs = 80\n",
    "lr = 1e-3\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../input/siic-isic-224x224-images/train/'\n",
    "test_path = '../input/siic-isic-224x224-images/test/'\n",
    "train_csv = pd.read_csv('../input/siim-isic-melanoma-classification/train.csv')\n",
    "test_csv = pd.read_csv('../input/siim-isic-melanoma-classification/test.csv')\n",
    "sample = pd.read_csv('../input/siim-isic-melanoma-classification/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_2637011</td>\n",
       "      <td>IP_7279968</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015719</td>\n",
       "      <td>IP_3075186</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0052212</td>\n",
       "      <td>IP_2842074</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>nevus</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0068279</td>\n",
       "      <td>IP_6890425</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0074268</td>\n",
       "      <td>IP_8723313</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n",
       "0  ISIC_2637011  IP_7279968    male        45.0                     head/neck   \n",
       "1  ISIC_0015719  IP_3075186  female        45.0               upper extremity   \n",
       "2  ISIC_0052212  IP_2842074  female        50.0               lower extremity   \n",
       "3  ISIC_0068279  IP_6890425  female        45.0                     head/neck   \n",
       "4  ISIC_0074268  IP_8723313  female        55.0               upper extremity   \n",
       "\n",
       "  diagnosis benign_malignant  target  \n",
       "0   unknown           benign       0  \n",
       "1   unknown           benign       0  \n",
       "2     nevus           benign       0  \n",
       "3   unknown           benign       0  \n",
       "4   unknown           benign       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, transform=None, test=False):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "        self.test = test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        label = self.df.target.values[idx]\n",
    "        p = self.df.image_name.values[idx]\n",
    "        \n",
    "        if self.test == False:\n",
    "            p_path = train_path + p + '.png'\n",
    "        else:\n",
    "            p_path = test_path + p + '.png'\n",
    "            \n",
    "        image = cv2.imread(p_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#         image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "        image = transforms.ToPILImage()(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    AutoAugment(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "testset      = MyDataset(sample, transform=test_transform, test=True)\n",
    "test_loader  = torch.utils.data.DataLoader(testset, batch_size=bs, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epoch):\n",
    "    model.train() \n",
    "    \n",
    "    losses = AverageMeter()\n",
    "    avg_loss = 0.\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    tk = tqdm(train_loader, total=len(train_loader), position=0, leave=True)\n",
    "    for idx, (imgs, labels) in enumerate(tk):\n",
    "        imgs_train, labels_train = imgs.cuda(), labels.cuda().long()\n",
    "        output_train = model(imgs_train)\n",
    "\n",
    "        loss = criterion(output_train, labels_train)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step() \n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "        \n",
    "        losses.update(loss.item(), imgs_train.size(0))\n",
    "\n",
    "        tk.set_postfix(loss=losses.avg)\n",
    "        \n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def test_model(model):    \n",
    "    model.eval()\n",
    "    \n",
    "    losses = AverageMeter()\n",
    "    avg_val_loss = 0.\n",
    "    \n",
    "    valid_preds, valid_targets = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        tk = tqdm(val_loader, total=len(val_loader), position=0, leave=True)\n",
    "        for idx, (imgs, labels) in enumerate(tk):\n",
    "            imgs_valid, labels_valid = imgs.cuda(), labels.cuda().long()\n",
    "            output_valid = model(imgs_valid)\n",
    "            \n",
    "            loss = criterion(output_valid, labels_valid)\n",
    "            \n",
    "            avg_val_loss += loss.item() / len(val_loader)\n",
    "\n",
    "            losses.update(loss.item(), imgs_valid.size(0))\n",
    "            \n",
    "            tk.set_postfix(loss=losses.avg)\n",
    "            \n",
    "            valid_preds.append(torch.softmax(output_valid,1)[:,1].detach().cpu().numpy())\n",
    "            valid_targets.append(labels_valid.detach().cpu().numpy())\n",
    "            \n",
    "        valid_preds = np.concatenate(valid_preds)\n",
    "        valid_targets = np.concatenate(valid_targets)\n",
    "        auc =  roc_auc_score(valid_targets, valid_preds) \n",
    "            \n",
    "    return avg_val_loss, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(5, shuffle=True, random_state=0)\n",
    "\n",
    "cv = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b2_ns-00306e48.pth\" to /root/.cache/torch/checkpoints/tf_efficientnet_b2_ns-00306e48.pth\n",
      "100%|██████████| 332/332 [03:45<00:00,  1.47it/s, loss=0.145]\n",
      "100%|██████████| 83/83 [00:23<00:00,  3.56it/s, loss=0.142]\n",
      "  0%|          | 0/332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_val_auc: 0.7608006271395424 best_val_auc: 0.7608006271395424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:44<00:00,  1.48it/s, loss=0.109]\n",
      "100%|██████████| 83/83 [00:20<00:00,  4.03it/s, loss=0.0927]\n",
      "  0%|          | 0/332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_val_auc: 0.7823119336408628 best_val_auc: 0.7823119336408628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:33<00:00,  1.55it/s, loss=0.0802]\n",
      "100%|██████████| 83/83 [00:20<00:00,  3.97it/s, loss=0.0712]\n",
      "  0%|          | 0/332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_val_auc: 0.859453642753689 best_val_auc: 0.859453642753689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:33<00:00,  1.55it/s, loss=0.0813]\n",
      "100%|██████████| 83/83 [00:21<00:00,  3.93it/s, loss=0.0762]\n",
      "  0%|          | 0/332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_val_auc: 0.8613779999553545 best_val_auc: 0.8613779999553545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:31<00:00,  1.57it/s, loss=0.075]\n",
      "100%|██████████| 83/83 [00:22<00:00,  3.75it/s, loss=0.0688]\n",
      "  0%|          | 0/332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_val_auc: 0.8691778510491063 best_val_auc: 0.8691778510491063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:32<00:00,  1.56it/s, loss=0.0736]\n",
      "100%|██████████| 83/83 [00:22<00:00,  3.71it/s, loss=0.0684]\n",
      "  0%|          | 0/332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_val_auc: 0.8752627853872285 best_val_auc: 0.8752627853872285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:31<00:00,  1.57it/s, loss=0.0716]\n",
      "100%|██████████| 83/83 [00:21<00:00,  3.78it/s, loss=0.0669]\n",
      "  0%|          | 0/332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_val_auc: 0.8781424273819418 best_val_auc: 0.8781424273819418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:58<00:00,  1.39it/s, loss=0.0713]\n",
      "100%|██████████| 83/83 [00:21<00:00,  3.95it/s, loss=0.0682]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_val_auc: 0.8758379259224243 best_val_auc: 0.8781424273819418\n",
      "fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:39<00:00,  1.52it/s, loss=0.131]\n",
      "100%|██████████| 83/83 [00:21<00:00,  3.83it/s, loss=0.0721]\n",
      "  0%|          | 0/332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_val_auc: 0.864548291225412 best_val_auc: 0.864548291225412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:31<00:00,  1.57it/s, loss=0.0841]\n",
      "100%|██████████| 83/83 [00:21<00:00,  3.85it/s, loss=0.0731]\n",
      "  0%|          | 0/332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_val_auc: 0.8649495923416385 best_val_auc: 0.8649495923416385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:33<00:00,  1.55it/s, loss=0.132]\n",
      "100%|██████████| 83/83 [00:21<00:00,  3.86it/s, loss=1.41]\n",
      "  0%|          | 0/332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_val_auc: 0.7040788351407335 best_val_auc: 0.8649495923416385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:30<00:00,  1.58it/s, loss=0.0877]\n",
      "100%|██████████| 83/83 [00:22<00:00,  3.76it/s, loss=0.0742]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:31<00:00,  1.57it/s, loss=0.131]\n",
      "100%|██████████| 83/83 [00:21<00:00,  3.82it/s, loss=0.0778]\n",
      "  0%|          | 0/332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_val_auc: 0.820852967288124 best_val_auc: 0.820852967288124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:32<00:00,  1.56it/s, loss=0.116]\n",
      "100%|██████████| 83/83 [00:21<00:00,  3.89it/s, loss=0.0763]\n",
      "  0%|          | 0/332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_val_auc: 0.8261968175920235 best_val_auc: 0.8261968175920235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:31<00:00,  1.57it/s, loss=0.0802]\n",
      "100%|██████████| 83/83 [00:20<00:00,  4.07it/s, loss=0.0716]\n",
      "  0%|          | 0/332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_val_auc: 0.8525470295599368 best_val_auc: 0.8525470295599368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:29<00:00,  1.59it/s, loss=0.0762]\n",
      "100%|██████████| 83/83 [00:20<00:00,  4.08it/s, loss=0.0695]\n",
      "  0%|          | 0/332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_val_auc: 0.8671457614297196 best_val_auc: 0.8671457614297196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:29<00:00,  1.58it/s, loss=0.0745]\n",
      "100%|██████████| 83/83 [00:20<00:00,  4.09it/s, loss=0.0699]\n",
      "  0%|          | 0/332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_val_auc: 0.861770391733514 best_val_auc: 0.8671457614297196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:28<00:00,  1.59it/s, loss=0.0734]\n",
      "100%|██████████| 83/83 [00:21<00:00,  3.90it/s, loss=0.0695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:28<00:00,  1.59it/s, loss=0.14]\n",
      "100%|██████████| 83/83 [00:21<00:00,  3.79it/s, loss=0.0757]\n",
      "  0%|          | 0/332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_val_auc: 0.8193426630734559 best_val_auc: 0.8193426630734559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:29<00:00,  1.59it/s, loss=0.0781]\n",
      "100%|██████████| 83/83 [00:21<00:00,  3.92it/s, loss=0.0823]\n",
      "  0%|          | 0/332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_val_auc: 0.8403739775897121 best_val_auc: 0.8403739775897121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:34<00:00,  1.55it/s, loss=0.0715]\n",
      "100%|██████████| 83/83 [00:21<00:00,  3.89it/s, loss=0.0729]\n",
      "  0%|          | 0/332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_val_auc: 0.8530500265288218 best_val_auc: 0.8530500265288218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:29<00:00,  1.59it/s, loss=0.069]\n",
      "100%|██████████| 83/83 [00:20<00:00,  4.06it/s, loss=0.0756]\n",
      "  0%|          | 0/332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_val_auc: 0.8506085869331105 best_val_auc: 0.8530500265288218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:28<00:00,  1.59it/s, loss=0.0671]\n",
      "100%|██████████| 83/83 [00:20<00:00,  4.13it/s, loss=0.0713]\n",
      "  0%|          | 0/332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_val_auc: 0.8630219742696693 best_val_auc: 0.8630219742696693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:29<00:00,  1.59it/s, loss=0.0643]\n",
      "100%|██████████| 332/332 [03:48<00:00,  1.45it/s, loss=0.0657]\n",
      "100%|██████████| 83/83 [00:21<00:00,  3.82it/s, loss=0.0687]\n",
      "  0%|          | 0/332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_val_auc: 0.8986664670438488 best_val_auc: 0.904037896816016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:31<00:00,  1.57it/s, loss=0.0587]\n",
      "100%|██████████| 83/83 [00:22<00:00,  3.76it/s, loss=0.0649]\n",
      "  0%|          | 0/332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_val_auc: 0.9076179744587858 best_val_auc: 0.9076179744587858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [03:32<00:00,  1.57it/s, loss=0.0538]\n",
      "100%|██████████| 83/83 [00:21<00:00,  3.78it/s, loss=0.0688]\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "\n",
    "for trn_ind, val_ind in kf.split(train_csv.image_name, train_csv.target):\n",
    "    fold += 1\n",
    "    print('fold:', fold)\n",
    "\n",
    "    train_df = train_csv.loc[trn_ind]\n",
    "    val_df = train_csv.loc[val_ind]\n",
    "    train_df.reset_index(drop=True, inplace=True)\n",
    "    val_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    trainset = MyDataset(train_df, transform=train_transform)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=4)\n",
    "   \n",
    "    valset = MyDataset(val_df, transform=test_transform)\n",
    "    val_loader = torch.utils.data.DataLoader(valset, batch_size=bs, shuffle=False, num_workers=4)\n",
    "\n",
    "    model = timm.create_model('tf_efficientnet_b2_ns', pretrained=True, num_classes=num_classes)\n",
    "    model.cuda()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.3)\n",
    "\n",
    "    best_auc = 0\n",
    "    n_epochs = 8\n",
    "    es = 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        avg_loss = train_model(model, epoch)\n",
    "        avg_val_loss, auc = test_model(model)\n",
    "\n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            torch.save(model.state_dict(), str(fold) + 'weight.pt')\n",
    "        else:\n",
    "            es += 1\n",
    "            if es > 1:\n",
    "                break\n",
    "        print('current_val_auc:', auc, 'best_val_auc:', best_auc)\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "    cv.append(best_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8781424273819418, 0.8649495923416385, 0.8671457614297196, 0.8714218923192493, 0.9076179744587858]\n"
     ]
    }
   ],
   "source": [
    "print(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = timm.create_model('tf_efficientnet_b2_ns', pretrained=True, num_classes=num_classes)\n",
    "model1.cuda()\n",
    "model1.load_state_dict(torch.load(\"./1weight.pt\"))\n",
    "\n",
    "model2 = timm.create_model('tf_efficientnet_b2_ns', pretrained=True, num_classes=num_classes)\n",
    "model2.cuda()\n",
    "model2.load_state_dict(torch.load(\"./2weight.pt\"))\n",
    "\n",
    "model3 = timm.create_model('tf_efficientnet_b2_ns', pretrained=True, num_classes=num_classes)\n",
    "model3.cuda()\n",
    "model3.load_state_dict(torch.load(\"./3weight.pt\"))\n",
    "\n",
    "model4 = timm.create_model('tf_efficientnet_b2_ns', pretrained=True, num_classes=num_classes)\n",
    "model4.cuda()\n",
    "model4.load_state_dict(torch.load(\"./4weight.pt\"))\n",
    "\n",
    "model5 = timm.create_model('tf_efficientnet_b2_ns', pretrained=True, num_classes=num_classes)\n",
    "model5.cuda()\n",
    "model5.load_state_dict(torch.load(\"./5weight.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (conv_stem): Conv2dSame(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): Swish()\n",
       "  (blocks): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Swish()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): Swish()\n",
       "          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Identity()\n",
       "      )\n",
       "      (1): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Swish()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): Swish()\n",
       "          (conv_expand): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Swish()\n",
       "        (conv_dw): Conv2dSame(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "        (bn2): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Swish()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): Swish()\n",
       "          (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Swish()\n",
       "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Swish()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): Swish()\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Swish()\n",
       "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Swish()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): Swish()\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Swish()\n",
       "        (conv_dw): Conv2dSame(144, 144, kernel_size=(5, 5), stride=(2, 2), groups=144, bias=False)\n",
       "        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Swish()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): Swish()\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Swish()\n",
       "        (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "        (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Swish()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): Swish()\n",
       "          (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Swish()\n",
       "        (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "        (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Swish()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): Swish()\n",
       "          (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Swish()\n",
       "        (conv_dw): Conv2dSame(288, 288, kernel_size=(3, 3), stride=(2, 2), groups=288, bias=False)\n",
       "        (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Swish()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): Swish()\n",
       "          (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Swish()\n",
       "        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
       "        (bn2): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Swish()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): Swish()\n",
       "          (conv_expand): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Swish()\n",
       "        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
       "        (bn2): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Swish()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): Swish()\n",
       "          (conv_expand): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Swish()\n",
       "        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
       "        (bn2): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Swish()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): Swish()\n",
       "          (conv_expand): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Swish()\n",
       "        (conv_dw): Conv2d(528, 528, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=528, bias=False)\n",
       "        (bn2): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Swish()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): Swish()\n",
       "          (conv_expand): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(528, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Swish()\n",
       "        (conv_dw): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
       "        (bn2): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Swish()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): Swish()\n",
       "          (conv_expand): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Swish()\n",
       "        (conv_dw): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
       "        (bn2): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Swish()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): Swish()\n",
       "          (conv_expand): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Swish()\n",
       "        (conv_dw): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
       "        (bn2): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Swish()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): Swish()\n",
       "          (conv_expand): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Swish()\n",
       "        (conv_dw): Conv2dSame(720, 720, kernel_size=(5, 5), stride=(2, 2), groups=720, bias=False)\n",
       "        (bn2): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Swish()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): Swish()\n",
       "          (conv_expand): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(720, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Swish()\n",
       "        (conv_dw): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "        (bn2): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Swish()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): Swish()\n",
       "          (conv_expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Swish()\n",
       "        (conv_dw): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "        (bn2): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Swish()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): Swish()\n",
       "          (conv_expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Swish()\n",
       "        (conv_dw): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "        (bn2): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Swish()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): Swish()\n",
       "          (conv_expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv_pw): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Swish()\n",
       "        (conv_dw): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "        (bn2): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Swish()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): Swish()\n",
       "          (conv_expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Swish()\n",
       "        (conv_dw): Conv2d(1248, 1248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1248, bias=False)\n",
       "        (bn2): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Swish()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): Swish()\n",
       "          (conv_expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1248, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(352, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(352, 2112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(2112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): Swish()\n",
       "        (conv_dw): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2112, bias=False)\n",
       "        (bn2): BatchNorm2d(2112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Swish()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(2112, 88, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): Swish()\n",
       "          (conv_expand): Conv2d(88, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(2112, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(352, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_head): Conv2d(352, 1408, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(1408, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act2): Swish()\n",
       "  (global_pool): SelectAdaptivePool2d (output_size=1, pool_type=avg)\n",
       "  (classifier): Linear(in_features=1408, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.eval()\n",
    "model2.eval()\n",
    "model3.eval()\n",
    "model4.eval()\n",
    "model5.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [04:24<00:00,  1.92s/it]\n"
     ]
    }
   ],
   "source": [
    "test_pred = np.zeros((len(sample),))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(tqdm(test_loader, position=0, leave=True)):\n",
    "        images, _ = data\n",
    "        images = images.cuda()\n",
    "        \n",
    "        pred = (model1(images) + model2(images) + model3(images) + model4(images) + model5(images)) \\\n",
    "             + (model1(images) + model2(images) + model3(images) + model4(images) + model5(images)) \\\n",
    "             + (model1(images) + model2(images) + model3(images) + model4(images) + model5(images)) \\\n",
    "             + (model1(images) + model2(images) + model3(images) + model4(images) + model5(images)) \n",
    "        \n",
    "        pred = torch.softmax(pred,1).cpu().detach().numpy()[:,1]\n",
    "    \n",
    "        test_pred[i*bs: (i+1)*bs] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 8.75042687e-36 3.23384653e-40 1.40129846e-45 3.98195914e-39\n",
      " 4.47420833e-37 8.65362058e-38]\n"
     ]
    }
   ],
   "source": [
    "print(test_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.target = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
