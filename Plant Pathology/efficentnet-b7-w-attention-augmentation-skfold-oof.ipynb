{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting iterative-stratification\r\n",
      "  Downloading iterative_stratification-0.1.6-py3-none-any.whl (8.7 kB)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from iterative-stratification) (1.4.1)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from iterative-stratification) (0.22.2.post1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from iterative-stratification) (1.18.2)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->iterative-stratification) (0.14.1)\r\n",
      "Installing collected packages: iterative-stratification\r\n",
      "Successfully installed iterative-stratification-0.1.6\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q efficientnet\n",
    "!pip install iterative-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.57 s, sys: 827 ms, total: 4.39 s\n",
      "Wall time: 10.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import math, re, os, gc, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "import tensorflow as tf \n",
    "import tensorflow_hub as hub\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.applications as app \n",
    "import efficientnet.tfkeras as efn\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "GCS_DS_PATH = KaggleDatasets().get_gcs_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "BATCH_SIZE = 16*strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_path(st):\n",
    "    return GCS_DS_PATH + '/images/' + st + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/plant-pathology-2020-fgvc7/train.csv')\n",
    "test = pd.read_csv('../input/plant-pathology-2020-fgvc7/test.csv')\n",
    "sample_submission = pd.read_csv('../input/plant-pathology-2020-fgvc7/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = train.image_id.apply(format_path).values\n",
    "test_paths = test.image_id.apply(format_path).values\n",
    "train_labels = train.loc[:, \"healthy\":].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(filename, label=None, image_size=(300,300)):\n",
    "    bits = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(bits, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label\n",
    "    \n",
    "def data_augment(image, label=None):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 310, 310)\n",
    "    image = tf.image.random_crop(image, size=[300, 300, 3])\n",
    "    image = tf.image.random_brightness(image, max_delta=0.5)\n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(train_paths, train_labels, valid_paths, valid_labels):\n",
    "    train_dataset = (\n",
    "                    tf.data.Dataset\n",
    "                    .from_tensor_slices((train_paths, train_labels))\n",
    "                    .map(decode_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "                    .cache()\n",
    "                    .map(data_augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "                    .repeat()\n",
    "                    .shuffle(512)\n",
    "                    .batch(BATCH_SIZE)\n",
    "                    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "                    )\n",
    "\n",
    "    valid_dataset = (\n",
    "                    tf.data.Dataset\n",
    "                    .from_tensor_slices((valid_paths, valid_labels))\n",
    "                    .map(decode_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "                    .cache()\n",
    "                    .batch(64)\n",
    "                    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "                    )\n",
    "    return train_dataset, valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = (\n",
    "                tf.data.Dataset\n",
    "                .from_tensor_slices((test_paths))\n",
    "                .map(decode_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "                .cache()\n",
    "                .batch(BATCH_SIZE)\n",
    "                .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficient Net B7 with Visual Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_efficientnet_attention(image_batch):\n",
    "    with strategy.scope():\n",
    "        # input layer\n",
    "        in_lay = L.Input(image_batch.shape[1:])\n",
    "\n",
    "        # pretrained model\n",
    "        base_pretrained_model = efn.EfficientNetB7(input_shape=(720,720,3),weights='imagenet',include_top=False)\n",
    "        base_pretrained_model.trainable = False\n",
    "        pt_depth = base_pretrained_model.get_output_shape_at(0)[-1]\n",
    "        pt_features = base_pretrained_model(in_lay)\n",
    "\n",
    "        #batch normalization layer\n",
    "        bn_features = L.BatchNormalization()(pt_features)\n",
    "\n",
    "        #attention layer\n",
    "        attn_layer = L.Conv2D(128, kernel_size = (1,1), padding = 'same', activation = 'relu')(bn_features)\n",
    "        attn_layer = L.Conv2D(64, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n",
    "        attn_layer = L.Conv2D(1, kernel_size = (1,1), padding = 'valid', activation = 'sigmoid')(attn_layer)\n",
    "        up_c2_w = np.ones((1, 1, 1, pt_depth))\n",
    "        up_c2 = L.Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', activation = 'linear', use_bias = False, weights = [up_c2_w])\n",
    "        up_c2.trainable = False\n",
    "        attn_layer = up_c2(attn_layer)\n",
    "\n",
    "        #global average pooling layers\n",
    "        mask_features = L.multiply([attn_layer, bn_features])\n",
    "        gap_features = L.GlobalAveragePooling2D()(mask_features)\n",
    "        gap_mask = L.GlobalAveragePooling2D()(attn_layer)\n",
    "\n",
    "        # to account for missing values from the attention model\n",
    "        gap = L.Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\n",
    "        gap_dr = L.Dropout(0.4)(gap)\n",
    "\n",
    "        #final layers\n",
    "        dr_steps = L.Dropout(0.4)(L.Dense(1024, activation = 'elu')(gap_dr))\n",
    "        out_layer = L.Dense(train_labels.shape[1], activation = 'softmax')(dr_steps)\n",
    "        model = tf.keras.models.Model(inputs = [in_lay], outputs = [out_layer])\n",
    "\n",
    "        model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficient Net B7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    with strategy.scope():\n",
    "        model = tf.keras.Sequential([\n",
    "            efn.EfficientNetB7(\n",
    "                input_shape=(300, 300, 3),\n",
    "                weights='imagenet',\n",
    "                include_top=False\n",
    "            ),\n",
    "            L.GlobalAveragePooling2D(),\n",
    "            L.Dense(train_labels.shape[1], activation='softmax')\n",
    "        ])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss = 'categorical_crossentropy',\n",
    "            metrics=['categorical_accuracy']\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lrfn(lr_start=0.00001, lr_max=0.000075, \n",
    "               lr_min=0.000001, lr_rampup_epochs=20, \n",
    "               lr_sustain_epochs=0, lr_exp_decay=.8):\n",
    "    lr_max = lr_max * strategy.num_replicas_in_sync\n",
    "\n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_rampup_epochs:\n",
    "            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n",
    "        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n",
    "            lr = lr_max\n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n",
    "        return lr\n",
    "    \n",
    "    return lrfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrfn = build_lrfn()\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\n",
    "STEPS_PER_EPOCH = train_labels.shape[0] // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 1/5\n",
      "Creating Dataset ..\n",
      "Done.!\n",
      "Training Mode ..\n",
      "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b7_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
      "258441216/258434480 [==============================] - 9s 0us/step\n",
      "Train for 14 steps, validate for 6 steps\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/30\n",
      "14/14 [==============================] - 323s 23s/step - loss: 1.3808 - categorical_accuracy: 0.2829 - val_loss: 1.3884 - val_categorical_accuracy: 0.2665\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 3.95e-05.\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 7s 479ms/step - loss: 1.2915 - categorical_accuracy: 0.4911 - val_loss: 1.3090 - val_categorical_accuracy: 0.4176\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 6.9e-05.\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 7s 477ms/step - loss: 1.0163 - categorical_accuracy: 0.7461 - val_loss: 0.8909 - val_categorical_accuracy: 0.7555\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 9.849999999999998e-05.\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 7s 477ms/step - loss: 0.4870 - categorical_accuracy: 0.8616 - val_loss: 0.5606 - val_categorical_accuracy: 0.8352\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.000128.\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 7s 476ms/step - loss: 0.3240 - categorical_accuracy: 0.9029 - val_loss: 0.4236 - val_categorical_accuracy: 0.8846\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.00015749999999999998.\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 7s 477ms/step - loss: 0.2432 - categorical_accuracy: 0.9180 - val_loss: 0.3646 - val_categorical_accuracy: 0.8764\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.00018699999999999996.\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 7s 471ms/step - loss: 0.1806 - categorical_accuracy: 0.9453 - val_loss: 0.3345 - val_categorical_accuracy: 0.8956\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.00021649999999999998.\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 7s 480ms/step - loss: 0.1328 - categorical_accuracy: 0.9581 - val_loss: 0.2587 - val_categorical_accuracy: 0.9231\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00024599999999999996.\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 7s 483ms/step - loss: 0.1139 - categorical_accuracy: 0.9671 - val_loss: 0.3164 - val_categorical_accuracy: 0.9038\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0002755.\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 7s 480ms/step - loss: 0.1016 - categorical_accuracy: 0.9643 - val_loss: 0.3099 - val_categorical_accuracy: 0.9176\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.000305.\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 7s 481ms/step - loss: 0.0854 - categorical_accuracy: 0.9715 - val_loss: 0.2848 - val_categorical_accuracy: 0.9313\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0003345.\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 7s 476ms/step - loss: 0.0810 - categorical_accuracy: 0.9771 - val_loss: 0.3337 - val_categorical_accuracy: 0.9313\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.00036399999999999996.\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 7s 481ms/step - loss: 0.0771 - categorical_accuracy: 0.9766 - val_loss: 0.2899 - val_categorical_accuracy: 0.9341\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.00039349999999999997.\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 7s 479ms/step - loss: 0.0830 - categorical_accuracy: 0.9727 - val_loss: 0.2787 - val_categorical_accuracy: 0.9423\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.000423.\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 7s 478ms/step - loss: 0.0667 - categorical_accuracy: 0.9799 - val_loss: 0.3632 - val_categorical_accuracy: 0.9396\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.00045249999999999994.\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 7s 480ms/step - loss: 0.0680 - categorical_accuracy: 0.9777 - val_loss: 0.8221 - val_categorical_accuracy: 0.9011\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.00048199999999999995.\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 7s 486ms/step - loss: 0.0685 - categorical_accuracy: 0.9777 - val_loss: 0.4857 - val_categorical_accuracy: 0.9423\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0005114999999999999.\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 7s 475ms/step - loss: 0.0731 - categorical_accuracy: 0.9754 - val_loss: 0.4953 - val_categorical_accuracy: 0.9313\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0005409999999999999.\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 7s 482ms/step - loss: 0.0838 - categorical_accuracy: 0.9749 - val_loss: 0.4051 - val_categorical_accuracy: 0.9368\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.0005704999999999999.\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 7s 478ms/step - loss: 0.0690 - categorical_accuracy: 0.9788 - val_loss: 0.7068 - val_categorical_accuracy: 0.9093\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.0006.\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 7s 480ms/step - loss: 0.0821 - categorical_accuracy: 0.9743 - val_loss: 0.3855 - val_categorical_accuracy: 0.9396\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.00048019999999999996.\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 7s 481ms/step - loss: 0.0533 - categorical_accuracy: 0.9816 - val_loss: 0.4142 - val_categorical_accuracy: 0.9341\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.00038436000000000004.\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 7s 478ms/step - loss: 0.0490 - categorical_accuracy: 0.9844 - val_loss: 0.6947 - val_categorical_accuracy: 0.8956\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.0003076880000000001.\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 7s 480ms/step - loss: 0.0419 - categorical_accuracy: 0.9855 - val_loss: 0.4991 - val_categorical_accuracy: 0.9093\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.0002463504.\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 7s 476ms/step - loss: 0.0343 - categorical_accuracy: 0.9911 - val_loss: 0.3673 - val_categorical_accuracy: 0.9313\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.00019728032000000003.\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 7s 477ms/step - loss: 0.0235 - categorical_accuracy: 0.9933 - val_loss: 0.2711 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.00015802425600000002.\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 7s 479ms/step - loss: 0.0138 - categorical_accuracy: 0.9967 - val_loss: 0.2763 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.0001266194048.\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 7s 475ms/step - loss: 0.0212 - categorical_accuracy: 0.9927 - val_loss: 0.2716 - val_categorical_accuracy: 0.9533\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.00010149552384000004.\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 7s 480ms/step - loss: 0.0108 - categorical_accuracy: 0.9967 - val_loss: 0.2678 - val_categorical_accuracy: 0.9505\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 8.139641907200002e-05.\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 7s 476ms/step - loss: 0.0115 - categorical_accuracy: 0.9972 - val_loss: 0.2763 - val_categorical_accuracy: 0.9505\n",
      "Evaluation Mode ..\n",
      "6/6 [==============================] - 22s 4s/step - loss: 0.2763 - categorical_accuracy: 0.9505\n",
      "[0.27634915336966515, 0.9505495]\n",
      "Finetuning Mode ..\n",
      "Train for 14 steps, validate for 6 steps\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 8.139641907200002e-05.\n",
      "Epoch 30/45\n",
      "14/14 [==============================] - 177s 13s/step - loss: 0.0142 - categorical_accuracy: 0.9955 - val_loss: 0.2724 - val_categorical_accuracy: 0.9478\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 6.531713525760003e-05.\n",
      "Epoch 31/45\n",
      "14/14 [==============================] - 4s 275ms/step - loss: 0.0081 - categorical_accuracy: 0.9978 - val_loss: 0.2621 - val_categorical_accuracy: 0.9451\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 5.2453708206080024e-05.\n",
      "Epoch 32/45\n",
      "14/14 [==============================] - 4s 279ms/step - loss: 0.0155 - categorical_accuracy: 0.9944 - val_loss: 0.2512 - val_categorical_accuracy: 0.9505\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 4.2162966564864016e-05.\n",
      "Epoch 33/45\n",
      "14/14 [==============================] - 4s 269ms/step - loss: 0.0089 - categorical_accuracy: 0.9972 - val_loss: 0.2483 - val_categorical_accuracy: 0.9505\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 3.3930373251891216e-05.\n",
      "Epoch 34/45\n",
      "14/14 [==============================] - 4s 282ms/step - loss: 0.0117 - categorical_accuracy: 0.9967 - val_loss: 0.2496 - val_categorical_accuracy: 0.9505\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 2.734429860151298e-05.\n",
      "Epoch 35/45\n",
      "14/14 [==============================] - 4s 271ms/step - loss: 0.0067 - categorical_accuracy: 0.9972 - val_loss: 0.2475 - val_categorical_accuracy: 0.9533\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 2.2075438881210384e-05.\n",
      "Epoch 36/45\n",
      "14/14 [==============================] - 4s 271ms/step - loss: 0.0047 - categorical_accuracy: 0.9994 - val_loss: 0.2445 - val_categorical_accuracy: 0.9533\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 1.7860351104968306e-05.\n",
      "Epoch 37/45\n",
      "14/14 [==============================] - 4s 273ms/step - loss: 0.0065 - categorical_accuracy: 0.9967 - val_loss: 0.2451 - val_categorical_accuracy: 0.9533\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 1.4488280883974648e-05.\n",
      "Epoch 38/45\n",
      "14/14 [==============================] - 4s 271ms/step - loss: 0.0053 - categorical_accuracy: 0.9989 - val_loss: 0.2424 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 1.179062470717972e-05.\n",
      "Epoch 39/45\n",
      "14/14 [==============================] - 4s 270ms/step - loss: 0.0063 - categorical_accuracy: 0.9972 - val_loss: 0.2366 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 9.632499765743775e-06.\n",
      "Epoch 40/45\n",
      "14/14 [==============================] - 4s 276ms/step - loss: 0.0082 - categorical_accuracy: 0.9967 - val_loss: 0.2358 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 7.905999812595021e-06.\n",
      "Epoch 41/45\n",
      "14/14 [==============================] - 4s 278ms/step - loss: 0.0096 - categorical_accuracy: 0.9961 - val_loss: 0.2330 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 6.524799850076017e-06.\n",
      "Epoch 42/45\n",
      "14/14 [==============================] - 4s 284ms/step - loss: 0.0123 - categorical_accuracy: 0.9955 - val_loss: 0.2322 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 5.419839880060813e-06.\n",
      "Epoch 43/45\n",
      "14/14 [==============================] - 4s 278ms/step - loss: 0.0101 - categorical_accuracy: 0.9967 - val_loss: 0.2321 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 4.535871904048651e-06.\n",
      "Epoch 44/45\n",
      "14/14 [==============================] - 4s 278ms/step - loss: 0.0064 - categorical_accuracy: 0.9967 - val_loss: 0.2304 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 3.828697523238921e-06.\n",
      "Epoch 45/45\n",
      "14/14 [==============================] - 4s 280ms/step - loss: 0.0063 - categorical_accuracy: 0.9978 - val_loss: 0.2300 - val_categorical_accuracy: 0.9560\n",
      "Evaluation Mode ..\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.2300 - categorical_accuracy: 0.9560\n",
      "[0.2299932607760032, 0.95604396]\n",
      "Fold - 2/5\n",
      "Creating Dataset ..\n",
      "Done.!\n",
      "Training Mode ..\n",
      "Train for 14 steps, validate for 6 steps\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/30\n",
      "14/14 [==============================] - 269s 19s/step - loss: 1.3719 - categorical_accuracy: 0.3214 - val_loss: 1.3504 - val_categorical_accuracy: 0.2830\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 3.95e-05.\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 7s 483ms/step - loss: 1.2871 - categorical_accuracy: 0.4950 - val_loss: 1.2558 - val_categorical_accuracy: 0.3846\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 6.9e-05.\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 7s 483ms/step - loss: 0.9957 - categorical_accuracy: 0.7377 - val_loss: 0.8131 - val_categorical_accuracy: 0.7280\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 9.849999999999998e-05.\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 7s 481ms/step - loss: 0.4924 - categorical_accuracy: 0.8661 - val_loss: 0.6190 - val_categorical_accuracy: 0.8214\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.000128.\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 7s 479ms/step - loss: 0.3005 - categorical_accuracy: 0.9046 - val_loss: 0.4280 - val_categorical_accuracy: 0.8791\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.00015749999999999998.\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 7s 478ms/step - loss: 0.2503 - categorical_accuracy: 0.9146 - val_loss: 0.3851 - val_categorical_accuracy: 0.8901\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.00018699999999999996.\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 7s 474ms/step - loss: 0.1845 - categorical_accuracy: 0.9442 - val_loss: 0.4081 - val_categorical_accuracy: 0.8791\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.00021649999999999998.\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 7s 482ms/step - loss: 0.1593 - categorical_accuracy: 0.9459 - val_loss: 0.2292 - val_categorical_accuracy: 0.9423\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00024599999999999996.\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 7s 482ms/step - loss: 0.1244 - categorical_accuracy: 0.9542 - val_loss: 0.2789 - val_categorical_accuracy: 0.9313\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0002755.\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 7s 477ms/step - loss: 0.1094 - categorical_accuracy: 0.9643 - val_loss: 0.3142 - val_categorical_accuracy: 0.9313\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.000305.\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 7s 480ms/step - loss: 0.0986 - categorical_accuracy: 0.9688 - val_loss: 0.1626 - val_categorical_accuracy: 0.9588\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0003345.\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 7s 481ms/step - loss: 0.0723 - categorical_accuracy: 0.9766 - val_loss: 0.2177 - val_categorical_accuracy: 0.9451\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.00036399999999999996.\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 7s 481ms/step - loss: 0.0565 - categorical_accuracy: 0.9844 - val_loss: 0.2683 - val_categorical_accuracy: 0.9505\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.00039349999999999997.\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 7s 477ms/step - loss: 0.0907 - categorical_accuracy: 0.9721 - val_loss: 0.2847 - val_categorical_accuracy: 0.9423\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.000423.\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 7s 479ms/step - loss: 0.0920 - categorical_accuracy: 0.9760 - val_loss: 0.3540 - val_categorical_accuracy: 0.9313\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.00045249999999999994.\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 7s 481ms/step - loss: 0.0961 - categorical_accuracy: 0.9766 - val_loss: 0.2999 - val_categorical_accuracy: 0.9451\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.00048199999999999995.\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 7s 476ms/step - loss: 0.0987 - categorical_accuracy: 0.9749 - val_loss: 0.4507 - val_categorical_accuracy: 0.9313\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0005114999999999999.\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 7s 482ms/step - loss: 0.0617 - categorical_accuracy: 0.9805 - val_loss: 0.3284 - val_categorical_accuracy: 0.9478\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0005409999999999999.\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 7s 479ms/step - loss: 0.0601 - categorical_accuracy: 0.9827 - val_loss: 0.3295 - val_categorical_accuracy: 0.9478\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.0005704999999999999.\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 7s 476ms/step - loss: 0.0760 - categorical_accuracy: 0.9754 - val_loss: 0.5464 - val_categorical_accuracy: 0.9423\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.0006.\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 7s 479ms/step - loss: 0.0706 - categorical_accuracy: 0.9799 - val_loss: 0.2824 - val_categorical_accuracy: 0.9478\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.00048019999999999996.\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 7s 478ms/step - loss: 0.0694 - categorical_accuracy: 0.9760 - val_loss: 0.2574 - val_categorical_accuracy: 0.9451\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.00038436000000000004.\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 7s 482ms/step - loss: 0.0423 - categorical_accuracy: 0.9866 - val_loss: 0.2960 - val_categorical_accuracy: 0.9368\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.0003076880000000001.\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 7s 485ms/step - loss: 0.0362 - categorical_accuracy: 0.9894 - val_loss: 0.2476 - val_categorical_accuracy: 0.9423\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.0002463504.\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 7s 474ms/step - loss: 0.0233 - categorical_accuracy: 0.9933 - val_loss: 0.1929 - val_categorical_accuracy: 0.9615\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.00019728032000000003.\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 7s 483ms/step - loss: 0.0213 - categorical_accuracy: 0.9933 - val_loss: 0.2431 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.00015802425600000002.\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 7s 480ms/step - loss: 0.0175 - categorical_accuracy: 0.9955 - val_loss: 0.2281 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.0001266194048.\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 7s 474ms/step - loss: 0.0157 - categorical_accuracy: 0.9933 - val_loss: 0.2044 - val_categorical_accuracy: 0.9615\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.00010149552384000004.\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 7s 481ms/step - loss: 0.0142 - categorical_accuracy: 0.9933 - val_loss: 0.1915 - val_categorical_accuracy: 0.9615\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 8.139641907200002e-05.\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 7s 477ms/step - loss: 0.0210 - categorical_accuracy: 0.9939 - val_loss: 0.1863 - val_categorical_accuracy: 0.9643\n",
      "Evaluation Mode ..\n",
      "6/6 [==============================] - 21s 3s/step - loss: 0.1863 - categorical_accuracy: 0.9643\n",
      "[0.1863024552585557, 0.96428573]\n",
      "Finetuning Mode ..\n",
      "Train for 14 steps, validate for 6 steps\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 8.139641907200002e-05.\n",
      "Epoch 30/45\n",
      "14/14 [==============================] - 166s 12s/step - loss: 0.0059 - categorical_accuracy: 0.9989 - val_loss: 0.1946 - val_categorical_accuracy: 0.9588\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 6.531713525760003e-05.\n",
      "Epoch 31/45\n",
      "14/14 [==============================] - 4s 286ms/step - loss: 0.0110 - categorical_accuracy: 0.9972 - val_loss: 0.1983 - val_categorical_accuracy: 0.9588\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 5.2453708206080024e-05.\n",
      "Epoch 32/45\n",
      "14/14 [==============================] - 4s 269ms/step - loss: 0.0109 - categorical_accuracy: 0.9961 - val_loss: 0.1983 - val_categorical_accuracy: 0.9588\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 4.2162966564864016e-05.\n",
      "Epoch 33/45\n",
      "14/14 [==============================] - 4s 275ms/step - loss: 0.0073 - categorical_accuracy: 0.9978 - val_loss: 0.1899 - val_categorical_accuracy: 0.9588\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 3.3930373251891216e-05.\n",
      "Epoch 34/45\n",
      "14/14 [==============================] - 4s 280ms/step - loss: 0.0097 - categorical_accuracy: 0.9972 - val_loss: 0.1814 - val_categorical_accuracy: 0.9588\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 2.734429860151298e-05.\n",
      "Epoch 35/45\n",
      "14/14 [==============================] - 4s 277ms/step - loss: 0.0047 - categorical_accuracy: 0.9989 - val_loss: 0.1781 - val_categorical_accuracy: 0.9615\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 2.2075438881210384e-05.\n",
      "Epoch 36/45\n",
      "14/14 [==============================] - 4s 272ms/step - loss: 0.0070 - categorical_accuracy: 0.9978 - val_loss: 0.1782 - val_categorical_accuracy: 0.9588\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 1.7860351104968306e-05.\n",
      "Epoch 37/45\n",
      "14/14 [==============================] - 4s 282ms/step - loss: 0.0039 - categorical_accuracy: 0.9989 - val_loss: 0.1785 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 1.4488280883974648e-05.\n",
      "Epoch 38/45\n",
      "14/14 [==============================] - 4s 278ms/step - loss: 0.0047 - categorical_accuracy: 0.9983 - val_loss: 0.1765 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 1.179062470717972e-05.\n",
      "Epoch 39/45\n",
      "14/14 [==============================] - 4s 276ms/step - loss: 0.0047 - categorical_accuracy: 0.9983 - val_loss: 0.1741 - val_categorical_accuracy: 0.9615\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 9.632499765743775e-06.\n",
      "Epoch 40/45\n",
      "14/14 [==============================] - 4s 280ms/step - loss: 0.0057 - categorical_accuracy: 0.9967 - val_loss: 0.1724 - val_categorical_accuracy: 0.9643\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 7.905999812595021e-06.\n",
      "Epoch 41/45\n",
      "14/14 [==============================] - 4s 276ms/step - loss: 0.0068 - categorical_accuracy: 0.9983 - val_loss: 0.1725 - val_categorical_accuracy: 0.9643\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 6.524799850076017e-06.\n",
      "Epoch 42/45\n",
      "14/14 [==============================] - 4s 280ms/step - loss: 0.0140 - categorical_accuracy: 0.9939 - val_loss: 0.1711 - val_categorical_accuracy: 0.9643\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 5.419839880060813e-06.\n",
      "Epoch 43/45\n",
      "14/14 [==============================] - 4s 282ms/step - loss: 0.0062 - categorical_accuracy: 0.9989 - val_loss: 0.1714 - val_categorical_accuracy: 0.9643\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 4.535871904048651e-06.\n",
      "Epoch 44/45\n",
      "14/14 [==============================] - 4s 274ms/step - loss: 0.0053 - categorical_accuracy: 0.9983 - val_loss: 0.1699 - val_categorical_accuracy: 0.9643\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 3.828697523238921e-06.\n",
      "Epoch 45/45\n",
      "14/14 [==============================] - 4s 275ms/step - loss: 0.0077 - categorical_accuracy: 0.9978 - val_loss: 0.1696 - val_categorical_accuracy: 0.9643\n",
      "Evaluation Mode ..\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.1696 - categorical_accuracy: 0.9643\n",
      "[0.1695716818794608, 0.96428573]\n",
      "Fold - 3/5\n",
      "Creating Dataset ..\n",
      "Done.!\n",
      "Training Mode ..\n",
      "Train for 14 steps, validate for 6 steps\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/30\n",
      "14/14 [==============================] - 269s 19s/step - loss: 1.3809 - categorical_accuracy: 0.3086 - val_loss: 1.3389 - val_categorical_accuracy: 0.3315\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 3.95e-05.\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 7s 483ms/step - loss: 1.2971 - categorical_accuracy: 0.4559 - val_loss: 1.2249 - val_categorical_accuracy: 0.4164\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 6.9e-05.\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 7s 480ms/step - loss: 1.0087 - categorical_accuracy: 0.7405 - val_loss: 0.7208 - val_categorical_accuracy: 0.8274\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 9.849999999999998e-05.\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 7s 483ms/step - loss: 0.5344 - categorical_accuracy: 0.8504 - val_loss: 0.5681 - val_categorical_accuracy: 0.8438\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.000128.\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 7s 486ms/step - loss: 0.3047 - categorical_accuracy: 0.9068 - val_loss: 0.4504 - val_categorical_accuracy: 0.8877\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.00015749999999999998.\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 7s 479ms/step - loss: 0.2452 - categorical_accuracy: 0.9208 - val_loss: 0.4319 - val_categorical_accuracy: 0.8795\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.00018699999999999996.\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 7s 483ms/step - loss: 0.2040 - categorical_accuracy: 0.9275 - val_loss: 0.2193 - val_categorical_accuracy: 0.9425\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.00021649999999999998.\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 7s 482ms/step - loss: 0.1636 - categorical_accuracy: 0.9470 - val_loss: 0.2244 - val_categorical_accuracy: 0.9342\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00024599999999999996.\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 7s 482ms/step - loss: 0.1322 - categorical_accuracy: 0.9576 - val_loss: 0.2383 - val_categorical_accuracy: 0.9342\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0002755.\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 7s 481ms/step - loss: 0.0944 - categorical_accuracy: 0.9704 - val_loss: 0.2746 - val_categorical_accuracy: 0.9205\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.000305.\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 7s 481ms/step - loss: 0.0953 - categorical_accuracy: 0.9699 - val_loss: 0.2617 - val_categorical_accuracy: 0.9342\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0003345.\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 7s 485ms/step - loss: 0.1063 - categorical_accuracy: 0.9637 - val_loss: 0.2971 - val_categorical_accuracy: 0.9479\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.00036399999999999996.\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 7s 483ms/step - loss: 0.0919 - categorical_accuracy: 0.9688 - val_loss: 0.3527 - val_categorical_accuracy: 0.9342\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.00039349999999999997.\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 7s 481ms/step - loss: 0.0804 - categorical_accuracy: 0.9732 - val_loss: 0.1924 - val_categorical_accuracy: 0.9644\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.000423.\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 7s 479ms/step - loss: 0.0695 - categorical_accuracy: 0.9782 - val_loss: 0.3102 - val_categorical_accuracy: 0.9233\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.00045249999999999994.\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 7s 482ms/step - loss: 0.0681 - categorical_accuracy: 0.9777 - val_loss: 0.3294 - val_categorical_accuracy: 0.9425\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.00048199999999999995.\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 7s 478ms/step - loss: 0.0587 - categorical_accuracy: 0.9794 - val_loss: 0.3032 - val_categorical_accuracy: 0.9534\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0005114999999999999.\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 7s 480ms/step - loss: 0.0579 - categorical_accuracy: 0.9838 - val_loss: 0.2656 - val_categorical_accuracy: 0.9479\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0005409999999999999.\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 7s 482ms/step - loss: 0.0820 - categorical_accuracy: 0.9738 - val_loss: 0.1888 - val_categorical_accuracy: 0.9562\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.0005704999999999999.\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 7s 486ms/step - loss: 0.0750 - categorical_accuracy: 0.9782 - val_loss: 1.0291 - val_categorical_accuracy: 0.9370\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.0006.\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 7s 481ms/step - loss: 0.0758 - categorical_accuracy: 0.9754 - val_loss: 0.4140 - val_categorical_accuracy: 0.9397\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.00048019999999999996.\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 7s 477ms/step - loss: 0.0668 - categorical_accuracy: 0.9771 - val_loss: 0.2570 - val_categorical_accuracy: 0.9370\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.00038436000000000004.\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 7s 481ms/step - loss: 0.0618 - categorical_accuracy: 0.9816 - val_loss: 0.2553 - val_categorical_accuracy: 0.9534\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.0003076880000000001.\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 9s 676ms/step - loss: 0.0533 - categorical_accuracy: 0.9844 - val_loss: 0.2633 - val_categorical_accuracy: 0.9534\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.0002463504.\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 7s 495ms/step - loss: 0.0299 - categorical_accuracy: 0.9927 - val_loss: 0.2588 - val_categorical_accuracy: 0.9507\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.00019728032000000003.\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 7s 479ms/step - loss: 0.0221 - categorical_accuracy: 0.9950 - val_loss: 0.2587 - val_categorical_accuracy: 0.9589\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.00015802425600000002.\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 7s 481ms/step - loss: 0.0174 - categorical_accuracy: 0.9944 - val_loss: 0.2449 - val_categorical_accuracy: 0.9589\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.0001266194048.\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 7s 483ms/step - loss: 0.0203 - categorical_accuracy: 0.9927 - val_loss: 0.2209 - val_categorical_accuracy: 0.9671\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.00010149552384000004.\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 7s 486ms/step - loss: 0.0156 - categorical_accuracy: 0.9967 - val_loss: 0.2081 - val_categorical_accuracy: 0.9616\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 8.139641907200002e-05.\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 7s 479ms/step - loss: 0.0198 - categorical_accuracy: 0.9922 - val_loss: 0.2005 - val_categorical_accuracy: 0.9644\n",
      "Evaluation Mode ..\n",
      "6/6 [==============================] - 21s 3s/step - loss: 0.2005 - categorical_accuracy: 0.9644\n",
      "[0.2004710187514623, 0.9643836]\n",
      "Finetuning Mode ..\n",
      "Train for 14 steps, validate for 6 steps\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 8.139641907200002e-05.\n",
      "Epoch 30/45\n",
      "14/14 [==============================] - 165s 12s/step - loss: 0.0070 - categorical_accuracy: 0.9983 - val_loss: 0.1972 - val_categorical_accuracy: 0.9644\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 6.531713525760003e-05.\n",
      "Epoch 31/45\n",
      "14/14 [==============================] - 4s 285ms/step - loss: 0.0068 - categorical_accuracy: 0.9978 - val_loss: 0.2131 - val_categorical_accuracy: 0.9671\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 5.2453708206080024e-05.\n",
      "Epoch 32/45\n",
      "14/14 [==============================] - 4s 271ms/step - loss: 0.0249 - categorical_accuracy: 0.9961 - val_loss: 0.2094 - val_categorical_accuracy: 0.9699\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 4.2162966564864016e-05.\n",
      "Epoch 33/45\n",
      "14/14 [==============================] - 4s 268ms/step - loss: 0.0117 - categorical_accuracy: 0.9967 - val_loss: 0.2023 - val_categorical_accuracy: 0.9671\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 3.3930373251891216e-05.\n",
      "Epoch 34/45\n",
      "14/14 [==============================] - 4s 283ms/step - loss: 0.0079 - categorical_accuracy: 0.9967 - val_loss: 0.1990 - val_categorical_accuracy: 0.9671\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 2.734429860151298e-05.\n",
      "Epoch 35/45\n",
      "14/14 [==============================] - 4s 277ms/step - loss: 0.0096 - categorical_accuracy: 0.9967 - val_loss: 0.2004 - val_categorical_accuracy: 0.9699\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 2.2075438881210384e-05.\n",
      "Epoch 36/45\n",
      "14/14 [==============================] - 4s 274ms/step - loss: 0.0055 - categorical_accuracy: 0.9983 - val_loss: 0.2014 - val_categorical_accuracy: 0.9699\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 1.7860351104968306e-05.\n",
      "Epoch 37/45\n",
      "14/14 [==============================] - 4s 280ms/step - loss: 0.0072 - categorical_accuracy: 0.9967 - val_loss: 0.2026 - val_categorical_accuracy: 0.9671\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 1.4488280883974648e-05.\n",
      "Epoch 38/45\n",
      "14/14 [==============================] - 4s 275ms/step - loss: 0.0086 - categorical_accuracy: 0.9967 - val_loss: 0.2028 - val_categorical_accuracy: 0.9671\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 1.179062470717972e-05.\n",
      "Epoch 39/45\n",
      "14/14 [==============================] - 4s 277ms/step - loss: 0.0066 - categorical_accuracy: 0.9983 - val_loss: 0.2022 - val_categorical_accuracy: 0.9671\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 9.632499765743775e-06.\n",
      "Epoch 40/45\n",
      "14/14 [==============================] - 4s 281ms/step - loss: 0.0099 - categorical_accuracy: 0.9978 - val_loss: 0.2029 - val_categorical_accuracy: 0.9671\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 7.905999812595021e-06.\n",
      "Epoch 41/45\n",
      "14/14 [==============================] - 4s 277ms/step - loss: 0.0043 - categorical_accuracy: 0.9994 - val_loss: 0.2037 - val_categorical_accuracy: 0.9671\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 6.524799850076017e-06.\n",
      "Epoch 42/45\n",
      "14/14 [==============================] - 4s 283ms/step - loss: 0.0082 - categorical_accuracy: 0.9978 - val_loss: 0.2021 - val_categorical_accuracy: 0.9699\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 5.419839880060813e-06.\n",
      "Epoch 43/45\n",
      "14/14 [==============================] - 4s 283ms/step - loss: 0.0039 - categorical_accuracy: 0.9994 - val_loss: 0.2012 - val_categorical_accuracy: 0.9726\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 4.535871904048651e-06.\n",
      "Epoch 44/45\n",
      "14/14 [==============================] - 4s 271ms/step - loss: 0.0052 - categorical_accuracy: 0.9994 - val_loss: 0.1996 - val_categorical_accuracy: 0.9726\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 3.828697523238921e-06.\n",
      "Epoch 45/45\n",
      "14/14 [==============================] - 4s 276ms/step - loss: 0.0052 - categorical_accuracy: 0.9983 - val_loss: 0.1988 - val_categorical_accuracy: 0.9726\n",
      "Evaluation Mode ..\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.1988 - categorical_accuracy: 0.9726\n",
      "[0.19876507545510927, 0.9726028]\n",
      "Fold - 4/5\n",
      "Creating Dataset ..\n",
      "Done.!\n",
      "Training Mode ..\n",
      "Train for 14 steps, validate for 6 steps\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/30\n",
      "14/14 [==============================] - 272s 19s/step - loss: 1.3726 - categorical_accuracy: 0.3108 - val_loss: 1.3875 - val_categorical_accuracy: 0.2253\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 3.95e-05.\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 7s 486ms/step - loss: 1.2802 - categorical_accuracy: 0.4955 - val_loss: 1.2698 - val_categorical_accuracy: 0.6071\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 6.9e-05.\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 7s 482ms/step - loss: 0.9758 - categorical_accuracy: 0.7662 - val_loss: 0.7877 - val_categorical_accuracy: 0.7308\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 9.849999999999998e-05.\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 7s 477ms/step - loss: 0.4876 - categorical_accuracy: 0.8717 - val_loss: 0.6049 - val_categorical_accuracy: 0.7830\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.000128.\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 7s 485ms/step - loss: 0.3352 - categorical_accuracy: 0.8923 - val_loss: 0.5432 - val_categorical_accuracy: 0.8242\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.00015749999999999998.\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 7s 481ms/step - loss: 0.2140 - categorical_accuracy: 0.9291 - val_loss: 0.4764 - val_categorical_accuracy: 0.8516\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.00018699999999999996.\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 7s 482ms/step - loss: 0.1788 - categorical_accuracy: 0.9386 - val_loss: 0.3057 - val_categorical_accuracy: 0.9066\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.00021649999999999998.\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 7s 480ms/step - loss: 0.1536 - categorical_accuracy: 0.9515 - val_loss: 0.2655 - val_categorical_accuracy: 0.9231\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00024599999999999996.\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 7s 478ms/step - loss: 0.1146 - categorical_accuracy: 0.9604 - val_loss: 0.3038 - val_categorical_accuracy: 0.9203\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0002755.\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 7s 483ms/step - loss: 0.1165 - categorical_accuracy: 0.9637 - val_loss: 0.2222 - val_categorical_accuracy: 0.9505\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.000305.\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 7s 477ms/step - loss: 0.0854 - categorical_accuracy: 0.9771 - val_loss: 0.2741 - val_categorical_accuracy: 0.9451\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0003345.\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 7s 479ms/step - loss: 0.0672 - categorical_accuracy: 0.9788 - val_loss: 0.5051 - val_categorical_accuracy: 0.9451\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.00036399999999999996.\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 7s 481ms/step - loss: 0.0752 - categorical_accuracy: 0.9754 - val_loss: 0.4179 - val_categorical_accuracy: 0.9286\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.00039349999999999997.\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 7s 479ms/step - loss: 0.1184 - categorical_accuracy: 0.9699 - val_loss: 0.4542 - val_categorical_accuracy: 0.9286\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.000423.\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 7s 479ms/step - loss: 0.0737 - categorical_accuracy: 0.9760 - val_loss: 0.4762 - val_categorical_accuracy: 0.9231\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.00045249999999999994.\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 7s 487ms/step - loss: 0.1018 - categorical_accuracy: 0.9665 - val_loss: 0.4969 - val_categorical_accuracy: 0.9396\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.00048199999999999995.\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 7s 480ms/step - loss: 0.0734 - categorical_accuracy: 0.9771 - val_loss: 0.3743 - val_categorical_accuracy: 0.9396\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0005114999999999999.\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 7s 486ms/step - loss: 0.0743 - categorical_accuracy: 0.9794 - val_loss: 0.4937 - val_categorical_accuracy: 0.9231\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0005409999999999999.\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 7s 479ms/step - loss: 0.0758 - categorical_accuracy: 0.9760 - val_loss: 0.4059 - val_categorical_accuracy: 0.9313\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.0005704999999999999.\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 7s 486ms/step - loss: 0.0822 - categorical_accuracy: 0.9732 - val_loss: 0.2796 - val_categorical_accuracy: 0.9615\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.0006.\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 7s 485ms/step - loss: 0.0744 - categorical_accuracy: 0.9760 - val_loss: 0.5447 - val_categorical_accuracy: 0.9423\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.00048019999999999996.\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 7s 485ms/step - loss: 0.0662 - categorical_accuracy: 0.9805 - val_loss: 0.2700 - val_categorical_accuracy: 0.9478\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.00038436000000000004.\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 7s 481ms/step - loss: 0.0433 - categorical_accuracy: 0.9877 - val_loss: 0.4226 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.0003076880000000001.\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 7s 478ms/step - loss: 0.0370 - categorical_accuracy: 0.9883 - val_loss: 0.3717 - val_categorical_accuracy: 0.9615\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.0002463504.\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 7s 485ms/step - loss: 0.0223 - categorical_accuracy: 0.9933 - val_loss: 0.2879 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.00019728032000000003.\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 7s 484ms/step - loss: 0.0215 - categorical_accuracy: 0.9939 - val_loss: 0.2981 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.00015802425600000002.\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 7s 485ms/step - loss: 0.0207 - categorical_accuracy: 0.9911 - val_loss: 0.2644 - val_categorical_accuracy: 0.9615\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.0001266194048.\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 7s 481ms/step - loss: 0.0313 - categorical_accuracy: 0.9950 - val_loss: 0.1708 - val_categorical_accuracy: 0.9643\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.00010149552384000004.\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 7s 485ms/step - loss: 0.0276 - categorical_accuracy: 0.9927 - val_loss: 0.1660 - val_categorical_accuracy: 0.9615\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 8.139641907200002e-05.\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 7s 480ms/step - loss: 0.0111 - categorical_accuracy: 0.9972 - val_loss: 0.1712 - val_categorical_accuracy: 0.9588\n",
      "Evaluation Mode ..\n",
      "6/6 [==============================] - 21s 4s/step - loss: 0.1712 - categorical_accuracy: 0.9588\n",
      "[0.17121595004573464, 0.95879126]\n",
      "Finetuning Mode ..\n",
      "Train for 14 steps, validate for 6 steps\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 8.139641907200002e-05.\n",
      "Epoch 30/45\n",
      "14/14 [==============================] - 170s 12s/step - loss: 0.0149 - categorical_accuracy: 0.9950 - val_loss: 0.1483 - val_categorical_accuracy: 0.9643\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 6.531713525760003e-05.\n",
      "Epoch 31/45\n",
      "14/14 [==============================] - 4s 286ms/step - loss: 0.0135 - categorical_accuracy: 0.9961 - val_loss: 0.1658 - val_categorical_accuracy: 0.9670\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 5.2453708206080024e-05.\n",
      "Epoch 32/45\n",
      "14/14 [==============================] - 4s 277ms/step - loss: 0.0128 - categorical_accuracy: 0.9961 - val_loss: 0.1836 - val_categorical_accuracy: 0.9698\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 4.2162966564864016e-05.\n",
      "Epoch 33/45\n",
      "14/14 [==============================] - 4s 273ms/step - loss: 0.0096 - categorical_accuracy: 0.9989 - val_loss: 0.1889 - val_categorical_accuracy: 0.9698\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 3.3930373251891216e-05.\n",
      "Epoch 34/45\n",
      "14/14 [==============================] - 4s 278ms/step - loss: 0.0113 - categorical_accuracy: 0.9967 - val_loss: 0.1883 - val_categorical_accuracy: 0.9698\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 2.734429860151298e-05.\n",
      "Epoch 35/45\n",
      "14/14 [==============================] - 4s 275ms/step - loss: 0.0085 - categorical_accuracy: 0.9967 - val_loss: 0.1928 - val_categorical_accuracy: 0.9670\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 2.2075438881210384e-05.\n",
      "Epoch 36/45\n",
      "14/14 [==============================] - 4s 271ms/step - loss: 0.0085 - categorical_accuracy: 0.9972 - val_loss: 0.1963 - val_categorical_accuracy: 0.9670\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 1.7860351104968306e-05.\n",
      "Epoch 37/45\n",
      "14/14 [==============================] - 4s 282ms/step - loss: 0.0070 - categorical_accuracy: 0.9972 - val_loss: 0.1928 - val_categorical_accuracy: 0.9670\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 1.4488280883974648e-05.\n",
      "Epoch 38/45\n",
      "14/14 [==============================] - 4s 281ms/step - loss: 0.0096 - categorical_accuracy: 0.9978 - val_loss: 0.1933 - val_categorical_accuracy: 0.9670\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 1.179062470717972e-05.\n",
      "Epoch 39/45\n",
      "14/14 [==============================] - 4s 279ms/step - loss: 0.0079 - categorical_accuracy: 0.9972 - val_loss: 0.1954 - val_categorical_accuracy: 0.9670\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 9.632499765743775e-06.\n",
      "Epoch 40/45\n",
      "14/14 [==============================] - 4s 279ms/step - loss: 0.0058 - categorical_accuracy: 0.9983 - val_loss: 0.1950 - val_categorical_accuracy: 0.9670\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 7.905999812595021e-06.\n",
      "Epoch 41/45\n",
      "14/14 [==============================] - 4s 280ms/step - loss: 0.0056 - categorical_accuracy: 0.9989 - val_loss: 0.1943 - val_categorical_accuracy: 0.9698\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 6.524799850076017e-06.\n",
      "Epoch 42/45\n",
      "14/14 [==============================] - 4s 285ms/step - loss: 0.0045 - categorical_accuracy: 0.9994 - val_loss: 0.1934 - val_categorical_accuracy: 0.9698\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 5.419839880060813e-06.\n",
      "Epoch 43/45\n",
      "14/14 [==============================] - 4s 281ms/step - loss: 0.0055 - categorical_accuracy: 0.9983 - val_loss: 0.1906 - val_categorical_accuracy: 0.9698\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 4.535871904048651e-06.\n",
      "Epoch 44/45\n",
      "14/14 [==============================] - 4s 276ms/step - loss: 0.0059 - categorical_accuracy: 0.9978 - val_loss: 0.1901 - val_categorical_accuracy: 0.9670\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 3.828697523238921e-06.\n",
      "Epoch 45/45\n",
      "14/14 [==============================] - 4s 284ms/step - loss: 0.0036 - categorical_accuracy: 0.9994 - val_loss: 0.1887 - val_categorical_accuracy: 0.9670\n",
      "Evaluation Mode ..\n",
      "6/6 [==============================] - 21s 3s/step - loss: 0.1887 - categorical_accuracy: 0.9670\n",
      "[0.18870299262925982, 0.96703297]\n",
      "Fold - 5/5\n",
      "Creating Dataset ..\n",
      "Done.!\n",
      "Training Mode ..\n",
      "Train for 14 steps, validate for 6 steps\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/30\n",
      "14/14 [==============================] - 273s 20s/step - loss: 1.3906 - categorical_accuracy: 0.2444 - val_loss: 1.4313 - val_categorical_accuracy: 0.2088\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 3.95e-05.\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 7s 489ms/step - loss: 1.3000 - categorical_accuracy: 0.4280 - val_loss: 1.3352 - val_categorical_accuracy: 0.3736\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 6.9e-05.\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 7s 490ms/step - loss: 1.0344 - categorical_accuracy: 0.7249 - val_loss: 0.8802 - val_categorical_accuracy: 0.8214\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 9.849999999999998e-05.\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 7s 480ms/step - loss: 0.5249 - categorical_accuracy: 0.8521 - val_loss: 0.5147 - val_categorical_accuracy: 0.8599\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.000128.\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 7s 479ms/step - loss: 0.3260 - categorical_accuracy: 0.9012 - val_loss: 0.3195 - val_categorical_accuracy: 0.8956\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.00015749999999999998.\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 7s 484ms/step - loss: 0.2478 - categorical_accuracy: 0.9219 - val_loss: 0.2649 - val_categorical_accuracy: 0.9203\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.00018699999999999996.\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 7s 478ms/step - loss: 0.1959 - categorical_accuracy: 0.9336 - val_loss: 0.2336 - val_categorical_accuracy: 0.9368\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.00021649999999999998.\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 7s 477ms/step - loss: 0.1652 - categorical_accuracy: 0.9526 - val_loss: 0.1987 - val_categorical_accuracy: 0.9533\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00024599999999999996.\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 7s 481ms/step - loss: 0.1266 - categorical_accuracy: 0.9643 - val_loss: 0.2249 - val_categorical_accuracy: 0.9423\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0002755.\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 7s 481ms/step - loss: 0.1057 - categorical_accuracy: 0.9637 - val_loss: 0.3384 - val_categorical_accuracy: 0.9368\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.000305.\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 7s 485ms/step - loss: 0.0731 - categorical_accuracy: 0.9743 - val_loss: 0.3940 - val_categorical_accuracy: 0.9341\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0003345.\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 7s 473ms/step - loss: 0.0680 - categorical_accuracy: 0.9782 - val_loss: 0.4321 - val_categorical_accuracy: 0.9286\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.00036399999999999996.\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 7s 489ms/step - loss: 0.1060 - categorical_accuracy: 0.9665 - val_loss: 0.3343 - val_categorical_accuracy: 0.9451\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.00039349999999999997.\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 7s 485ms/step - loss: 0.0985 - categorical_accuracy: 0.9671 - val_loss: 0.2472 - val_categorical_accuracy: 0.9258\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.000423.\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 7s 478ms/step - loss: 0.0830 - categorical_accuracy: 0.9715 - val_loss: 0.3082 - val_categorical_accuracy: 0.9505\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.00045249999999999994.\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 7s 488ms/step - loss: 0.0743 - categorical_accuracy: 0.9760 - val_loss: 0.3449 - val_categorical_accuracy: 0.9505\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.00048199999999999995.\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 7s 488ms/step - loss: 0.0539 - categorical_accuracy: 0.9844 - val_loss: 0.3472 - val_categorical_accuracy: 0.9478\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0005114999999999999.\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 7s 479ms/step - loss: 0.0772 - categorical_accuracy: 0.9754 - val_loss: 0.4627 - val_categorical_accuracy: 0.9451\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0005409999999999999.\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 7s 488ms/step - loss: 0.0585 - categorical_accuracy: 0.9833 - val_loss: 0.5649 - val_categorical_accuracy: 0.9368\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.0005704999999999999.\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 7s 482ms/step - loss: 0.0636 - categorical_accuracy: 0.9794 - val_loss: 0.6147 - val_categorical_accuracy: 0.9341\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.0006.\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 7s 483ms/step - loss: 0.0757 - categorical_accuracy: 0.9754 - val_loss: 0.3702 - val_categorical_accuracy: 0.9533\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.00048019999999999996.\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 7s 483ms/step - loss: 0.0739 - categorical_accuracy: 0.9777 - val_loss: 0.4939 - val_categorical_accuracy: 0.9423\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.00038436000000000004.\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 7s 482ms/step - loss: 0.0503 - categorical_accuracy: 0.9844 - val_loss: 0.4807 - val_categorical_accuracy: 0.9505\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.0003076880000000001.\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 7s 487ms/step - loss: 0.0512 - categorical_accuracy: 0.9872 - val_loss: 0.6680 - val_categorical_accuracy: 0.9451\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.0002463504.\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 7s 477ms/step - loss: 0.0326 - categorical_accuracy: 0.9911 - val_loss: 0.5092 - val_categorical_accuracy: 0.9533\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.00019728032000000003.\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 7s 487ms/step - loss: 0.0304 - categorical_accuracy: 0.9900 - val_loss: 0.4007 - val_categorical_accuracy: 0.9533\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.00015802425600000002.\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 7s 487ms/step - loss: 0.0195 - categorical_accuracy: 0.9955 - val_loss: 0.3223 - val_categorical_accuracy: 0.9533\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.0001266194048.\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 7s 484ms/step - loss: 0.0127 - categorical_accuracy: 0.9967 - val_loss: 0.3052 - val_categorical_accuracy: 0.9533\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.00010149552384000004.\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 7s 487ms/step - loss: 0.0192 - categorical_accuracy: 0.9944 - val_loss: 0.3083 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 8.139641907200002e-05.\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 7s 496ms/step - loss: 0.0161 - categorical_accuracy: 0.9950 - val_loss: 0.2830 - val_categorical_accuracy: 0.9560\n",
      "Evaluation Mode ..\n",
      "6/6 [==============================] - 21s 3s/step - loss: 0.2830 - categorical_accuracy: 0.9560\n",
      "[0.2830231414021303, 0.95604396]\n",
      "Finetuning Mode ..\n",
      "Train for 14 steps, validate for 6 steps\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 8.139641907200002e-05.\n",
      "Epoch 30/45\n",
      "14/14 [==============================] - 166s 12s/step - loss: 0.0112 - categorical_accuracy: 0.9967 - val_loss: 0.2579 - val_categorical_accuracy: 0.9588\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 6.531713525760003e-05.\n",
      "Epoch 31/45\n",
      "14/14 [==============================] - 4s 284ms/step - loss: 0.0081 - categorical_accuracy: 0.9967 - val_loss: 0.2478 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 5.2453708206080024e-05.\n",
      "Epoch 32/45\n",
      "14/14 [==============================] - 4s 280ms/step - loss: 0.0088 - categorical_accuracy: 0.9972 - val_loss: 0.2561 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 4.2162966564864016e-05.\n",
      "Epoch 33/45\n",
      "14/14 [==============================] - 4s 276ms/step - loss: 0.0061 - categorical_accuracy: 0.9994 - val_loss: 0.2582 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 3.3930373251891216e-05.\n",
      "Epoch 34/45\n",
      "14/14 [==============================] - 4s 282ms/step - loss: 0.0130 - categorical_accuracy: 0.9972 - val_loss: 0.2473 - val_categorical_accuracy: 0.9588\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 2.734429860151298e-05.\n",
      "Epoch 35/45\n",
      "14/14 [==============================] - 4s 280ms/step - loss: 0.0061 - categorical_accuracy: 0.9983 - val_loss: 0.2390 - val_categorical_accuracy: 0.9615\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 2.2075438881210384e-05.\n",
      "Epoch 36/45\n",
      "14/14 [==============================] - 4s 282ms/step - loss: 0.0044 - categorical_accuracy: 0.9994 - val_loss: 0.2367 - val_categorical_accuracy: 0.9615\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 1.7860351104968306e-05.\n",
      "Epoch 37/45\n",
      "14/14 [==============================] - 4s 280ms/step - loss: 0.0076 - categorical_accuracy: 0.9989 - val_loss: 0.2420 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 1.4488280883974648e-05.\n",
      "Epoch 38/45\n",
      "14/14 [==============================] - 4s 281ms/step - loss: 0.0036 - categorical_accuracy: 0.9994 - val_loss: 0.2431 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 1.179062470717972e-05.\n",
      "Epoch 39/45\n",
      "14/14 [==============================] - 4s 281ms/step - loss: 0.0065 - categorical_accuracy: 0.9978 - val_loss: 0.2456 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 9.632499765743775e-06.\n",
      "Epoch 40/45\n",
      "14/14 [==============================] - 4s 277ms/step - loss: 0.0036 - categorical_accuracy: 1.0000 - val_loss: 0.2440 - val_categorical_accuracy: 0.9533\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 7.905999812595021e-06.\n",
      "Epoch 41/45\n",
      "14/14 [==============================] - 4s 276ms/step - loss: 0.0059 - categorical_accuracy: 0.9983 - val_loss: 0.2410 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 6.524799850076017e-06.\n",
      "Epoch 42/45\n",
      "14/14 [==============================] - 4s 278ms/step - loss: 0.0053 - categorical_accuracy: 0.9983 - val_loss: 0.2405 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 5.419839880060813e-06.\n",
      "Epoch 43/45\n",
      "14/14 [==============================] - 4s 277ms/step - loss: 0.0041 - categorical_accuracy: 0.9989 - val_loss: 0.2354 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 4.535871904048651e-06.\n",
      "Epoch 44/45\n",
      "14/14 [==============================] - 4s 279ms/step - loss: 0.0071 - categorical_accuracy: 0.9989 - val_loss: 0.2351 - val_categorical_accuracy: 0.9560\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 3.828697523238921e-06.\n",
      "Epoch 45/45\n",
      "14/14 [==============================] - 4s 279ms/step - loss: 0.0038 - categorical_accuracy: 0.9989 - val_loss: 0.2352 - val_categorical_accuracy: 0.9560\n",
      "Evaluation Mode ..\n",
      "6/6 [==============================] - 20s 3s/step - loss: 0.2352 - categorical_accuracy: 0.9560\n",
      "[0.23515116507284498, 0.95604396]\n"
     ]
    }
   ],
   "source": [
    "nfold = 5\n",
    "all_predictions = []\n",
    "mskf = MultilabelStratifiedKFold(n_splits=nfold, random_state=2020, shuffle=True)\n",
    "for i, (train_idx, val_idx) in enumerate(mskf.split(train_paths, train_labels)):\n",
    "    print(f\"Fold - {i+1}/{nfold}\")\n",
    "    tr_paths = train_paths[train_idx]\n",
    "    tr_labels = train_labels[train_idx]\n",
    "    val_paths = train_paths[val_idx]\n",
    "    val_labels = train_labels[val_idx]\n",
    "    print(\"Creating Dataset ..\")\n",
    "    train_dataset, valid_dataset = dataset(tr_paths, tr_labels, val_paths, val_labels)\n",
    "    print(\"Done.!\")\n",
    "    \n",
    "    print(\"Training Mode ..\")\n",
    "    model = create_model()\n",
    "    history = model.fit(train_dataset, \n",
    "                        epochs=EPOCHS, \n",
    "                        validation_data=valid_dataset, \n",
    "                        steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                        callbacks=[lr_schedule])\n",
    "    print(\"Evaluation Mode ..\")\n",
    "    print(model.evaluate(valid_dataset))\n",
    "    \n",
    "    # unfreeze layers and train again\n",
    "    model.layers[1].trainable = True\n",
    "    limit = 500\n",
    "    for i in range(limit): model.layers[0].layers[i].trainable = False\n",
    "    for i in range(limit, 806): model.layers[0].layers[i].trainable = True\n",
    "    with strategy.scope():\n",
    "        model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    print(\"Finetuning Mode ..\")\n",
    "    fine_tune_epochs = 15\n",
    "    total_epochs =  EPOCHS + fine_tune_epochs\n",
    "    ft_history = model.fit(train_dataset,\n",
    "                           validation_data=valid_dataset, \n",
    "                           epochs=total_epochs, \n",
    "                           steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                           callbacks=[lr_schedule], \n",
    "                           initial_epoch =  history.epoch[-1])\n",
    "    print(\"Evaluation Mode ..\")\n",
    "    print(model.evaluate(valid_dataset))\n",
    "    all_predictions.append(model.predict(test_dataset))\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array(all_predictions).sum(axis=0)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>healthy</th>\n",
       "      <th>multiple_diseases</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test_0</td>\n",
       "      <td>8.391365e-07</td>\n",
       "      <td>2.081831e-04</td>\n",
       "      <td>9.997902e-01</td>\n",
       "      <td>7.596158e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test_1</td>\n",
       "      <td>8.562303e-09</td>\n",
       "      <td>6.850918e-07</td>\n",
       "      <td>9.999992e-01</td>\n",
       "      <td>3.853503e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test_2</td>\n",
       "      <td>7.287722e-09</td>\n",
       "      <td>1.296874e-07</td>\n",
       "      <td>4.565488e-10</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test_3</td>\n",
       "      <td>9.999942e-01</td>\n",
       "      <td>1.342393e-06</td>\n",
       "      <td>4.113271e-06</td>\n",
       "      <td>4.214021e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test_4</td>\n",
       "      <td>1.122802e-07</td>\n",
       "      <td>1.135226e-04</td>\n",
       "      <td>9.998863e-01</td>\n",
       "      <td>8.218198e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id       healthy  multiple_diseases          rust          scab\n",
       "0   Test_0  8.391365e-07       2.081831e-04  9.997902e-01  7.596158e-07\n",
       "1   Test_1  8.562303e-09       6.850918e-07  9.999992e-01  3.853503e-08\n",
       "2   Test_2  7.287722e-09       1.296874e-07  4.565488e-10  9.999999e-01\n",
       "3   Test_3  9.999942e-01       1.342393e-06  4.113271e-06  4.214021e-07\n",
       "4   Test_4  1.122802e-07       1.135226e-04  9.998863e-01  8.218198e-09"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.loc[:, 'healthy':] = preds\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
